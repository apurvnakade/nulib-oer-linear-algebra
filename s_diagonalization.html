<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*       on 2022-09-07T20:18:27+05:30       *-->
<!--*   A recent stable commit (2020-08-09):   *-->
<!--* 98f21740783f166a773df4dc83cab5293ab63a4a *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Diagonalization</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="Linear algebra: the theory of vector spaces and linear transformations">
<meta property="book:author" content="Aaron Greicius">
<script src="https://sagecell.sagemath.org/static/embedded_sagecell.js"></script><script>window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|ignore-math",
    processHtmlClass: "process-math",
    renderActions: {
        findScript: [10, function (doc) {
            document.querySelectorAll('script[type^="math/tex"]').forEach(function(node) {
                var display = !!node.type.match(/; *mode=display/);
                var math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                var text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = {node: text, delim: '', n: 0};
                math.end = {node: text, delim: '', n: 0};
                doc.math.push(math);
            });
        }, '']
    },
  },
  chtml: {
    scale: 0.88,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><link href="https://webwork-ptx.aimath.org/webwork2_files/js/apps/MathView/mathview.css" rel="stylesheet">
<script src="https://pretextbook.org/js/0.13/pretext-webwork.js"></script><script src="https://webwork-ptx.aimath.org/webwork2_files/node_modules/iframe-resizer/js/iframeResizer.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.13/pretext.js"></script><script>miniversion=0.674</script><script src="https://pretextbook.org/js/0.13/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/colors_blue_red.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/setcolors.css" rel="stylesheet" type="text/css">
<!--** eBookCongig is necessary to configure interactive       **-->
<!--** Runestone components to run locally in reader's browser **-->
<!--** No external communication:                              **-->
<!--**     log level is 0, Runestone Services are disabled     **-->
<script type="text/javascript">
eBookConfig = {};
eBookConfig.useRunestoneServices = false;
eBookConfig.host = 'http://127.0.0.1:8000';
eBookConfig.course = 'PTX Course: Title Here';
eBookConfig.basecourse = 'PTX Base Course';
eBookConfig.isLoggedIn = false;
eBookConfig.email = '';
eBookConfig.isInstructor = false;
eBookConfig.logLevel = 0;
eBookConfig.username = '';
eBookConfig.readings = null;
eBookConfig.activities = null;
eBookConfig.downloadsEnabled = false;
eBookConfig.allow_pairs = false;
eBookConfig.enableScratchAC = false;
eBookConfig.build_info = "";
eBookConfig.python3 = null;
eBookConfig.acDefaultLanguage = 'python';
eBookConfig.runestone_version = '5.0.1';
eBookConfig.jobehost = '';
eBookConfig.proxyuri_runs = '';
eBookConfig.proxyuri_files = '';
eBookConfig.enable_chatcodes =  false;
</script>
<!--*** Runestone Services ***-->
<script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/runtime.b0f8547c48f16a9f.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/637.d54be67956c5c660.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/runestone.0e9550fe42760516.bundle.js"></script><link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/6.2.1/637.fafafbd97df8a0d1.css">
<link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/6.2.1/runestone.e4d5592da655219f.css">
</head>
<body class="pretext-book ignore-math has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\require{cancel}\newcommand{\Z}{{\mathbb Z}}
\newcommand{\Q}{{\mathbb Q}}
\newcommand{\R}{{\mathbb R}}
\newcommand{\C}{{\mathbb C}}
\newcommand{\T}{{\mathbb T}}
\newcommand{\F}{{\mathbb F}}
\newcommand{\HH}{{\mathbb H}}
\newcommand{\compose}{\circ}
\newcommand{\bolda}{{\mathbf a}}
\newcommand{\boldb}{{\mathbf b}}
\newcommand{\boldc}{{\mathbf c}}
\newcommand{\boldd}{{\mathbf d}}
\newcommand{\bolde}{{\mathbf e}}
\newcommand{\boldi}{{\mathbf i}}
\newcommand{\boldj}{{\mathbf j}}
\newcommand{\boldk}{{\mathbf k}}
\newcommand{\boldn}{{\mathbf n}}
\newcommand{\boldp}{{\mathbf p}}
\newcommand{\boldq}{{\mathbf q}}
\newcommand{\boldr}{{\mathbf r}}
\newcommand{\bolds}{{\mathbf s}}
\newcommand{\boldt}{{\mathbf t}}
\newcommand{\boldu}{{\mathbf u}}
\newcommand{\boldv}{{\mathbf v}}
\newcommand{\boldw}{{\mathbf w}}
\newcommand{\boldx}{{\mathbf x}}
\newcommand{\boldy}{{\mathbf y}}
\newcommand{\boldz}{{\mathbf z}}
\newcommand{\boldzero}{{\mathbf 0}}
\newcommand{\boldmod}{\boldsymbol{ \bmod }}
\newcommand{\boldT}{{\mathbf T}}
\newcommand{\boldN}{{\mathbf N}}
\newcommand{\boldB}{{\mathbf B}}
\newcommand{\boldF}{{\mathbf F}}
\newcommand{\boldS}{{\mathbf S}}
\newcommand{\boldG}{{\mathbf G}}
\newcommand{\boldK}{{\mathbf K}}
\newcommand{\boldL}{{\mathbf L}}
\DeclareMathOperator{\lcm}{lcm}
\DeclareMathOperator{\Span}{span}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\NS}{null}
\DeclareMathOperator{\RS}{row}
\DeclareMathOperator{\CS}{col}
\DeclareMathOperator{\im}{im}
\DeclareMathOperator{\range}{range}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\nullity}{nullity}
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Fix}{Fix}
\DeclareMathOperator{\Aff}{Aff}
\DeclareMathOperator{\Frac}{Frac}
\DeclareMathOperator{\Ann}{Ann}
\DeclareMathOperator{\Tor}{Tor}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\mdeg}{mdeg}
\DeclareMathOperator{\Lt}{Lt}
\DeclareMathOperator{\Lc}{Lc}
\DeclareMathOperator{\disc}{disc}
\DeclareMathOperator{\Frob}{Frob}
\DeclareMathOperator{\adj}{adj}
\DeclareMathOperator{\curl}{curl}
\DeclareMathOperator{\grad}{grad}
\DeclareMathOperator{\diver}{div}
\DeclareMathOperator{\flux}{flux}
\def\Gal{\operatorname{Gal}}
\def\ord{\operatorname{ord}}
\def\ML{\operatorname{M}}
\def\GL{\operatorname{GL}}
\def\PGL{\operatorname{PGL}}
\def\SL{\operatorname{SL}}
\def\PSL{\operatorname{PSL}}
\def\GSp{\operatorname{GSp}}
\def\PGSp{\operatorname{PGSp}}
\def\Sp{\operatorname{Sp}}
\def\PSp{\operatorname{PSp}}
\def\Aut{\operatorname{Aut}}
\def\Inn{\operatorname{Inn}}
\def\Hom{\operatorname{Hom}}
\def\End{\operatorname{End}}
\def\ch{\operatorname{char}}
\def\Zp{\Z/p\Z}
\def\Zm{\Z/m\Z}
\def\Zn{\Z/n\Z}
\def\Fp{\F_p}
\newcommand{\surjects}{\twoheadrightarrow}
\newcommand{\injects}{\hookrightarrow}
\newcommand{\bijects}{\leftrightarrow}
\newcommand{\isomto}{\overset{\sim}{\rightarrow}}
\newcommand{\floor}[1]{\lfloor#1\rfloor}
\newcommand{\ceiling}[1]{\left\lceil#1\right\rceil}
\newcommand{\mclass}[2][m]{[#2]_{#1}}
\newcommand{\val}[2][]{\left\lvert #2\right\rvert_{#1}}
\newcommand{\abs}[2][]{\left\lvert #2\right\rvert_{#1}}
\newcommand{\valuation}[2][]{\left\lvert #2\right\rvert_{#1}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\anpoly}{a_nx^n+a_{n-1}x^{n-1}\cdots +a_1x+a_0}
\newcommand{\anmonic}{x^n+a_{n-1}x^{n-1}\cdots +a_1x+a_0}
\newcommand{\bmpoly}{b_mx^m+b_{m-1}x^{m-1}\cdots +b_1x+b_0}
\newcommand{\pder}[2]{\frac{\partial#1}{\partial#2}}
\newcommand{\normalin}{\trianglelefteq}
\newcommand{\angvec}[1]{\langle #1\rangle}
\newcommand{\varpoly}[2]{#1_{#2}x^{#2}+#1_{#2-1}x^{#2-1}\cdots +#1_1x+#1_0}
\newcommand{\varpower}[1][a]{#1_0+#1_1x+#1_1x^2+\cdots}
\newcommand{\limasto}[2][x]{\lim_{#1\rightarrow #2}}
\def\ntoinfty{\lim_{n\rightarrow\infty}}
\def\xtoinfty{\lim_{x\rightarrow\infty}}
\def\ii{\item}
\def\bb{\begin{enumerate}}
\def\ee{\end{enumerate}}
\def\ds{\displaystyle}
\def\p{\partial}
\newcommand{\abcdmatrix}[4]{\begin{bmatrix}#1\amp #2\\ #3\amp #4 \end{bmatrix}
}
\newenvironment{amatrix}[1][ccc|c]{\left[\begin{array}{#1}}{\end{array}\right]}
\newenvironment{linsys}[2][m]{
\begin{array}[#1]{@{}*{#2}{rc}r@{}}
}{
\end{array}}
\newcommand{\eqsys}{\begin{array}{rcrcrcr}
a_{11}x_{1}\amp +\amp a_{12}x_{2}\amp +\cdots+\amp  a_{1n}x_{n}\amp =\amp b_1\\
a_{21}x_{1}\amp +\amp a_{22}x_{2}\amp +\cdots+\amp a_{2n}x_{n}\amp =\amp b_2\\
\amp \vdots\amp   \amp \vdots \amp  \amp \vdots \amp  \vdots\\
a_{m1}x_{1}\amp +\amp a_{m2}x_{2}\amp +\cdots +\amp a_{mn}x_{n}\amp =\amp b_m
\end{array}
}
\newcommand{\numeqsys}{\begin{array}{rrcrcrcr}
e_1:\amp  a_{11}x_{1}\amp +\amp a_{12}x_{2}\amp +\cdots+\amp  a_{1n}x_{n}\amp =\amp b_1\\
e_2: \amp a_{21}x_{1}\amp +\amp a_{22}x_{2}\amp +\cdots+\amp a_{2n}x_{n}\amp =\amp b_2\\
\amp \vdots\amp   \amp \vdots \amp  \amp \vdots \amp  \vdots\\
e_m: \amp a_{m1}x_{1}\amp +\amp a_{m2}x_{2}\amp +\cdots +\amp a_{mn}x_{n}\amp =\amp b_m
\end{array}
}
\newcommand{\homsys}{\begin{array}{rcrcrcr}
a_{11}x_{1}\amp +\amp a_{12}x_{2}\amp +\cdots+\amp  a_{1n}x_{n}\amp =\amp 0\\
a_{21}x_{1}\amp +\amp a_{22}x_{2}\amp +\cdots+\amp a_{2n}x_{n}\amp =\amp 0\\
\amp \vdots\amp   \amp \vdots \amp  \amp \vdots \amp  \vdots\\
a_{m1}x_{1}\amp +\amp a_{m2}x_{2}\amp +\cdots +\amp a_{mn}x_{n}\amp =\amp 0
\end{array}
}
\newcommand{\vareqsys}[4]{
\begin{array}{ccccccc}
#3_{11}x_{1}\amp +\amp #3_{12}x_{2}\amp +\cdots+\amp  #3_{1#2}x_{#2}\amp =\amp #4_1\\
#3_{21}x_{1}\amp +\amp #3_{22}x_{2}\amp +\cdots+\amp #3_{2#2}x_{#2}\amp =\amp #4_2\\
\vdots \amp \amp \vdots \amp  \amp \vdots \amp =\amp  \vdots\\
#3_{#1 1}x_{1}\amp +\amp #3_{#1 2}x_{2}\amp +\cdots +\amp #3_{#1 #2}x_{#2}\amp =\amp #4_{#1}
\end{array}
}
\newcommand{\genmatrix}[1][a]{
\begin{bmatrix}
#1_{11} \amp  #1_{12} \amp  \cdots \amp  #1_{1n} \\
#1_{21} \amp  #1_{22} \amp  \cdots \amp  #1_{2n} \\
\vdots  \amp  \vdots  \amp  \ddots \amp  \vdots  \\
#1_{m1} \amp  #1_{m2} \amp  \cdots \amp  #1_{mn}
\end{bmatrix}
}
\newcommand{\varmatrix}[3]{
\begin{bmatrix}
#3_{11} \amp  #3_{12} \amp  \cdots \amp  #3_{1#2} \\
#3_{21} \amp  #3_{22} \amp  \cdots \amp  #3_{2#2} \\
\vdots  \amp  \vdots  \amp  \ddots \amp  \vdots  \\
#3_{#1 1} \amp  #3_{#1 2} \amp  \cdots \amp  #3_{#1 #2}
\end{bmatrix}
}
\newcommand{\augmatrix}{
\begin{amatrix}[cccc|c]
a_{11} \amp  a_{12} \amp  \cdots \amp  a_{1n} \amp b_{1}\\
a_{21} \amp  a_{22} \amp  \cdots \amp  a_{2n} \amp b_{2}\\
\vdots  \amp  \vdots  \amp  \ddots \amp  \vdots  \amp \vdots\\
a_{m1} \amp  a_{m2} \amp  \cdots \amp  a_{mn}\amp b_{m}
\end{amatrix}
}
\newcommand{\varaugmatrix}[4]{
\begin{amatrix}[cccc|c]
#3_{11} \amp  #3_{12} \amp  \cdots \amp  #3_{1#2} \amp #4_{1}\\
#3_{21} \amp  #3_{22} \amp  \cdots \amp  #3_{2#2} \amp #4_{2}\\
\vdots  \amp  \vdots  \amp  \ddots \amp  \vdots  \amp \vdots\\
#3_{#1 1} \amp  #3_{#1 2} \amp  \cdots \amp  #3_{#1 #2}\amp #4_{#1}
\end{amatrix}
}
\newcommand{\spaceforemptycolumn}{\makebox[\wd\boxofmathplus]{\ }}

\newcommand{\generalmatrix}[3]{
\left(
\begin{array}{cccc}
#1_{1,1}  \amp #1_{1,2}  \amp \ldots  \amp #1_{1,#2}  \\
#1_{2,1}  \amp #1_{2,2}  \amp \ldots  \amp #1_{2,#2}  \\
\amp \vdots                         \\
#1_{#3,1} \amp #1_{#3,2} \amp \ldots  \amp #1_{#3,#2}
\end{array}
\right)  }
\newcommand{\colvec}[2][c]{\begin{amatrix}[#1] #2 \end{amatrix}}
\DeclareMathOperator{\size}{size}
\DeclareMathOperator{\adjoint}{adj}
\DeclareMathOperator{\sgn}{sgn}
\newcommand{\restrictionmap}[2]{{#1}\mathpunct\upharpoonright\hbox{}_{#2}}
\renewcommand{\emptyset}{\varnothing}

\newcommand{\proj}[2]{\mbox{proj}_{#2}({#1}) }
\renewcommand{\Re}{\operatorname{Re}}
 \renewcommand{\Im}{\operatorname{Im}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href="http://linear-algebra.northwestern.pub/" target="_blank"><img src="external/images/im_holycomm.svg" alt="Logo image"></a><div class="title-container">
<h1 class="heading"><a href="book-1.html"><span class="title">Linear algebra: the theory of vector spaces and linear transformations</span></a></h1>
<p class="byline">Aaron Greicius</p>
</div>
</div></div>
<nav id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<a class="index-button toolbar-item button" href="index-1.html" title="Index">Index</a><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="s_eigenvectors.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="c_transbasis.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="s_spectral_theorem.html" title="Next">Next</a></span>
</div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="s_eigenvectors.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="c_transbasis.html" title="Up">Up</a><a class="next-button button toolbar-item" href="s_spectral_theorem.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link frontmatter">
<a href="frontmatter-1.html" data-scroll="frontmatter-1" class="internal"><span class="title">Front Matter</span></a><ul>
<li><a href="colophon-1.html" data-scroll="colophon-1" class="internal">Colophon</a></li>
<li><a href="acknowledgement-1.html" data-scroll="acknowledgement-1" class="internal">Acknowledgements</a></li>
</ul>
</li>
<li class="link">
<a href="c_foundations.html" data-scroll="c_foundations" class="internal"><span class="codenumber">0</span> <span class="title">Foundations</span></a><ul>
<li><a href="s_sets_functions.html" data-scroll="s_sets_functions" class="internal">Sets and functions</a></li>
<li><a href="s_logic.html" data-scroll="s_logic" class="internal">Logic</a></li>
<li><a href="s_proof_technique.html" data-scroll="s_proof_technique" class="internal">Proof techniques</a></li>
<li><a href="s_complex_numbers.html" data-scroll="s_complex_numbers" class="internal">Complex numbers</a></li>
<li><a href="s_polynomials.html" data-scroll="s_polynomials" class="internal">Polynomials</a></li>
</ul>
</li>
<li class="link">
<a href="c_linear_systems.html" data-scroll="c_linear_systems" class="internal"><span class="codenumber">1</span> <span class="title">Systems of linear equations</span></a><ul>
<li><a href="s_systems.html" data-scroll="s_systems" class="internal">Systems of linear equations</a></li>
<li><a href="s_ge.html" data-scroll="s_ge" class="internal">Gaussian elimination</a></li>
<li><a href="s_solving.html" data-scroll="s_solving" class="internal">Solving linear systems</a></li>
</ul>
</li>
<li class="link">
<a href="c_matrices.html" data-scroll="c_matrices" class="internal"><span class="codenumber">2</span> <span class="title">Matrices, their arithmetic, and their algebra</span></a><ul>
<li><a href="s_matrix.html" data-scroll="s_matrix" class="internal">Matrices and their arithmetic</a></li>
<li><a href="s_algebraic.html" data-scroll="s_algebraic" class="internal">Algebra of matrices</a></li>
<li><a href="s_invertible_matrices.html" data-scroll="s_invertible_matrices" class="internal">Invertible matrices</a></li>
<li><a href="s_invertibility_theorem.html" data-scroll="s_invertibility_theorem" class="internal">The invertibility theorem</a></li>
<li><a href="s_det.html" data-scroll="s_det" class="internal">The determinant</a></li>
</ul>
</li>
<li class="link">
<a href="c_vectorspace.html" data-scroll="c_vectorspace" class="internal"><span class="codenumber">3</span> <span class="title">Vector spaces and linear transformations</span></a><ul>
<li><a href="s_vectorspace.html" data-scroll="s_vectorspace" class="internal">Real vector spaces</a></li>
<li><a href="s_transformation.html" data-scroll="s_transformation" class="internal">Linear transformations</a></li>
<li><a href="s_subspace.html" data-scroll="s_subspace" class="internal">Subspaces</a></li>
<li><a href="s_nullspace_image.html" data-scroll="s_nullspace_image" class="internal">Null space and image</a></li>
<li><a href="s_span_independence.html" data-scroll="s_span_independence" class="internal">Span and linear independence</a></li>
<li><a href="s_basis.html" data-scroll="s_basis" class="internal">Bases</a></li>
<li><a href="s_dimension.html" data-scroll="s_dimension" class="internal">Dimension</a></li>
<li><a href="s_rank_nullity.html" data-scroll="s_rank_nullity" class="internal">Rank-nullity theorem and fundamental spaces</a></li>
<li><a href="s_isom.html" data-scroll="s_isom" class="internal">Isomorphisms</a></li>
</ul>
</li>
<li class="link">
<a href="c_innerproductspaces.html" data-scroll="c_innerproductspaces" class="internal"><span class="codenumber">4</span> <span class="title">Inner product spaces</span></a><ul>
<li><a href="s_innerproducts.html" data-scroll="s_innerproducts" class="internal">Inner product spaces</a></li>
<li><a href="s_orthogonality.html" data-scroll="s_orthogonality" class="internal">Orthogonal bases</a></li>
<li><a href="s_orthogonal_projection.html" data-scroll="s_orthogonal_projection" class="internal">Orthogonal projection</a></li>
</ul>
</li>
<li class="link">
<a href="c_transbasis.html" data-scroll="c_transbasis" class="internal"><span class="codenumber">5</span> <span class="title">Eigenvectors and diagonalization</span></a><ul>
<li><a href="s_coordinatevectors.html" data-scroll="s_coordinatevectors" class="internal">Coordinate vectors</a></li>
<li><a href="s_matrixreps.html" data-scroll="s_matrixreps" class="internal">Matrix representations of linear transformations</a></li>
<li><a href="s_changeofbasis.html" data-scroll="s_changeofbasis" class="internal">Change of basis</a></li>
<li><a href="s_eigenvectors.html" data-scroll="s_eigenvectors" class="internal">Eigenvectors and eigenvalues</a></li>
<li><a href="s_diagonalization.html" data-scroll="s_diagonalization" class="active">Diagonalization</a></li>
<li><a href="s_spectral_theorem.html" data-scroll="s_spectral_theorem" class="internal">The spectral theorem</a></li>
</ul>
</li>
<li class="link backmatter"><a href="backmatter-1.html" data-scroll="backmatter-1" class="internal"><span class="title">Back Matter</span></a></li>
<li class="link"><a href="appendix-notation.html" data-scroll="appendix-notation" class="internal"><span class="codenumber">A</span> <span class="title">Notation</span></a></li>
<li class="link"><a href="appendix-defs.html" data-scroll="appendix-defs" class="internal"><span class="codenumber">B</span> <span class="title">Definitions</span></a></li>
<li class="link"><a href="appendix-thms.html" data-scroll="appendix-thms" class="internal"><span class="codenumber">C</span> <span class="title">Theory and procedures</span></a></li>
<li class="link"><a href="appendix-egs.html" data-scroll="appendix-egs" class="internal"><span class="codenumber">D</span> <span class="title">Examples</span></a></li>
<li class="link"><a href="appendix-sage.html" data-scroll="appendix-sage" class="internal"><span class="codenumber">E</span> <span class="title">Sage examples</span></a></li>
<li class="link"><a href="appendix-mantras.html" data-scroll="appendix-mantras" class="internal"><span class="codenumber">F</span> <span class="title">Video examples and figures</span></a></li>
<li class="link"><a href="appendix-vids.html" data-scroll="appendix-vids" class="internal"><span class="codenumber">G</span> <span class="title">Mantras and fiats</span></a></li>
<li class="link"><a href="index-1.html" data-scroll="index-1" class="internal"><span class="title">Index</span></a></li>
</ul></nav><div class="extras"><nav><a class="pretext-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content">
<section class="section" id="s_diagonalization"><h2 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber">5.5</span> <span class="title">Diagonalization</span>
</h2>
<section class="introduction" id="introduction-79"><p id="p-3055">Our treatment of eigenvectors in <a href="s_eigenvectors.html" class="internal" title="Section 5.4: Eigenvectors and eigenvalues">Section 5.4</a> was motivated in part by the objective of finding particularly simple matrix representations <span class="process-math">\([T]_B\)</span> of a linear transformation <span class="process-math">\(T\colon V\rightarrow V\text{.}\)</span> The simplest situation we could hope for is that there is a choice of basis <span class="process-math">\(B\)</span> for which <span class="process-math">\([T]_B\)</span> is diagonal. We say that the basis <span class="process-math">\(B\)</span> <em class="emphasis">diagonalizes</em> the transformation <span class="process-math">\(T\)</span> in this case, and that <span class="process-math">\(T\)</span> is <em class="emphasis">diagonalizable</em>. In this section we develop theoretical and computational tools for determining whether a linear transformation <span class="process-math">\(T\)</span> is diagonalizable, and for finding a diagonalizing basis <span class="process-math">\(B\)</span> when <span class="process-math">\(T\)</span> is in fact diagonalizable.</p></section><section class="subsection" id="ss_diagonalizable"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">5.5.1</span> <span class="title">Diagonalizable transformations</span>
</h3>
<article class="definition definition-like" id="d_diagonalizable"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">5.5.1</span><span class="period">.</span><span class="space"> </span><span class="title">Diagonalizable.</span>
</h4>
<p id="p-3056">Let <span class="process-math">\(V\)</span> be a finite-dimensional vector space. A linear transformation <span class="process-math">\(T\colon V\rightarrow V\)</span> is <dfn class="terminology">diagonalizable</dfn> if there exists an ordered basis <span class="process-math">\(B\)</span> of <span class="process-math">\(V\)</span> for which <span class="process-math">\([T]_B\)</span> is a diagonal matrix. In this case, we say the basis <span class="process-math">\(B\)</span> <dfn class="terminology">diagonalizes</dfn> <span class="process-math">\(T\text{.}\)</span></p>
<p id="p-3057">An <span class="process-math">\(n\times n\)</span> matrix <span class="process-math">\(A\)</span> is <dfn class="terminology">diagonalizable</dfn> if the matrix transformation <span class="process-math">\(T_A\colon \R^n\rightarrow \R^n\)</span> is diagonalizable.</p></article><p id="p-3058">As was already laid out in <a href="s_eigenvectors.html" class="internal" title="Section 5.4: Eigenvectors and eigenvalues">Section 5.4</a> a matrix representation <span class="process-math">\([T]_B\)</span> is diagonal if the elements of <span class="process-math">\(B\)</span> are eigenvectors of <span class="process-math">\(T\text{.}\)</span> According to <a href="" class="xref" data-knowl="./knowl/th_diagonalizability_eigenbasis.html" title="Theorem 5.5.2: Diagonalizabilty: basis of eigenvectors">Theorem 5.5.2</a>, the converse is also true.</p>
<article class="theorem theorem-like" id="th_diagonalizability_eigenbasis"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">5.5.2</span><span class="period">.</span><span class="space"> </span><span class="title">Diagonalizabilty: basis of eigenvectors.</span>
</h4>
<p id="p-3059">Let <span class="process-math">\(T\colon V\rightarrow V\)</span> be a linear transformation, and let <span class="process-math">\(B=(\boldv_1, \boldv_2, \dots, \boldv_n)\)</span> be an ordered basis of <span class="process-math">\(V\text{.}\)</span></p>
<ol class="decimal">
<li id="li-998"><p id="p-3060">The matrix <span class="process-math">\([T]_B\)</span> is diagonal if and only if <span class="process-math">\(B\)</span> consists of eigenvectors of <span class="process-math">\(T\text{.}\)</span></p></li>
<li id="li-999"><p id="p-3061">If <span class="process-math">\([T]_B\)</span> is diagonal, then the <span class="process-math">\(j\)</span>-th diagonal entry of <span class="process-math">\([T]_B\)</span> is the eigenvalue <span class="process-math">\(\lambda_j\)</span> associated to the eigenvector <span class="process-math">\(\boldv_j\text{.}\)</span></p></li>
<li id="li-1000"><p id="p-3062">The transformation <span class="process-math">\(T\)</span> is diagonalizable if and only if there is an ordered basis of <span class="process-math">\(V\)</span> consisting of eigenvectors of <span class="process-math">\(T\text{.}\)</span></p></li>
</ol></article><article class="hiddenproof" id="proof-106"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-106"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-106"><article class="hiddenproof"><p id="p-3063">Let <span class="process-math">\(B=(\boldv_1, \boldv_2, \dots, \boldv_n)\)</span> be an ordered basis of <span class="process-math">\(V\text{.}\)</span> The matrix <span class="process-math">\([T]_B\)</span> will be diagonal if and only if for each <span class="process-math">\(1\leq j\leq n\)</span> the <span class="process-math">\(j\)</span>-th column of <span class="process-math">\(A\)</span> is of the form</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/d_matrix_representation.html ./knowl/d_diagonalizable.html">
\begin{equation*}
(0,\dots, \lambda_j,0,\dots, 0)=\lambda_j\bolde_j
\end{equation*}
</div>
<p class="continuation">for some <span class="process-math">\(\lambda_j\text{.}\)</span> By <a href="" class="xref" data-knowl="./knowl/d_matrix_representation.html" title="Definition 5.2.1: Matrix representations of linear transformations">Definition 5.2.1</a> the <span class="process-math">\(j\)</span>-th column of <span class="process-math">\([T]_{B}\)</span> is the coordinate vector <span class="process-math">\([T(\boldv_j)]_{B}\text{.}\)</span> Thus <span class="process-math">\([T]_{B}\)</span> is diagonal if and only if for all <span class="process-math">\(1\leq j\leq n\)</span> we have <span class="process-math">\([T(\boldv_j)]_B=\lambda_j\bolde_j\)</span> for some <span class="process-math">\(\lambda_j\in \R\text{.}\)</span> Next, by definition of <span class="process-math">\([\phantom{v}]_B\text{,}\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/d_matrix_representation.html ./knowl/d_diagonalizable.html">
\begin{equation*}
[T(\boldv_j]_B=(0,\dots, \lambda_j,0,\dots, 0)\iff T(\boldv_j)=\lambda_j\boldv_j\text{.}
\end{equation*}
</div>
<p class="continuation">We conclude that <span class="process-math">\([T]_B\)</span> is diagonal if and only if <span class="process-math">\(\boldv_j\)</span> is an eigenvector of <span class="process-math">\(T\)</span> for all <span class="process-math">\(1\leq j\leq n\text{.}\)</span> Furthermore, when this is the case, we see that the <span class="process-math">\(j\)</span>-th diagonal entry of <span class="process-math">\([T]_B\)</span> is the corresponding eigenvalue <span class="process-math">\(\lambda_j\text{.}\)</span> This proves statements (1) and (2). Statement (3) follows from (1) and <a href="" class="xref" data-knowl="./knowl/d_diagonalizable.html" title="Definition 5.5.1: Diagonalizable">Definition 5.5.1</a>.</p></article></div>
<p id="p-3064">The phrase “an ordered basis consisting of eigenvectors of <span class="process-math">\(T\)</span>” is a bit of a mouthful. The definition below allows us to shorten this to simply “an eigenbasis of <span class="process-math">\(T\)</span>”.</p>
<article class="definition definition-like" id="d_eigenbasis"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">5.5.3</span><span class="period">.</span><span class="space"> </span><span class="title">Eigenbasis.</span>
</h4>
<p id="p-3065">Let <span class="process-math">\(T\colon V\rightarrow V\)</span> be a linear transformation. An ordered basis <span class="process-math">\(B=(\boldv_1, \boldv_2,\dots, \boldv_n)\)</span> is an <dfn class="terminology">eigenbasis</dfn> of <span class="process-math">\(T\)</span> if <span class="process-math">\(\boldv_j\)</span> is an eigenvector of <span class="process-math">\(T\)</span> for all <span class="process-math">\(1\leq j\leq n\text{.}\)</span></p></article><article class="example example-like" id="eg_diagonalizable_matrix"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">5.5.4</span><span class="period">.</span>
</h4>
<p id="p-3066">Let <span class="process-math">\(T=T_A\text{,}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eg_eigenvector_adhoc_reflection.html ./knowl/th_diagonalizability_eigenbasis.html">
\begin{equation*}
A=\frac{1}{5}\begin{amatrix}[rr]-3\amp 4\\ 4\amp 3 \end{amatrix}\text{.}
\end{equation*}
</div>
<p class="continuation">We saw in <a href="" class="xref" data-knowl="./knowl/eg_eigenvector_adhoc_reflection.html" title="Example 5.4.9: Reflection">Example 5.4.9</a> that <span class="process-math">\(\boldv_1=(1,2)\)</span> and <span class="process-math">\(\boldv_2=(-1,2)\)</span> are eigenvectors of <span class="process-math">\(T\)</span> with eigenvalues <span class="process-math">\(1, -1\text{,}\)</span> respectively. It is clear that the two eigenvectors are linearly independent, and hence that <span class="process-math">\(B'=(\boldv_1, \boldv_2)\)</span> is an eigenbasis of <span class="process-math">\(T\text{.}\)</span> It follows from <a href="" class="xref" data-knowl="./knowl/th_diagonalizability_eigenbasis.html" title="Theorem 5.5.2: Diagonalizabilty: basis of eigenvectors">Theorem 5.5.2</a> that <span class="process-math">\(T\)</span> is diagonalizable, and that in fact</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eg_eigenvector_adhoc_reflection.html ./knowl/th_diagonalizability_eigenbasis.html">
\begin{equation*}
[T]_{B'}=\begin{amatrix}[rr] 1\amp 0\\ 0\amp -1 \end{amatrix}\text{,}
\end{equation*}
</div>
<p class="continuation">as one easily verifies.</p></article><article class="example example-like" id="example-122"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">5.5.5</span><span class="period">.</span>
</h4>
<p id="p-3067">Let <span class="process-math">\(T\colon \R^2\rightarrow \R^2\)</span> be rotation by <span class="process-math">\(\pi/4\text{:}\)</span> i.e., <span class="process-math">\(T=T_A\text{,}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eg_eigenvector_adhoc_rotation.html">
\begin{equation*}
A=\frac{1}{2}\begin{amatrix}[rr]\sqrt{2}\amp -\sqrt{2}\\ \sqrt{2}\amp \sqrt{2} \end{amatrix}\text{.}
\end{equation*}
</div>
<p class="continuation">As discussed in <a href="" class="xref" data-knowl="./knowl/eg_eigenvector_adhoc_rotation.html" title="Example 5.4.10: Rotation">Example 5.4.10</a>, <span class="process-math">\(T\)</span> has no eigenvectors whatsoever. It follows that there is no eigenbasis of <span class="process-math">\(T\text{,}\)</span> and hence that <span class="process-math">\(T\)</span> is not diagonalizable.</p></article><article class="example example-like" id="example-123"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">5.5.6</span><span class="period">.</span>
</h4>
<p id="p-3068">Let <span class="process-math">\(T=T_A\text{,}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A=\begin{amatrix}[rr] 2\amp 1\\ 0\amp 2 \end{amatrix}\text{.}
\end{equation*}
</div>
<p class="continuation">As is easily computed, <span class="process-math">\(\lambda=2\)</span> is the only eigenvalue of <span class="process-math">\(T\text{,}\)</span> and <span class="process-math">\(W_2=\Span\{(1,0)\}\text{.}\)</span> It follows that <em class="emphasis">any two</em> eigenvectors <span class="process-math">\(\boldv_1\)</span> and <span class="process-math">\(\boldv_2\)</span> lie in the one-dimensional space <span class="process-math">\(W_2\text{,}\)</span> and hence are scalar multiples of one another. Thus we cannot find two linearly independent eigenvectors of <span class="process-math">\(T\text{.}\)</span> We conclude that <span class="process-math">\(T\)</span> does not have an eigenbasis, and hence is not diagonalizable.</p></article></section><section class="subsection" id="ss_diagonalizable_independent_eigenvectors"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">5.5.2</span> <span class="title">Linear independence of eigenvectors</span>
</h3>
<p id="p-3069">Roughly put, <a href="" class="xref" data-knowl="./knowl/th_diagonalizability_eigenbasis.html" title="Theorem 5.5.2: Diagonalizabilty: basis of eigenvectors">Theorem 5.5.2</a> tells us that <span class="process-math">\(T\)</span> is diagonalizable if it has “enough” eigenvectors: more precisely, if we can find a large enough collection of <em class="emphasis">linearly independent</em> eigenvectors. So when exactly can we do this? Our first examples were deceptively simple in this regard due to their low-dimensional setting. For transformations of higher-dimensional spaces we need more theory, which we now develop. <a href="" class="xref" data-knowl="./knowl/th_independent_eigenvectors.html" title="Theorem 5.5.7: Linear independence of eigenvectors">Theorem 5.5.7</a> will serve as one of the key results for our purposes. It tells us that eigenvectors chosen from different eigenspaces are linearly independent.</p>
<article class="theorem theorem-like" id="th_independent_eigenvectors"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">5.5.7</span><span class="period">.</span><span class="space"> </span><span class="title">Linear independence of eigenvectors.</span>
</h4>
<p id="p-3070">Let <span class="process-math">\(T\colon V\rightarrow V\)</span> be a linear transformation, and let <span class="process-math">\(S=\{\boldv_1,\dots, \boldv_r\}\)</span> be a set of eigenvectors of <span class="process-math">\(T\)</span> satisfying <span class="process-math">\(T\boldv_i=\lambda_i\boldv_i\text{.}\)</span> If the eigenvalues <span class="process-math">\(\lambda_i\)</span> are distinct (i.e., <span class="process-math">\(\lambda_i\ne \lambda_j\)</span>  for <span class="process-math">\(i\ne j\)</span>), then <span class="process-math">\(S\)</span> is linearly independent.</p></article><article class="hiddenproof" id="proof-107"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-107"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-107"><article class="hiddenproof"><p id="p-3071">We prove the result by contradiction. Suppose we can find a finite set of eigenvectors with distinct eigenvalues that is linearly dependent. It follows that we can find such a set of <em class="emphasis">minimum cardinality</em>. In other words, there is positive integer <span class="process-math">\(r\)</span> satisfying the following properties: (i) we can find a linearly dependent set of <span class="process-math">\(r\)</span> eigenvectors of <span class="process-math">\(T\)</span> with distinct eigenvalues; (ii) for all <span class="process-math">\(k\lt r\text{,}\)</span> any set of <span class="process-math">\(k\)</span> eigenvectors of <span class="process-math">\(T\)</span> with distinct eigenvalues is linearly independent<a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-6" id="fn-6"><sup> 1 </sup></a>.</p>
<p id="p-3072">Now assume <span class="process-math">\(S=\{\boldv_1, \boldv_2, \dots, \boldv_r\}\)</span> is a set of minimal cardinality satisfying <span class="process-math">\(T(\boldv_i)=\lambda_i\boldv_i\)</span> for all <span class="process-math">\(1\leq i\leq n\)</span> and <span class="process-math">\(\lambda_i\ne \lambda j\)</span> for all <span class="process-math">\(1\leq i\lt j\leq n\text{.}\)</span> First observe that we must have <span class="process-math">\(r\gt 1\text{:}\)</span> eigenvectors are nonzero by definition, and thus any set consisting of a single eigenvector is linearly independent. Next, since <span class="process-math">\(S\)</span> is linearly dependent we have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_independent_eigenvectors_A.html ./knowl/eq_independent_eigenvectors_A.html ./knowl/eq_independent_eigenvectors_B.html ./knowl/eq_independent_eigenvectors_C.html" id="eq_independent_eigenvectors_A">
\begin{equation}
c_1\boldv_1+c_2\boldv_2+\cdots +c_r\boldv_r=\boldzero\text{,}\tag{5.5.1}
\end{equation}
</div>
<p class="continuation">where <span class="process-math">\(c_i\ne 0\)</span> for some <span class="process-math">\(1\leq i\leq r\text{.}\)</span> After reordering, we may assume without loss of generality that <span class="process-math">\(c_1\ne 0\text{.}\)</span> Next we apply <span class="process-math">\(T\)</span> to both sides of <a href="" class="xref" data-knowl="./knowl/eq_independent_eigenvectors_A.html" title="Equation 5.5.1">(5.5.1)</a>:</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_independent_eigenvectors_A.html ./knowl/eq_independent_eigenvectors_A.html ./knowl/eq_independent_eigenvectors_B.html ./knowl/eq_independent_eigenvectors_C.html" id="mdn-8">
\begin{align}
c_1\boldv_1+c_2\boldv_2\cdots +c_r\boldv_r=\boldzero \amp\implies T(c_1\boldv_1+c_2\boldv_2+\cdots +c_r\boldv_r)=T(\boldzero) \tag{5.5.2}\\
\amp\implies c_1T(\boldv_1)+c_2T(\boldv_2)+\cdots +c_rT(\boldv_r)=\boldzero \tag{5.5.3}\\
\amp\implies c_1\lambda_1\boldv_1+c_2\lambda_2\boldv_2+\cdots +c_r\lambda_r\boldv_r=\boldzero \text{.}\tag{5.5.4}
\end{align}
</div>
<p class="continuation">From equation <a href="" class="xref" data-knowl="./knowl/eq_independent_eigenvectors_A.html" title="Equation 5.5.1">(5.5.1)</a> and the equation in <a href="" class="xref" data-knowl="./knowl/eq_independent_eigenvectors_B.html" title="Equation 5.5.4">(5.5.4)</a> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_independent_eigenvectors_A.html ./knowl/eq_independent_eigenvectors_A.html ./knowl/eq_independent_eigenvectors_B.html ./knowl/eq_independent_eigenvectors_C.html">
\begin{equation*}
\lambda_r(c_1\boldv_1+c_2\boldv_2\cdots +c_r\boldv_r)- (c_1\lambda_1\boldv_1+c_2\lambda_2\boldv_2\cdots +c_r\lambda_r\boldv_r)=\boldzero\text{,}
\end{equation*}
</div>
<p class="continuation">and hence</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_independent_eigenvectors_A.html ./knowl/eq_independent_eigenvectors_A.html ./knowl/eq_independent_eigenvectors_B.html ./knowl/eq_independent_eigenvectors_C.html" id="eq_independent_eigenvectors_C">
\begin{equation}
c_1(\lambda_r-\lambda_1)\boldv_1+\cdots +c_{r-1}(\lambda_r-\lambda_{r-1})+\cancel{c_r(\lambda_r-\lambda_r)}\boldv_r=\boldzero\text{.}\tag{5.5.5}
\end{equation}
</div>
<p class="continuation">Since <span class="process-math">\(c_1\ne 0\)</span> and <span class="process-math">\(\lambda_1\ne \lambda_r\text{,}\)</span> we have <span class="process-math">\(c_1(\lambda_r-\lambda_1)\ne 0\text{.}\)</span> Thus equation <a href="" class="xref" data-knowl="./knowl/eq_independent_eigenvectors_C.html" title="Equation 5.5.5">(5.5.5)</a> implies that the set <span class="process-math">\(S'=\{\boldv_1, \boldv_2, \dots, \boldv_{r-1}\}\)</span> is a linearly dependent set of eigenvectors of <span class="process-math">\(T\)</span> with distinct eigenvalues, contradicting the minimality of <span class="process-math">\(r\text{.}\)</span> This completes our proof by contradiction.</p></article></div>
<article class="corollary theorem-like" id="cor_independent_eigenvectors"><h4 class="heading">
<span class="type">Corollary</span><span class="space"> </span><span class="codenumber">5.5.8</span><span class="period">.</span><span class="space"> </span><span class="title">Diagonalizable if distinct eigenvalues.</span>
</h4>
<p id="p-3073">Let <span class="process-math">\(T\colon V\rightarrow V\)</span> be a linear transformation, and suppose <span class="process-math">\(\dim V=n\text{.}\)</span> If <span class="process-math">\(T\)</span> has <span class="process-math">\(n\)</span> distinct eigenvalues, then <span class="process-math">\(T\)</span> is diagonalizable.</p></article><article class="hiddenproof" id="proof-108"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-108"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-108"><article class="hiddenproof"><p id="p-3074">Let <span class="process-math">\(S=\{\boldv_1, \boldv_2,\dots, \boldv_n\}\)</span> be a set eigenvectors of <span class="process-math">\(T\)</span> with distinct eigenvalues. According to <a href="" class="xref" data-knowl="./knowl/th_independent_eigenvectors.html" title="Theorem 5.5.7: Linear independence of eigenvectors">Theorem 5.5.7</a>  the set <span class="process-math">\(S\)</span> is linearly independent. Since <span class="process-math">\(\val{S}=n=\dim V\)</span> it follows that <span class="process-math">\(B=(\boldv_1,\boldv_2,\dots, \boldv_n)\)</span> is an eigenbasis for <span class="process-math">\(T\)</span> and hence <span class="process-math">\(T\)</span> is diagonalizable.</p></article></div>
<article class="example example-like" id="example-124"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">5.5.9</span><span class="period">.</span>
</h4>
<p id="p-3075">Let <span class="process-math">\(T=T_A\text{,}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A=\begin{amatrix}[rrr]
6 \amp 6 \amp -2 \\
-8 \amp -13 \amp 7 \\
-8 \amp -16 \amp 10
\end{amatrix}\text{.}
\end{equation*}
</div>
<p class="continuation">The characteristic polynomial of <span class="process-math">\(A\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
p(t)=t^{3} - 3 t^{2} - 4 t + 12=(t+2)(t-2)(t-3)\text{.}
\end{equation*}
</div>
<p class="continuation">Since <span class="process-math">\(A\)</span> has three distinct eigenvalues the linear transformation <span class="process-math">\(T_A\)</span> is diagonalizable. Indeed, any choice of eigenvectors <span class="process-math">\(\boldv_1, \boldv_2, \boldv_3\)</span> with <span class="process-math">\(\boldv_1\in W_{-2}, \boldv_2\in W_2, \boldv_3\in W_3\)</span> is guaranteed to be linearly independent, and hence gives rise to an eigenbasis <span class="process-math">\(B=(\boldv_1, \boldv_2, \boldv_3)\)</span> of <span class="process-math">\(T_A\text{.}\)</span> For example the usual procedure allows us to easily find eigenvectors</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\boldv_1=(1,-2,-2), \boldv_2=(1,-1,-1),\boldv_3=(2,-1,0)
\end{equation*}
</div>
<p class="continuation">from the three eigenspaces. You can verify for yourself that these three vectors are indeed linearly independent.</p></article><article class="remark remark-like" id="rm_independent_eigenvectors"><h4 class="heading">
<span class="type">Remark</span><span class="space"> </span><span class="codenumber">5.5.10</span><span class="period">.</span>
</h4>
<p id="p-3076">Let <span class="process-math">\(T\colon V\rightarrow V\)</span> be a linear transformation, <span class="process-math">\(\dim V=n\text{.}\)</span> It cannot be stressed enough that having <span class="process-math">\(n\)</span> distinct eigenvalues is a <em class="emphasis">sufficient</em>, but not <em class="emphasis">necessary</em> condition for <span class="process-math">\(T\)</span> to be diagonalizable. In other words we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
T \text{ has  distinct eigenvalues} \implies T \text{ diagonalizable}
\end{equation*}
</div>
<p class="continuation">but</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
T \text{ diagonalizable }\;\not\!\!\!\!\!\implies T \text{ has  distinct eigenvalues}\text{.}
\end{equation*}
</div>
<p class="continuation">A good counterexample to keep in mind is <span class="process-math">\(T_I\colon \R^n\rightarrow \R^n\text{,}\)</span> where <span class="process-math">\(I=I_n\)</span> is the <span class="process-math">\(n\times n\)</span> identity matrix. The transformation is clearly diagonalizable since <span class="process-math">\([T]_B=I\text{,}\)</span> where <span class="process-math">\(B=(\bolde_1, \bolde_2,\dots, \bolde_n)\)</span> is the standard basis; and yet <span class="process-math">\(\lambda=1\)</span> is the only eigenvalue of <span class="process-math">\(T\text{.}\)</span></p></article><p id="p-3077"><a href="" class="xref" data-knowl="./knowl/th_independent_eigenvectors.html" title="Theorem 5.5.7: Linear independence of eigenvectors">Theorem 5.5.7</a> makes no assumption about the dimension of <span class="process-math">\(V\)</span> and can thus can be applied to linear transformations of infinite-dimensional spaces. The differential operator <span class="process-math">\(T(f)=f'\)</span> provides an interesting example.</p>
<article class="example example-like" id="example-125"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">5.5.11</span><span class="period">.</span>
</h4>
<p id="p-3078">Let <span class="process-math">\(V=C^\infty(\R)\text{,}\)</span> and let <span class="process-math">\(T\colon V\rightarrow V\)</span> be defined as <span class="process-math">\(T(f)=f'\text{.}\)</span> For each <span class="process-math">\(\lambda\in \R\)</span> let <span class="process-math">\(f_{\lambda}(x)=e^{\lambda x}\text{.}\)</span> In <a href="" class="xref" data-knowl="./knowl/eg_eigenvectors_adhoc_derivative.html" title="Example 5.4.12: Differentiation">Example 5.4.12</a> we saw that the functions <span class="process-math">\(f_\lambda\)</span> are eigenvectors of <span class="process-math">\(T\)</span> with eigenvalue <span class="process-math">\(\lambda\text{:}\)</span> i.e., <span class="process-math">\(T(f_\lambda)=\lambda f_\lambda\text{.}\)</span> It follows from <a href="" class="xref" data-knowl="./knowl/cor_independent_eigenvectors.html" title="Corollary 5.5.8: Diagonalizable if distinct eigenvalues">Corollary 5.5.8</a> that for any distinct values <span class="process-math">\(\lambda_1, \lambda_2, \dots, \lambda_r\)</span> the set <span class="process-math">\(\{e^{\lambda_1x}, e^{\lambda_2x}, \dots, e^{\lambda_rx}\}\)</span> is linearly independent, and thus that the (uncountably) infinite set  <span class="process-math">\(S=\{e^{\lambda x}\colon \lambda\in \R\}\subseteq C^{\infty}(\R)\)</span> is linearly independent.</p></article><p id="p-3079">The next corollary is a useful strengthening of <a href="" class="xref" data-knowl="./knowl/th_independent_eigenvectors.html" title="Theorem 5.5.7: Linear independence of eigenvectors">Theorem 5.5.7</a>, and will be used to prove <a href="" class="xref" data-knowl="./knowl/th_diagonalizability_eigenspaces.html" title="Theorem 5.5.13: Diagonalizability: dimension of eigenspaces">Theorem 5.5.13</a>. Roughly speaking, it says that eigenspaces associated to distinct eigenvalues are “linearly independent”. Be careful: the phrase in quotes currently has no real meaning for us. We know what it means for <em class="emphasis">vectors</em> to be linearly independent, but not <em class="emphasis">subspaces</em>. However, it is a decent shorthand for the precise statement of <a href="" class="xref" data-knowl="./knowl/cor_independent_eigenspaces.html" title="Corollary 5.5.12">Corollary 5.5.12</a>.</p>
<article class="corollary theorem-like" id="cor_independent_eigenspaces"><h4 class="heading">
<span class="type">Corollary</span><span class="space"> </span><span class="codenumber">5.5.12</span><span class="period">.</span>
</h4>
<p id="p-3080">Let <span class="process-math">\(T\colon V\rightarrow V\)</span> be a linear transformation, where <span class="process-math">\(\dim V=n\text{.}\)</span> Let <span class="process-math">\(\lambda_1, \lambda_2, \dots, \lambda_r\)</span> be distinct eigenvalues of <span class="process-math">\(T\text{,}\)</span> and for each <span class="process-math">\(1\leq i\leq r\)</span> let <span class="process-math">\(W_{\lambda_i}\)</span> be the <span class="process-math">\(\lambda_i\)</span>-eigenspace. If</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_independent_eigenspaces">
\begin{equation}
\boldw_1+\boldw_2+\cdots +\boldw_r=\boldzero\text{,}\tag{5.5.6}
\end{equation}
</div>
<p class="continuation">where <span class="process-math">\(\boldw_i\in W_{\lambda_i}\text{,}\)</span> then <span class="process-math">\(\boldw_i=\boldzero\)</span> for all <span class="process-math">\(i\text{.}\)</span></p></article><article class="hiddenproof" id="proof-109"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-109"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-109"><article class="hiddenproof"><p id="p-3081">Before proving the result, we point out one subtlety here: although the <span class="process-math">\(\boldw_i\in W_{\lambda_i}\)</span> for all <span class="process-math">\(i\text{,}\)</span> we cannot assume that each <span class="process-math">\(\boldw_i\)</span> is an eigenvector. Indeed, <span class="process-math">\(\boldw_i\)</span> is an eigenvector in this case if and only if <span class="process-math">\(\boldw_i\ne 0\text{.}\)</span> This observation guides the proof that follows.</p>
<p id="p-3082">To pick out the terms of <a href="" class="xref" data-knowl="./knowl/eq_independent_eigenspaces.html" title="Equation 5.5.6">(5.5.6)</a> that are nonzero (if any), we define</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_independent_eigenspaces.html ./knowl/th_independent_eigenvectors.html">
\begin{equation*}
J=\{j \colon \boldw_j\ne 0\}=\{j_1, j_2,\dots, j_k\}\text{.}
\end{equation*}
</div>
<p class="continuation">Assume by contradiction that <span class="process-math">\(J\)</span> is nonempty: i.e., <span class="process-math">\(\val{J}=k\geq 1\text{.}\)</span> In this case we would have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_independent_eigenspaces.html ./knowl/th_independent_eigenvectors.html" id="md-256">
\begin{align*}
\boldzero \amp= \boldw_1+\boldw_2+\cdots \boldw_r \\
\amp = \boldw_{j_1}+\boldw_{j_2}+\cdots +\boldw_{j_k} \text{,}
\end{align*}
</div>
<p class="continuation">since <span class="process-math">\(\boldw_i=\boldzero\)</span> for all <span class="process-math">\(i\notin J\text{.}\)</span> But then</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_independent_eigenspaces.html ./knowl/th_independent_eigenvectors.html">
\begin{equation*}
\boldw_{j_1}+\boldw_{j_2}+\cdots +\boldw_{j_k}=\boldzero
\end{equation*}
</div>
<p class="continuation">would be a nontrivial linear combination of the eigenvectors <span class="process-math">\(\boldw_{j_i}\)</span> equal to <span class="process-math">\(\boldzero\text{.}\)</span> Since the eigenvectors <span class="process-math">\(\boldw_{j_i}\)</span> have distinct eigenvalues, this contradicts <a href="" class="xref" data-knowl="./knowl/th_independent_eigenvectors.html" title="Theorem 5.5.7: Linear independence of eigenvectors">Theorem 5.5.7</a>. Thus <span class="process-math">\(J=\{\, \}\text{.}\)</span> Equivalently, <span class="process-math">\(\boldw_i=\boldzero\)</span> for all <span class="process-math">\(1\leq i\leq r\text{,}\)</span> as desired.</p></article></div>
<p id="p-3083">At last we are ready to state and prove what will be our main tool for determining whether a linear transformation is diagonalizable.</p>
<article class="theorem theorem-like" id="th_diagonalizability_eigenspaces"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">5.5.13</span><span class="period">.</span><span class="space"> </span><span class="title">Diagonalizability: dimension of eigenspaces.</span>
</h4>
<p id="p-3084">Let <span class="process-math">\(T\colon V\rightarrow V\)</span> be a linear transformation, where <span class="process-math">\(\dim V=n\text{.}\)</span> Let <span class="process-math">\(\lambda_1, \lambda_2, \dots, \lambda_r\)</span> be the distinct eigenvalues of <span class="process-math">\(T\text{,}\)</span> and for each <span class="process-math">\(1\leq i\leq r\text{,}\)</span> let <span class="process-math">\(W_{\lambda_i}\)</span> be the <span class="process-math">\(\lambda_i\)</span>-eigenspace. We have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
T \text{ is diagonalizable } \iff \sum_{i=1}^r\dim W_{\lambda_i}=n\text{.}
\end{equation*}
</div></article><article class="hiddenproof" id="proof-110"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-110"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-110"><article class="hiddenproof">We prove the two implications separately. In each we use the equivalence<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_diagonalizability_eigenbasis.html ./knowl/th_diagonalizability_eigenbasis.html ./knowl/cor_independent_eigenspaces.html ./knowl/cor_independent_eigenspaces.html">
\begin{equation*}
T \text{ is diagonalizable} \iff T \text{ has an eigenbasis } B\text{,}
\end{equation*}
</div>proved in <a href="" class="xref" data-knowl="./knowl/th_diagonalizability_eigenbasis.html" title="Theorem 5.5.2: Diagonalizabilty: basis of eigenvectors">Theorem 5.5.2</a>. <article class="hiddenproof" id="proof-111"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-111"><h5 class="heading"><span class="title">Proof: <span class="process-math">\(T\)</span> diagonalizable <span class="process-math">\(\implies \sum_{i=1}^r\dim W_{\lambda_i}=n\)</span>.</span></h5></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-111"><article class="hiddenproof"><p id="p-3085">Assume <span class="process-math">\(T\)</span> is diagonalizable. From <a href="" class="xref" data-knowl="./knowl/th_diagonalizability_eigenbasis.html" title="Theorem 5.5.2: Diagonalizabilty: basis of eigenvectors">Theorem 5.5.2</a>, there is an eigenbasis <span class="process-math">\(B\)</span> of <span class="process-math">\(T\text{.}\)</span> After reordering we may assume that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_diagonalizability_eigenbasis.html ./knowl/cor_independent_eigenspaces.html">
\begin{equation*}
B=(\underset{W_{\lambda_1}}{\underbrace{\boldv_{\lambda_1,1},\dots, \boldv_{\lambda_1,n_1}}},\underset{W_{\lambda_2}}{\underbrace{\boldv_{\lambda_2,1},\dots, \boldv_{\lambda_2,n_2}}},\dots, \underset{W_{\lambda_r}}{\underbrace{\boldv_{\lambda_r,1},\dots, \boldv_{\lambda_r,n_r}}} )\text{,}
\end{equation*}
</div>
<p class="continuation">where for each <span class="process-math">\(1\leq i\leq r\)</span> and each <span class="process-math">\(1\leq j\leq n_i\text{,}\)</span> the element <span class="process-math">\(\boldv_{\lambda_i,j}\)</span> is an eigenvector with eigenvalue <span class="process-math">\(\lambda_i\text{:}\)</span> i.e., <span class="process-math">\(\boldv_{\lambda_i,j}\in W_{\lambda_i}\text{.}\)</span> Observer that since <span class="process-math">\(B\)</span> is a list of <span class="process-math">\(n\)</span> vectors, we have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_diagonalizability_eigenbasis.html ./knowl/cor_independent_eigenspaces.html">
\begin{equation*}
n=n_1+n_2+\cdots+n_r\text{.}
\end{equation*}
</div>
<p class="continuation">We claim that for all <span class="process-math">\(1\leq i\leq r\)</span> the set <span class="process-math">\(S_{\lambda_i}=\{\boldv_{\lambda_i, 1}, \dots, \boldv_{\lambda_i, n_i}\}\)</span> is a basis of <span class="process-math">\(W_{\lambda_i}\text{.}\)</span> The desired result follows in this case since</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_diagonalizability_eigenbasis.html ./knowl/cor_independent_eigenspaces.html" id="md-257">
\begin{align*}
\sum_{i=1}^r\dim W_{\lambda_i} \amp=\sum_{i=1}^r\val{S_{\lambda_i}} \\
\amp = \sum_{i=1}^r n_i \\
\amp = n\text{.}
\end{align*}
</div>
<p class="continuation">Proceeding then to the claim, observe that each set <span class="process-math">\(S_{\lambda_i}\)</span> is linearly independent, since the underlying set of <span class="process-math">\(B\)</span> is linearly independent. Thus it suffices to show that <span class="process-math">\(\Span S_{\lambda_i}=W_{\lambda_i}\)</span> for all <span class="process-math">\(1\leq i\leq r\text{.}\)</span> To this end, fix an <span class="process-math">\(i\)</span> with <span class="process-math">\(1\leq i\leq n\)</span> and take any <span class="process-math">\(\boldv\in W_{\lambda_i}\text{.}\)</span> Since <span class="process-math">\(B\)</span> is a basis we can write</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_diagonalizability_eigenbasis.html ./knowl/cor_independent_eigenspaces.html" id="md-258">
\begin{align*}
\boldv \amp=
\underset{\boldw_{\lambda_1}}{\underbrace{\sum_{j=1}^{n_1}c_{1,j}\boldv_{\lambda_1, j}}}+\dots +\underset{\boldw_{\lambda_i}}{\underbrace{\sum_{j=1}^{n_i}c_{i,j}\boldv_{\lambda_i, j}}}+\dots \underset{\boldw_{\lambda_r}}{\underbrace{\sum_{j=1}^{n_r}c_{r,j}\boldv_{\lambda_r, j}}} \\
\amp=\boldw_1+\boldw_2+\cdots +\boldw_r \text{,}
\end{align*}
</div>
<p class="continuation">where for each <span class="process-math">\(1\leq k\leq r\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_diagonalizability_eigenbasis.html ./knowl/cor_independent_eigenspaces.html">
\begin{equation*}
\boldw_k=\sum_{i=1}^{n_k}c_{k,j}\boldv_{\lambda_k, j}\in W_{\lambda_k}\text{.}
\end{equation*}
</div>
<p class="continuation">Bringing <span class="process-math">\(\boldv\)</span> to the right-hand side of the equation above yields</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_diagonalizability_eigenbasis.html ./knowl/cor_independent_eigenspaces.html">
\begin{equation*}
\boldzero=\boldw_1+\boldw_2+\cdots +(\boldw_i-\boldv)+\cdots +\boldw_r\text{.}
\end{equation*}
</div>
<p class="continuation">Recall that <span class="process-math">\(\boldv\in W_{\lambda_i}\text{,}\)</span> and thus <span class="process-math">\(\boldw_{i}-\boldv\in W){\lambda_i}\text{.}\)</span> Since <span class="process-math">\(\boldw_k\in W_{\lambda_k}\)</span> for all <span class="process-math">\(k\ne i\text{,}\)</span> it follows from <a href="" class="xref" data-knowl="./knowl/cor_independent_eigenspaces.html" title="Corollary 5.5.12">Corollary 5.5.12</a> that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_diagonalizability_eigenbasis.html ./knowl/cor_independent_eigenspaces.html">
\begin{equation*}
\boldw_1=\boldw_2=\dots=(\boldw_i-\boldv)=\dots =\boldw_r=0\text{.}
\end{equation*}
</div>
<p class="continuation">Thus</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_diagonalizability_eigenbasis.html ./knowl/cor_independent_eigenspaces.html">
\begin{equation*}
\boldv=w_i=\sum_{j=1}^{n_i}c_{i,j}\boldv_{\lambda_i, j}\text{,}
\end{equation*}
</div>
<p class="continuation">showing that <span class="process-math">\(\boldv\in \Span S_{\lambda_i}\text{,}\)</span> as desired.</p></article></div>
<article class="hiddenproof" id="proof-112"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-112"><h5 class="heading"><span class="title">Proof: <span class="process-math">\(\sum_{i=1}^r\dim W_{\lambda_i}=n\implies T\)</span> is diagonalizable.</span></h5></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-112"><article class="hiddenproof"><p id="p-3086">Let <span class="process-math">\(n_i=\dim W_{\lambda_i}\)</span>  for all <span class="process-math">\(1\leq i\leq r\)</span> . We assume that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/cor_independent_eigenspaces.html">
\begin{equation*}
n=\dim W_{\lambda_1}+
\dim W_{\lambda_2}+\cdots \dim W_{\lambda_r}=n_1+n_2+\cdots +n_r\text{.}
\end{equation*}
</div>
<p class="continuation">For each <span class="process-math">\(1\leq i\leq n\text{,}\)</span> let</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/cor_independent_eigenspaces.html">
\begin{equation*}
S_{\lambda_i}=\{\boldv_{\lambda_i, 1}, \boldv_{\lambda_i,2},\dots, \boldv_{\lambda_{i,n_i}}\}
\end{equation*}
</div>
<p class="continuation">be a basis of the eigenspace <span class="process-math">\(W_{\lambda_i}\text{.}\)</span> We claim</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/cor_independent_eigenspaces.html">
\begin{equation*}
B=(\underset{W_{\lambda_1}}{\underbrace{\boldv_{\lambda_1,1},\dots, \boldv_{\lambda_1,n_1}}},\underset{W_{\lambda_2}}{\underbrace{\boldv_{\lambda_2,1},\dots, \boldv_{\lambda_2,n_2}}},\dots, \underset{W_{\lambda_r}}{\underbrace{\boldv_{\lambda_r,1},\dots, \boldv_{\lambda_r,n_r}}} )
\end{equation*}
</div>
<p class="continuation">is an eigenbasis of <span class="process-math">\(T\text{.}\)</span> Since <span class="process-math">\(\boldzero\ne \boldv_{\lambda_i, j}\in W_{\lambda_i}\)</span> for all <span class="process-math">\(1\leq i\leq r\)</span> and <span class="process-math">\(1\leq j\leq n_i\text{,}\)</span> we see that <span class="process-math">\(B\)</span> consists of eigenvectors of <span class="process-math">\(T\text{.}\)</span> Since</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/cor_independent_eigenspaces.html">
\begin{equation*}
n_1+n_2+\cdots n_r=n=\dim V\text{,}
\end{equation*}
</div>
<p class="continuation">to show that <span class="process-math">\(B\)</span> is a basis it suffices to show that it is linearly independent. To this end, assume we have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/cor_independent_eigenspaces.html" id="md-259">
\begin{align*}
\boldzero \amp=
\underset{\boldw_{\lambda_1}}{\underbrace{\sum_{j=1}^{n_1}c_{1,j}\boldv_{\lambda_1, j}}} +\underset{\boldw_{\lambda_2}}{\underbrace{\sum_{j=1}^{n_2}c_{2,j}\boldv_{\lambda_2, j}}}+\dots \underset{\boldw_{\lambda_r}}{\underbrace{\sum_{j=1}^{n_r}c_{r,j}\boldv_{\lambda_r, j}}} \\
\amp=\boldw_1+\boldw_2+\cdots +\boldw_r \text{,}
\end{align*}
</div>
<p class="continuation">where for each <span class="process-math">\(1\leq i\leq r\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/cor_independent_eigenspaces.html">
\begin{equation*}
\boldw_i=\sum_{i=1}^{n_i}c_{i,j}\boldv_{\lambda_i, j}\in W_{\lambda_k}\text{.}
\end{equation*}
</div>
<p class="continuation">By <a href="" class="xref" data-knowl="./knowl/cor_independent_eigenspaces.html" title="Corollary 5.5.12">Corollary 5.5.12</a> we must have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/cor_independent_eigenspaces.html">
\begin{equation*}
\boldzero=\boldw_i=\sum_{i=1}^{n_i}c_{i,j}\boldv_{\lambda_i, j}
\end{equation*}
</div>
<p class="continuation">for all <span class="process-math">\(i\text{.}\)</span> Finally, since the set</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/cor_independent_eigenspaces.html">
\begin{equation*}
S_{\lambda_i}=\{\boldv_{\lambda_i, 1}, \boldv_{\lambda_i,2},\dots, \boldv_{\lambda_{i,n_i}}\}
\end{equation*}
</div>
<p class="continuation">is linearly independent for each <span class="process-math">\(i\text{,}\)</span> we must have <span class="process-math">\(c_{i,j}=0\)</span> for all <span class="process-math">\(1\leq i\leq r\)</span> and <span class="process-math">\(1\leq j\leq n_i\text{.}\)</span> This proves that <span class="process-math">\(B\)</span> is linearly independent, hence a basis.</p></article></div></article></div>
<p id="p-3087">We now collect our various results about diagonalizability into one procedure that (a) decides whether a linear transformation <span class="process-math">\(T\)</span> is diagonalizable, and (b) if it is, computes an eigenbasis for <span class="process-math">\(T\text{.}\)</span> The procedure applies to any linear transformation of a finite-dimensional vector space, not just matrix transformations. As usual, the first step is to choose a matrix representation <span class="process-math">\(A=[T]_B\)</span> for <span class="process-math">\(T\text{.}\)</span></p>
<article class="algorithm theorem-like" id="proc_diagonalize"><h4 class="heading">
<span class="type">Procedure</span><span class="space"> </span><span class="codenumber">5.5.14</span><span class="period">.</span><span class="space"> </span><span class="title">Deciding whether a linear transformation is diagonalizable.</span>
</h4>
<p id="p-3088">Let <span class="process-math">\(T\colon V\rightarrow V\)</span> be a linear transformation, where <span class="process-math">\(\dim V=n\text{.}\)</span> To decide whether <span class="process-math">\(T\)</span> is diagonalizable proceed as follows.</p>
<ol class="decimal">
<li id="li-1001"><p id="p-3089">Pick any ordered basis <span class="process-math">\(B\)</span> of <span class="process-math">\(V\)</span> and compute <span class="process-math">\(A=[T]_B\text{.}\)</span> We have <span class="process-math">\(T\)</span> diagonalizable if and only if <span class="process-math">\(A\)</span> diagonalizable.</p></li>
<li id="li-1002">
<p id="p-3090">Let <span class="process-math">\(\lambda_1, \lambda_2, \dots, \lambda_r\)</span> be the distinct eigenvalues of <span class="process-math">\(A\text{.}\)</span> Compute <span class="process-math">\(n_i=\dim W_{\lambda_i}\)</span> for each <span class="process-math">\(1\leq i\leq r\text{.}\)</span> We have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A \text{ diagonalizable }\iff \sum_{i=1}^r\dim W_{\lambda_i}=n\text{.}
\end{equation*}
</div>
</li>
<li id="li-1003">
<p id="p-3091">Assume <span class="process-math">\(A\)</span> is diagonalizable according to Step (2). For each <span class="process-math">\(1\leq i\leq r\)</span> compute a basis <span class="process-math">\(S_{\lambda_i}=\{\boldv_{\lambda_i, 1}, \boldv_{\lambda_i,2},\dots, \boldv_{\lambda_i, n_i} \}\)</span> of <span class="process-math">\(W_{\lambda_i}\text{.}\)</span> The ordered list</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
B'=(\boldv_{\lambda_1,1},\dots, \boldv_{\lambda_1,n_1},\boldv_{\lambda_2,1},\dots, \boldv_{\lambda_2,n_2},\dots,\boldv_{\lambda_r,1},\dots, \boldv_{\lambda_r,n_r} )\text{,}
\end{equation*}
</div>
<p class="continuation">is an eigenbasis of <span class="process-math">\(A\text{.}\)</span></p>
</li>
<li id="li-1004">
<p id="p-3092">“Lifting” the basis <span class="process-math">\(B'\)</span> back to <span class="process-math">\(V\)</span> via the coordinate transformation <span class="process-math">\([\phantom{\boldv}]_B\)</span> yields an eigenbasis <span class="process-math">\(B''\)</span> of <span class="process-math">\(T\text{.}\)</span> The matrix <span class="process-math">\([T]_{B''}\)</span> is diagonal, of the form</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
[T]_{B''}=
\begin{bmatrix}
\lambda_1 \amp \amp  \amp \amp \amp \amp   \\
\amp \ddots \amp \amp \amp \amp     \\
\amp   \amp   \lambda_2 \amp  \amp \amp   \\
\amp  \amp  \amp     \ddots \amp  \amp    \\
\amp  \amp  \amp    \amp   \lambda_r \amp   \\
\amp  \amp  \amp    \amp  \amp   \ddots    \\
\amp  \amp  \amp    \amp  \amp  \amp   \lambda_r
\end{bmatrix}\text{.}
\end{equation*}
</div>
</li>
</ol></article><article class="hiddenproof" id="proof-113"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-113"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-113"><article class="hiddenproof"><p id="p-3093">For the most part the validity of this procedure is a direct consequence of <a href="" class="xref" data-knowl="./knowl/th_diagonalizability_eigenbasis.html" title="Theorem 5.5.2: Diagonalizabilty: basis of eigenvectors">Theorem 5.5.2</a> and <a href="" class="xref" data-knowl="./knowl/th_diagonalizability_eigenspaces.html" title="Theorem 5.5.13: Diagonalizability: dimension of eigenspaces">Theorem 5.5.13</a>. However, there are two details that need to be pointed out.</p>
<ul class="disc">
<li id="li-1005"><p id="p-3094">That <span class="process-math">\(T\)</span> is diagonalizable if and only if <span class="process-math">\(A=[T]_B\)</span> is diagonalizable follows from the fact that a basis of the <span class="process-math">\(\lambda\)</span>-eigenspace of <span class="process-math">\(A\)</span> to a basis of the <span class="process-math">\(\lambda\)</span>-eigenspace of <span class="process-math">\(T\)</span> using the coordinate vector transformation <span class="process-math">\([\phantom{v}]_B\text{.}\)</span></p></li>
<li id="li-1006"><p id="p-3095">That the ordered list <span class="process-math">\(B'\)</span> described in Step 3 is in fact a basis is shown in the proof of <a href="" class="xref" data-knowl="./knowl/th_diagonalizability_eigenspaces.html" title="Theorem 5.5.13: Diagonalizability: dimension of eigenspaces">Theorem 5.5.13</a>.</p></li>
</ul></article></div>
<article class="example example-like" id="eg_diagonalizable_uppertriang"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">5.5.15</span><span class="period">.</span>
</h4>
<p id="p-3096">Let <span class="process-math">\(T=T_A\text{,}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A=\begin{amatrix}[rrr]
2\amp 1\amp 1\\
0\amp 3\amp 2\\
0\amp 0\amp 3
\end{amatrix}\text{.}
\end{equation*}
</div>
<p class="continuation">Decide whether <span class="process-math">\(T\)</span> is diagonalizable. If yes, find an eigenbasis of <span class="process-math">\(T\)</span> and compute the corresponding matrix representing <span class="process-math">\(T\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-103" id="solution-103"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-103"><div class="solution solution-like">
<p id="p-3097">Note first that <span class="process-math">\(A=[T]_B\)</span> where <span class="process-math">\(B\)</span> is the standard basis of <span class="process-math">\(\R^3\text{.}\)</span> (See <a href="" class="xref" data-knowl="./knowl/th_matrixreps_matrixtransforms.html" title="Theorem 5.2.3: Standard matrix as a matrix representation">Theorem 5.2.3</a>.) Since <span class="process-math">\(A\)</span> is upper triangular, we easily see that its characteristic polynomial is <span class="process-math">\(p(t)=(t-1)(t-3)^2\text{.}\)</span> Next we investigate the eigenspaces:</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_matrixreps_matrixtransforms.html">
\begin{equation*}
W_2=\NS(2I-A)=\NS \begin{amatrix}[rrr]0\amp -1\amp -1\\ 0\amp 1\amp -2\\ 0\amp 0\amp 1  \end{amatrix},coordinatecoordinate
W_3=\NS(3I-A)=\NS \begin{amatrix}[rrr]-1\amp -1\amp -1\\ 0\amp 0\amp -2\\ 0\amp 0\amp 0  \end{amatrix}\text{.}
\end{equation*}
</div>
<p class="continuation">By inspection we see that both <span class="process-math">\(2I-A\)</span> and <span class="process-math">\(3I-A\)</span> have rank 2, and hence nullity <span class="process-math">\(3-2=1\)</span> by the rank-nullity theorem. Thus both eigenspaces have dimension one, and we have <span class="process-math">\(\dim W_2+\dim W_3=1+1=2\lt 3\text{.}\)</span> We conclude that <span class="process-math">\(A\text{,}\)</span> and hence <span class="process-math">\(T_A\text{,}\)</span> is not diagonalizable.</p>
</div></div>
</div></article><p id="p-3098">The diagonalizability examples in this text will focus largely on the special case of matrix transformations <span class="process-math">\(T_A\colon \R^n\rightarrow \R^n\text{.}\)</span> However, our conscience demands that we give at least one full example of a more abstract linear transformation.</p>
<article class="example example-like" id="eg_diagonalizable_transposition"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">5.5.16</span><span class="period">.</span><span class="space"> </span><span class="title">Transposition.</span>
</h4>
<p id="p-3099">Let <span class="process-math">\(S\colon M_{22}\rightarrow M_{22}\)</span> be the linear transformation defined as <span class="process-math">\(S(A)=A^T\text{.}\)</span> Decide whether <span class="process-math">\(S\)</span> is diagonalizable. If yes, find an eigenbasis for <span class="process-math">\(S\)</span> and compute the corresponding matrix representing <span class="process-math">\(S\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-104" id="solution-104"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-104"><div class="solution solution-like">
<p id="p-3100">We saw in <a href="" class="xref" data-knowl="./knowl/eg_eigenvector_systematic_transposition.html" title="Example 5.4.24: Transposition (again)">Example 5.4.24</a> that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eg_eigenvector_systematic_transposition.html">
\begin{equation*}
[S]_B=\begin{bmatrix}
1\amp 0\amp 0\amp 0\\
0\amp 0\amp 1\amp 0\\
0\amp 1\amp 0\amp 0\\
0\amp 0\amp 0\amp 1
\end{bmatrix}\text{,}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(B=(E_{11}, E_{12}, E_{21}, E_{22})\)</span> is the standard ordered basis of <span class="process-math">\(M_{22}\text{.}\)</span> Furthermore, we saw that <span class="process-math">\(1\)</span> and <span class="process-math">\(-1\)</span> are the distinct eigenvalues of <span class="process-math">\(A=[S]_B\text{,}\)</span> and that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eg_eigenvector_systematic_transposition.html">
\begin{equation*}
S_1=\{(1,0,0,0), (0,1,1,0), (0,0,0,1)\}, S_{-1}=\Span\{(0,1,-1,0)\}
\end{equation*}
</div>
<p class="continuation">are bases of <span class="process-math">\(W_1\)</span> and <span class="process-math">\(W_{-1}\text{,}\)</span> respectively. It follows that <span class="process-math">\(\dim W_1+\dim W_{-1}=3+1=4\text{,}\)</span> that <span class="process-math">\(A\)</span> is diagonalizable, and that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eg_eigenvector_systematic_transposition.html">
\begin{equation*}
B'=((1,0,0,0), (0,1,1,0), (0,0,0,1), (0,1,-1,0))
\end{equation*}
</div>
<p class="continuation">is an eigenbasis of <span class="process-math">\(A\text{.}\)</span> We conclude that <span class="process-math">\(S\)</span> is diagonalizable, and we lift <span class="process-math">\(B'\)</span> via <span class="process-math">\([\phantom{v}]_B\)</span> to the eigenbasis</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eg_eigenvector_systematic_transposition.html">
\begin{equation*}
B''=\left\{
\begin{amatrix}[rr]1\amp 0\\ 0\amp 0  \end{amatrix},
\begin{amatrix}[rr]0\amp 1\\ 1\amp 0  \end{amatrix},
\begin{amatrix}[rr]0\amp 0\\ 0\amp 1  \end{amatrix},
\begin{amatrix}[rr]0\amp 1\\ -1\amp 0  \end{amatrix}
\right\}
\end{equation*}
</div>
<p class="continuation">of <span class="process-math">\(S\text{.}\)</span> Lastly, we have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eg_eigenvector_systematic_transposition.html">
\begin{equation*}
[S]_{B''}=
\begin{amatrix}[rrrr]1\amp 0\amp 0\amp 0\\ 0\amp 1\amp 0\amp 0\\ 0\amp 0\amp 1\amp 0\\ 0\amp 0\amp 0\amp -1  \end{amatrix}\text{.}
\end{equation*}
</div>
</div></div>
</div></article><section class="paragraphs" id="ss_vid_eg_diag"><h4 class="heading"><span class="title">Video example: deciding if diagonalizable.</span></h4>
<figure class="figure figure-like" id="fig_vid_diag"><div class="video-box" style="width: 100%;padding-top: 56.25%; margin-left: 0%; margin-right: 0%;"><iframe id="vid_diag" class="video" allowfullscreen="" src="https://www.youtube-nocookie.com/embed/_5z8kv1rDKQ?&amp;modestbranding=1&amp;rel=0"></iframe></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">5.5.17<span class="period">.</span></span><span class="space"> </span>Video: deciding if diagonalizable</figcaption></figure></section></section><section class="subsection" id="ss_diagonalizable_matrices"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">5.5.3</span> <span class="title">Diagonalizable matrices</span>
</h3>
<p id="p-3101">In this subsection we will focus on matrix transformations <span class="process-math">\(T_A\colon \R^n\rightarrow \R^n\text{.}\)</span> Recall (<a href="" class="xref" data-knowl="./knowl/th_matrixreps_matrixtransforms.html" title="Theorem 5.2.3: Standard matrix as a matrix representation">5.2.3</a>) that in this situation we have <span class="process-math">\(A=[T]_B\)</span> where <span class="process-math">\(B\)</span> is the <em class="emphasis">standard basis</em> of <span class="process-math">\(\R^n\text{.}\)</span> As such <a href="" class="xref" data-knowl="./knowl/proc_diagonalize.html" title="Procedure 5.5.14: Deciding whether a linear transformation is diagonalizable">Procedure 5.5.14</a> boils down to steps (2)-(3), and the eigenbasis <span class="process-math">\(B'\)</span> of <span class="process-math">\(A\)</span> found in (3) is itself an eigenbasis for <span class="process-math">\(T=T_A\text{.}\)</span> Letting <span class="process-math">\(D=[T]_{B'}\)</span> the change of basis formula (<a href="" class="xref" data-knowl="./knowl/th_change_of_basis_transformations.html" title="Theorem 5.3.20: Change of basis for transformations">5.3.20</a>) yields</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_matrixreps_matrixtransforms.html ./knowl/proc_diagonalize.html ./knowl/th_change_of_basis_transformations.html">
\begin{equation*}
D=P^{-1}AP\text{,}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(P=\underset{B'\rightarrow B}{P}\text{.}\)</span> Lastly, since <span class="process-math">\(B\)</span> is the standard basis of <span class="process-math">\(\R^n\text{,}\)</span> the change of basis matrix <span class="process-math">\(\underset{B'\rightarrow B}{P}\)</span> is obtained by placing the <span class="process-math">\(j\)</span>-th element of <span class="process-math">\(B'\)</span> as the <span class="process-math">\(j\)</span>-th column for all <span class="process-math">\(1\leq j\leq n\text{.}\)</span> We record these observations as a separate procedure specifically for matrix transformations.</p>
<article class="algorithm theorem-like" id="proc_diagonalize_matrixtransform"><h4 class="heading">
<span class="type">Procedure</span><span class="space"> </span><span class="codenumber">5.5.18</span><span class="period">.</span><span class="space"> </span><span class="title">Deciding whether a matrix is diagonalizable.</span>
</h4>
<p id="p-3102">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n\times n\)</span> matrix, and let <span class="process-math">\(T=T_A\)</span> be its corresponding matrix transformation. To decide whether <span class="process-math">\(A\)</span> is diagonalizable, proceed as follows.</p>
<ol class="decimal">
<li id="li-1007">
<p id="p-3103">Let <span class="process-math">\(W_1, W_2, \dots, W_r\)</span> be the nonzero eigenspaces of <span class="process-math">\(A\text{.}\)</span> We have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A \text{ diagonalizable}\iff \sum_{i=1}^r\dim W_i=n\text{.}
\end{equation*}
</div>
</li>
<li id="li-1008">
<p id="p-3104">Assume <span class="process-math">\(A\)</span> is diagonalizable and let <span class="process-math">\(B'=(\boldv_1, \boldv_2, \dots, \boldv_n)\)</span> be an eigenbasis of <span class="process-math">\(A\)</span> satisfying <span class="process-math">\(A\boldv_i=\lambda_i\boldv_i\)</span> for all <span class="process-math">\(1\leq i\leq n\text{.}\)</span> (We do not assume the <span class="process-math">\(\lambda_i\)</span> are distinct here.) Letting</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P=\begin{amatrix}[rrrr]\vert\amp \vert\amp \amp \vert \\
\boldv_1\amp \boldv_2\amp \cdots\amp \boldv_n \\
\vert\amp \vert\amp \amp \vert
\end{amatrix},
D=\begin{amatrix}[rrrr]
\lambda_1\amp 0\amp \dots \amp 0\\
0\amp \lambda_2\amp \dots \amp 0 \\
\vdots \amp  \amp \amp \vdots  \\
0\amp 0 \amp \dots \amp \lambda_n \end{amatrix}\text{,}
\end{equation*}
</div>
<p class="continuation">we have</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_diagonalize_matrix">
\begin{equation}
D=P^{-1}AP\text{.}\tag{5.5.7}
\end{equation}
</div>
</li>
</ol></article><p id="p-3105">The process of finding <span class="process-math">\(P\)</span> and <span class="process-math">\(D\)</span> satisfying <a href="" class="xref" data-knowl="./knowl/eq_diagonalize_matrix.html" title="Equation 5.5.7">(5.5.7)</a> is called <em class="emphasis">diagonalizing</em> the matrix <span class="process-math">\(A\text{;}\)</span> and we say that the matrix <span class="process-math">\(P\)</span> <em class="emphasis">diagonalizes</em> <span class="process-math">\(A\)</span> in this case. (Of course this is possible if and only if <span class="process-math">\(A\)</span> is diagonalizable.)</p>
<article class="example example-like" id="eg_diagonalizable_big"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">5.5.19</span><span class="period">.</span>
</h4>
<p id="p-3106">The matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A=\begin{amatrix}[rrrr]14 \amp 21 \amp 3 \amp -39 \\ 12 \amp 25 \amp 3 \amp -41 \\ 12 \amp 24 \amp 5 \amp -42 \\ 12 \amp 22 \amp 3 \amp -38 \end{amatrix}
\end{equation*}
</div>
<p class="continuation">has characteristic polynomial <span class="process-math">\(p(t)=t^4 - 6t^3 + 9t^2 + 4t - 12\text{.}\)</span> Decide whether <span class="process-math">\(A\)</span> is diagonalizable. If yes, find an invertible matrix <span class="process-math">\(P\)</span> and diagonal matrix <span class="process-math">\(D\)</span> such that <span class="process-math">\(D=P^{-1}AP\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-105" id="solution-105"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-105"><div class="solution solution-like">
<p id="p-3107">To factor <span class="process-math">\(p(t)\text{,}\)</span> we first look for integer roots dividing the constant term <span class="process-math">\(-12\text{:}\)</span> i.e., we test whether any of <span class="process-math">\(\pm 1, \pm 2, \pm 3, \pm 4, \pm 6, \pm 12\)</span> are roots. Luckily, we see that <span class="process-math">\(-1\)</span> is a root of <span class="process-math">\(p(t)\text{.}\)</span> Doing polynomial division of <span class="process-math">\(p(t)\)</span> by <span class="process-math">\((t+1)\)</span> yields</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/proc_fund_spaces.html">
\begin{equation*}
p(t)=(t+1)\underset{q(t)}{(t^3-7t^2+16t-12)}\text{.}
\end{equation*}
</div>
<p class="continuation">Repeating this factoring technique on <span class="process-math">\(q(t)\text{,}\)</span> we see that <span class="process-math">\(q(2)=0\text{,}\)</span> and thus can continue to factor:</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/proc_fund_spaces.html" id="md-260">
\begin{align*}
p(t)\amp=(t+1)(t^3-7t^2+16t-12)\\
\amp=(t+1)(t-2)(t^2-5t+6) \\
\amp = (t+1)(t-2)^2(t-3)\text{.}
\end{align*}
</div>
<p class="continuation">We conclude that the eigenvalues of <span class="process-math">\(A\)</span> are <span class="process-math">\(-1\text{,}\)</span> <span class="process-math">\(2\text{,}\)</span> and <span class="process-math">\(3\text{.}\)</span>  We now compute bases for the corresponding eigenspaces. The bases below were obtained using <a href="" class="xref" data-knowl="./knowl/proc_fund_spaces.html" title="Procedure 3.8.10: Computing bases of fundamental spaces">Procedure 3.8.10</a>. We omit the details of the Gaussian elimination performed in each case. (Check for yourself!)</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/proc_fund_spaces.html" id="md-261">
\begin{align*}
W_{-1} \amp =\NS \begin{amatrix}[rrrr]
-15\amp -21\amp -3\amp 39\\
-12\amp -26\amp -3\amp 41\\
-12\amp -24\amp -6\amp 42\\
-12\amp -22\amp -3\amp -37
\end{amatrix}=\Span\{(1,1,1,1)\} \\
W_{2} \amp =\NS \begin{amatrix}[rrrr]
-12\amp -21\amp -3\amp 39\\
-12\amp -23\amp -3\amp 41\\
-12\amp -24\amp -3\amp 42\\
-12\amp -22\amp -3\amp 40
\end{amatrix}=\Span\{(3,2,0,2),(1,1,2,1)\}  \\
W_{-1} \amp =\NS \begin{amatrix}[rrrr]
-11\amp -21\amp -3\amp 39\\
-12\amp -22\amp -3\amp 41\\
-12\amp -24\amp -2\amp 42\\
-12\amp -22\amp -3\amp 41
\end{amatrix}=\Span\{(3,5,6,4)\}  \text{.}
\end{align*}
</div>
<p class="continuation">We have ski Since</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/proc_fund_spaces.html">
\begin{equation*}
\dim W_{-1}+\dim W_{2}+\dim W_{3}=1+2+1=4=\dim \R^4\text{,}
\end{equation*}
</div>
<p class="continuation">we conclude that <span class="process-math">\(A\)</span> is diagonalizable. Furthermore, we have <span class="process-math">\(D=P^{-1}AP\text{,}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/proc_fund_spaces.html">
\begin{equation*}
P=\begin{amatrix}[rrrr]
1\amp 3\amp 1\amp 3\\
1\amp 2\amp 1\amp 5\\
1\amp 0\amp 2\amp 6\\
1\amp 2\amp 1\amp 4
\end{amatrix},
D=\begin{amatrix}[rrrr]
-1\amp 0 \amp 0 \amp 0 \\
0 \amp 2\amp 0\amp 0\\
0\amp 0\amp 2\amp 0\\
0\amp 0\amp 0\amp 3
\end{amatrix}\text{.}
\end{equation*}
</div>
</div></div>
</div></article><p id="p-3108">Recall that two square matrices <span class="process-math">\(A\)</span> and <span class="process-math">\(A'\)</span> are similar if <span class="process-math">\(A'=P^{-1}AP\)</span> for some invertible matrix <span class="process-math">\(P\)</span> (<a href="" class="xref" data-knowl="./knowl/d_similar.html" title="Definition 5.3.27">5.3.27</a>). From the foregoing discussion it follows that a matrix <span class="process-math">\(A\)</span> is diagonalizable if and only if it is similar to a diagonal matrix.</p>
<article class="corollary theorem-like" id="cor_diagonalizable_matrix"><h4 class="heading">
<span class="type">Corollary</span><span class="space"> </span><span class="codenumber">5.5.20</span><span class="period">.</span><span class="space"> </span><span class="title">Diagonalizabilty and similarity.</span>
</h4>
<p id="p-3109">An <span class="process-math">\(n\times n\)</span> matrix <span class="process-math">\(A\)</span> is diagonalizable if and only if it is similar to a diagonal matrix: i.e., if and only if there is an invertible matrix <span class="process-math">\(P\)</span> and a diagonal matrix <span class="process-math">\(D\)</span> such that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
D=P^{-1}AP\text{.}
\end{equation*}
</div></article><article class="hiddenproof" id="proof-114"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-114"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-114"><article class="hiddenproof"><p id="p-3110">According to <a href="" class="xref" data-knowl="./knowl/th_similarity_matrixreps.html" title="Theorem 5.3.28: Similarity and matrix representations">Theorem 5.3.28</a> the matrix <span class="process-math">\(A\)</span> is similar to a diagonal matrix <span class="process-math">\(D\)</span> if and only if there is a linear transformation <span class="process-math">\(T\colon \R^n\rightarrow \R^n\)</span> and ordered bases <span class="process-math">\(B, B'\)</span> of <span class="process-math">\(\R^n\)</span> such that <span class="process-math">\([T]_B=A\)</span> and <span class="process-math">\([T]_{B'}=D\text{.}\)</span> By definition such a <span class="process-math">\(T\)</span> would be diagonalizable, since <span class="process-math">\([T]_{B'}=D\)</span> is diagonal. Since <span class="process-math">\(T\)</span> is diagonalizable if and only if <span class="process-math">\(A=[T]_B\)</span> is diagonalizable, we conclude that <span class="process-math">\(A\)</span> is similar to a diagonal matrix <span class="process-math">\(D\)</span> if and only if <span class="process-math">\(A\)</span> is diagonalizable.</p></article></div>
<p id="p-3111">We know from <a href="" class="xref" data-knowl="./knowl/th_similarity_matrixreps.html" title="Theorem 5.3.28: Similarity and matrix representations">Theorem 5.3.28</a> that similar matrices can be thought of as two matrix representations of the same overlying linear transformation <span class="process-math">\(T\text{.}\)</span> As such similar matrices share many of the same algebraic properties, as <a href="" class="xref" data-knowl="./knowl/th_similarity.html" title="Theorem 5.5.21: Properties of similarity">Theorem 5.5.21</a> details.</p>
<article class="theorem theorem-like" id="th_similarity"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">5.5.21</span><span class="period">.</span><span class="space"> </span><span class="title">Properties of similarity.</span>
</h4>
<p id="p-3112">Suppose <span class="process-math">\(A\)</span> is similar to <span class="process-math">\(A'\text{:}\)</span> i.e., there is an invertible matrix <span class="process-math">\(P\)</span> such that <span class="process-math">\(A'=P^{-1}AP\text{.}\)</span> The following hold:</p>
<ol class="decimal">
<li id="li-1009"><p id="p-3113"><span class="process-math">\(A'\)</span> is similar to <span class="process-math">\(A\text{:}\)</span> i.e., there is an invertible matrix <span class="process-math">\(Q\)</span> such that <span class="process-math">\(A=Q^{-1}AQ\text{.}\)</span></p></li>
<li id="li-1010"><p id="p-3114"><span class="process-math">\(A\)</span> and <span class="process-math">\(A'\)</span> have the same characteristic polynomial.</p></li>
<li id="li-1011"><p id="p-3115"><span class="process-math">\(A\)</span> and <span class="process-math">\(A'\)</span> have the same eigenvalues.</p></li>
<li id="li-1012"><p id="p-3116"><span class="process-math">\(A\)</span> and <span class="process-math">\(A'\)</span> have the same trace and determinant.</p></li>
<li id="li-1013"><p id="p-3117"><span class="process-math">\(A\)</span> and <span class="process-math">\(A'\)</span> have the same rank.</p></li>
<li id="li-1014"><p id="p-3118">For any <span class="process-math">\(\lambda\in \R\)</span> we have <span class="process-math">\(\dim W_{\lambda}=\dim W_{\lambda}'\text{,}\)</span> where <span class="process-math">\(W_\lambda, W_\lambda'\)</span> are the <span class="process-math">\(\lambda\)</span>-eigenspaces of <span class="process-math">\(A\)</span> and <span class="process-math">\(A'\text{,}\)</span> respectively.</p></li>
</ol></article><article class="hiddenproof" id="proof-115"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-115"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-115"><article class="hiddenproof"><p id="p-3119">Statement (1) follows by taking <span class="process-math">\(Q=P^{-1}\text{.}\)</span></p>
<p id="p-3120">Let <span class="process-math">\(p_A(t)\)</span> and <span class="process-math">\(p_{A'}(t)\)</span> be the characteristic polynomials of <span class="process-math">\(A\)</span> and <span class="process-math">\(A'\text{,}\)</span> repsectively. We have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_det_mult.html" id="md-262">
\begin{align*}
p_{A'}(t)\amp =\det(tI-A')\\
\amp =\det(tI-P^{-1}AP) \amp (A'=P^{-1}AP)\\
\amp = \det(P^{-1}tIP-P^{-1}AP) \amp (\text{algebra}) \\
\amp = \det(P^{-1}(tI-A)P) \amp (\text{left/right dist.}) \\
\amp = \det(P^{-1})\det(tI-A)\det(P) \amp (\knowl{./knowl/th_det_mult.html}{\text{2.5.26}}) \\
\amp = (\det(P))^{-1}\det(P)\det(tI-A)  \\
\amp = \det(tI-A)=p_A(t)\text{.}
\end{align*}
</div>
<p class="continuation">This proves statement (2).</p>
<p id="p-3121">Statement (3) follows from (2) since the eigenvalues of a matrix are the real roots of its characteristic polynomial. Furthermore, by <a href="" class="xref" data-knowl="./knowl/th_characteristic_polynomial.html" title="Theorem 5.4.25: Characteristic polynomial">Theorem 5.4.25</a> the trace and determinant of a matrix are equal to the sum and product of the roots of its characteristic polynomial. Thus (4) also follows from (2).</p>
<p id="p-3122">The proofs of statements (5)-(6) are left as exercises.</p></article></div>
<p id="p-3123">A diagonalizable matrix is similar to a diagonal matrix (<a href="" class="xref" data-knowl="./knowl/cor_diagonalizable_matrix.html" title="Corollary 5.5.20: Diagonalizabilty and similarity">5.5.20</a>) and similar matrices share many essential properties (<a href="" class="xref" data-knowl="./knowl/th_similarity_matrixreps.html" title="Theorem 5.3.28: Similarity and matrix representations">5.3.28</a>, <a href="" class="xref" data-knowl="./knowl/th_similarity.html" title="Theorem 5.5.21: Properties of similarity">5.5.21</a>) In this spirit, a good way of thinking about a diagonalizable matrix is that it is “as good as diagonal”.</p>
<article class="principle theorem-like" id="mantra_diagonalizable"><h4 class="heading">
<span class="type">Mantra</span><span class="space"> </span><span class="codenumber">5.5.22</span><span class="period">.</span><span class="space"> </span><span class="title">Diagonalizable mantra.</span>
</h4>
<p id="p-3124">A diagonalizable matrix is as good as diagonal.</p></article><p id="p-3125">In practical terms, if <span class="process-math">\(A\)</span> is diagonalizable, then we have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_diagonalize_matrix_2.html" id="mdn-9">
\begin{align}
D\amp=P^{-1}AP \amp A\amp=PDP^{-1} \tag{5.5.8}
\end{align}
</div>
<p class="continuation">where <span class="process-math">\(D\)</span> is diagonal. This allows us to answer questions about <span class="process-math">\(A\)</span> by first answering the question for <span class="process-math">\(D\)</span> and then use the equations in <a href="" class="xref" data-knowl="./knowl/eq_diagonalize_matrix_2.html" title="Equation 5.5.8">(5.5.8)</a> to translate the results back to <span class="process-math">\(A\text{.}\)</span> What makes this method effective is that algebraic questions involving diagonal matrices are easy to answer! Before getting to some illustrative examples, we need a few results about the operation <span class="process-math">\(A\mapsto P^{-1}AP\text{,}\)</span> which is called <em class="emphasis">conjugation</em> by <span class="process-math">\(P\text{.}\)</span></p>
<article class="theorem theorem-like" id="th_conjugation"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">5.5.23</span><span class="period">.</span><span class="space"> </span><span class="title">Properties of conjugation.</span>
</h4>
<p id="p-3126">Let <span class="process-math">\(P\)</span> be an invertible <span class="process-math">\(n\times n\)</span> matrix.</p>
<ol class="decimal">
<li id="li-1015">
<span class="heading"><span class="title">Conjugation is linear.</span></span><p id="p-3127">For all <span class="process-math">\(A_1,A_2\in M_{nn}\)</span> and <span class="process-math">\(c_1,c_2\in \R\text{,}\)</span> we have <span class="process-math">\(P^{-1}(c_1A_1+c_2A_2)P=c_1P^{-1}A_1P+c_2P^{-1}A_2P\text{.}\)</span></p>
</li>
<li id="li-1016">
<span class="heading"><span class="title">Conjugation commutes with powers.</span></span><p id="p-3128">For all <span class="process-math">\(A\in M_{nn}\)</span> and integers <span class="process-math">\(k\geq 0\text{,}\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
(P^{-1}AP)^k=P^{-1}A^kP\text{.}
\end{equation*}
</div>
<p class="continuation">If <span class="process-math">\(A\)</span> is invertible, this equality holds for <em class="emphasis">all</em> integers <span class="process-math">\(n\text{.}\)</span></p>
</li>
<li id="li-1017">
<span class="heading"><span class="title">Conjugation commutes with polynomials.</span></span><p id="p-3129">Given any polynomial <span class="process-math">\(f(x)=a_rx^r+a_{r-1}x^{r-1}+\cdots +a_1x+a_0\)</span> with real coefficients, we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
f(P^{-1}AP)=P^{-1}f(A)P\text{.}
\end{equation*}
</div>
</li>
</ol></article><article class="hiddenproof" id="proof-116"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-116"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-116"><article class="hiddenproof"><p id="p-3130">The proof is left as an exercise.</p></article></div>
<article class="example example-like" id="eg_diagonalizable_matrix_powers"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">5.5.24</span><span class="period">.</span><span class="space"> </span><span class="title">Diagonalizable: matrix powers.</span>
</h4>
<p id="p-3131">Assume <span class="process-math">\(D=P^{-1}AP\text{,}\)</span> where <span class="process-math">\(D\)</span> is diagonal. The normally difficult computation <span class="process-math">\(A^{k}\)</span> can be accomplished by first computing <span class="process-math">\(D^{k}\)</span> (easy) and then observing that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_conjugation.html" id="md-263">
\begin{align*}
A^k\amp = (PDP^{-1})^k \amp \\
\amp =PD^kP^{-1} \amp (\knowl{./knowl/th_conjugation.html}{\text{Theorem 5.5.23}}, (2)) \text{.}
\end{align*}
</div>
<p class="continuation">For example, the matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_conjugation.html">
\begin{equation*}
A=\begin{amatrix}[rr]1\amp 3\\ 1\amp -1 \end{amatrix}
\end{equation*}
</div>
<p class="continuation">is diagonalizable and satisfies <span class="process-math">\(D=P^{-1}AP\text{,}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_conjugation.html">
\begin{equation*}
P=\begin{amatrix}[rr]3\amp 1\\ 1\amp -1 \end{amatrix}, D=\begin{amatrix}[rr]2\amp 0\\ 0\amp -2 \end{amatrix}\text{.}
\end{equation*}
</div>
<p class="continuation">It follows that for any <span class="process-math">\(k\in \Z\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_conjugation.html" id="md-264">
\begin{align*}
A^k \amp=PD^kP^{-1} \\
\amp = P\begin{amatrix}[rr]2^{k}\amp 0\\ 0\amp (-2)^{k} \end{amatrix} P^{-1}\\
\amp = \frac{1}{4}\begin{amatrix}[rr]3\cdot2^k+(-2)^k\amp 3\cdot 2^k-3(-2)^{k}\\ 2^{k}-(-2)^k\amp 2^k+3(-2)^{k} \end{amatrix}\text{.}
\end{align*}
</div></article><article class="example example-like" id="eg_diagonalizable_matrix_polynomials"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">5.5.25</span><span class="period">.</span><span class="space"> </span><span class="title">Diagonalizable: matrix polynomials.</span>
</h4>
<p id="p-3132">Assume <span class="process-math">\(D=P^{-1}AP\text{,}\)</span> where <span class="process-math">\(D\)</span> is a diagonal <span class="process-math">\(n\times n\)</span> matrix. Let <span class="process-math">\([D]_{ii}=d_{i}\text{.}\)</span> Given any polynomial <span class="process-math">\(f(x)=\anpoly\text{,}\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_conjugation.html" id="md-265">
\begin{align*}
f(A) \amp= f(PDP^{-1}) \\
\amp =Pf(D)P^{-1}  \amp (\knowl{./knowl/th_conjugation.html}{\text{Theorem 5.5.23}},(3))\text{.}
\end{align*}
</div>
<p class="continuation">Furthermore, since <span class="process-math">\(D\)</span> is diagonal, it follows that <span class="process-math">\(f(D)\)</span> is also diagonal, and in fact its diagonal entries are given by <span class="process-math">\(f(d_i)\text{.}\)</span> This gives us an easy method of computing arbitrary polynomials of the matrix <span class="process-math">\(A\text{.}\)</span></p>
<p id="p-3133">Consider again the matrix <span class="process-math">\(A\)</span> (and <span class="process-math">\(P\)</span> and <span class="process-math">\(D\)</span>) from  <a href="" class="xref" data-knowl="./knowl/eg_diagonalizable_matrix_powers.html" title="Example 5.5.24: Diagonalizable: matrix powers">Example 5.5.24</a>.  Let <span class="process-math">\(f(x)=x^2 -4\text{.}\)</span> Since <span class="process-math">\(f(2)=f(-2)=0\text{,}\)</span> it follows that <span class="process-math">\(f(D)=D^2-4I=\boldzero\text{.}\)</span> We conclude that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eg_diagonalizable_matrix_powers.html">
\begin{equation*}
f(A)=A^2-4I=Pf(D)P^{-1}=P\boldzero P^{-1}=\boldzero\text{,}
\end{equation*}
</div>
<p class="continuation">as you can check directly.</p></article><article class="example example-like" id="example-131"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">5.5.26</span><span class="period">.</span>
</h4>
<p id="p-3134">A <em class="emphasis">square-root</em> of an <span class="process-math">\(n\times n\)</span> matrix <span class="process-math">\(A\)</span> is a matrix <span class="process-math">\(B\)</span> such that <span class="process-math">\(B^2=A\text{.}\)</span> If <span class="process-math">\(A\)</span> and <span class="process-math">\(A'\)</span> are similar matrices, satisfying <span class="process-math">\(A'=P^{-1}AP\text{,}\)</span> then <span class="process-math">\(A\)</span> has a square-root if and only if <span class="process-math">\(A'\)</span> has a square-root. Indeed, if <span class="process-math">\(B\)</span> satisfies <span class="process-math">\(B^2=A\text{,}\)</span> then  <span class="process-math">\(C=P^{-1}BP\)</span> satisfies</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
C^2=(P^{-1}BP)^2=P^{-1}B^2P=P^{-1}AP=A'\text{.}
\end{equation*}
</div>
<p class="continuation">Similarly, if <span class="process-math">\(C\)</span> satisfies <span class="process-math">\(C^2=A'\text{,}\)</span> then <span class="process-math">\(B=PCP^{-1}\)</span> satisfies</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
B^2=(PCP^{-1})^2=PC^2P^{-1}=PA'P^{-1}=A\text{.}
\end{equation*}
</div>
<p class="continuation">As an example, the matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A=\begin{amatrix}[rr]0\amp -2\\ 1 \amp 3 \end{amatrix}
\end{equation*}
</div>
<p class="continuation">satisfies <span class="process-math">\(D=P^{-1}AP\text{,}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P=\begin{amatrix}[rr]2\amp 1\\ -1\amp -1 \end{amatrix}, D=\begin{amatrix}[rr]1\amp 0\\ 0\amp 2 \end{amatrix}\text{.}
\end{equation*}
</div>
<p class="continuation">Since</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
C=\begin{bmatrix}1\amp 0\\ 0\amp \sqrt{2} \end{bmatrix}
\end{equation*}
</div>
<p class="continuation">is a square-root of <span class="process-math">\(D\text{,}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
B=PCP^{-1}=\begin{amatrix}[rr]2-\sqrt{2}\amp 2-2\sqrt{2}\\ -1+\sqrt{2}\amp -1+2\sqrt{2} \end{amatrix}
\end{equation*}
</div>
<p class="continuation">is a square-root of <span class="process-math">\(A\text{.}\)</span></p>
<p id="p-3135">So when exactly does a diagonal matrix <span class="process-math">\(D\)</span> have a square-root? Clearly, it is <em class="emphasis">sufficient</em>  that the diagonal entries <span class="process-math">\(d_i\)</span> satisfy <span class="process-math">\(d_i\geq 0\)</span> for all <span class="process-math">\(i\text{,}\)</span> as in the example above. Interestingly, this is not a necessary condition! Indeed, consider the following example:</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\begin{amatrix}[rr]-1\amp 0\\ 0\amp -1 \end{amatrix} =\begin{amatrix}[rr]0\amp -1\\ 1\amp 0 \end{amatrix} ^2\text{.}
\end{equation*}
</div></article></section><section class="subsection" id="subsection-86"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">5.5.4</span> <span class="title">Algebraic and geometric multiplicity</span>
</h3>
<p id="p-3136">We end this section with a deeper look at what the characteristic polynomial reveals about eigenspaces. To begin with, we first define the characteristic polynomial of a general linear transformation <span class="process-math">\(T\colon V\rightarrow V\text{,}\)</span> where <span class="process-math">\(V\)</span> is a finite-dimensional vector space.</p>
<article class="definition definition-like" id="d_char_poly_transform"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">5.5.27</span><span class="period">.</span><span class="space"> </span><span class="title">Characteristic polynomial of a transformation.</span>
</h4>
<p id="p-3137">Let <span class="process-math">\(T\colon V\rightarrow V\)</span> be a linear transformation, where <span class="process-math">\(V\)</span> is finite-dimensional. Let <span class="process-math">\(B\)</span> be an ordered basis of <span class="process-math">\(V\text{,}\)</span> and let <span class="process-math">\(A=[T]_B\text{.}\)</span> We define the <dfn class="terminology">characteristic polynomial</dfn> of <span class="process-math">\(T\)</span> to be the characteristic polynomial of <span class="process-math">\(A\text{:}\)</span> i.e., the characteristic polynomial of <span class="process-math">\(T\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
p(t)=\det(tI-A)\text{.}
\end{equation*}
</div></article><article class="remark remark-like" id="rm_char_poly_transform"><h4 class="heading">
<span class="type">Remark</span><span class="space"> </span><span class="codenumber">5.5.28</span><span class="period">.</span>
</h4>
<p id="p-3138">For the characteristic polynomial of a linear transformation <span class="process-math">\(T\colon V\rightarrow V\)</span> to be well-defined, it should not depend on the choice of basis. This is true thanks to <a href="" class="xref" data-knowl="./knowl/th_similarity.html" title="Theorem 5.5.21: Properties of similarity">Theorem 5.5.21</a> and <a href="" class="xref" data-knowl="./knowl/th_change_of_basis_transformations.html" title="Theorem 5.3.20: Change of basis for transformations">Theorem 5.3.20</a>. Indeed, given two choice of ordered bases <span class="process-math">\(B, B'\)</span> of <span class="process-math">\(V\text{,}\)</span> the matrices <span class="process-math">\(A=[T]_B\)</span> and <span class="process-math">\(A'=[T]_{B'}\)</span> are similar (<a href="" class="xref" data-knowl="./knowl/th_change_of_basis_transformations.html" title="Theorem 5.3.20: Change of basis for transformations">5.3.20</a>), and thus their characteristic polynomials are equal (<a href="" class="xref" data-knowl="./knowl/th_similarity.html" title="Theorem 5.5.21: Properties of similarity">5.5.21</a>,(2)).</p></article><p id="p-3139">Let <span class="process-math">\(T\colon V\rightarrow V\)</span> be a linear transformation, where <span class="process-math">\(V\)</span> is finite-dimensional. If <span class="process-math">\(\lambda\in \R\)</span> is an eigenvalue of <span class="process-math">\(T\text{,}\)</span> then we can factor the chacteristic polynomial <span class="process-math">\(p(t)\)</span> of <span class="process-math">\(T\)</span> as <span class="process-math">\(p(t)=(t-\lambda)^mq(t)\text{,}\)</span> where <span class="process-math">\(\lambda\)</span> is not a root of <span class="process-math">\(q(t)\text{.}\)</span> As we will see, the exponent <span class="process-math">\(m\)</span> is an upper bound for the dimension of <span class="process-math">\(W_\lambda\text{.}\)</span> We call <span class="process-math">\(m\)</span> the <em class="emphasis">algebraic multiplicity</em> of the eigenvalue <span class="process-math">\(\lambda\text{.}\)</span></p>
<article class="definition definition-like" id="d_alg_geom_mult"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">5.5.29</span><span class="period">.</span><span class="space"> </span><span class="title">Algebraic/geometric multiplicity.</span>
</h4>
<p id="p-3140">Let <span class="process-math">\(T\colon V\rightarrow V\)</span> be a linear transformation, where <span class="process-math">\(V\)</span> is finite-dimensional, and let <span class="process-math">\(p(t)\)</span> be the characteristic polynomial of <span class="process-math">\(T\text{.}\)</span> Given an eigenvalue <span class="process-math">\(\lambda\in \R\)</span> of <span class="process-math">\(T\text{,}\)</span> we can factor <span class="process-math">\(p(t)\)</span> as <span class="process-math">\(p(t)=(t-\lambda)^mq(t)
\text{,}\)</span> where <span class="process-math">\(\lambda\)</span> is not a root of the polynomial <span class="process-math">\(q(t)\text{:}\)</span> i.e., <span class="process-math">\(q(\lambda)\ne 0\text{.}\)</span> We call <span class="process-math">\(m\)</span> the <dfn class="terminology">geometric multiplicity</dfn> of the eigenvalue <span class="process-math">\(\lambda\text{,}\)</span> and we call <span class="process-math">\(\dim W_\lambda\)</span> its <dfn class="terminology">geometric multiplicity</dfn>. If <span class="process-math">\(m\gt 1\text{,}\)</span> we say <span class="process-math">\(\lambda\)</span> is a <dfn class="terminology">repeated</dfn> eigenvalue of <span class="process-math">\(T\text{.}\)</span></p></article><article class="theorem theorem-like" id="th_alg_geom_mult"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">5.5.30</span><span class="period">.</span><span class="space"> </span><span class="title">Algebraic and geometric multiplicity.</span>
</h4>
<p id="p-3141">Let <span class="process-math">\(T\colon V\rightarrow V\)</span> be a linear transformation, where <span class="process-math">\(dim V=n\text{,}\)</span> let <span class="process-math">\(p(t)\)</span> be the characteristic polynomial of <span class="process-math">\(T\text{,}\)</span> and suppose <span class="process-math">\(\lambda\in\R\)</span> is an eigenvalue of <span class="process-math">\(T\)</span> of algebraic multiplicity <span class="process-math">\(m\geq 1\text{:}\)</span> i.e., <span class="process-math">\(p(t)=(t-\lambda)^mq(t)\)</span> and <span class="process-math">\(q(\lambda)\ne 0\text{.}\)</span> We have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
1\leq \dim W_\lambda\leq m\text{.}
\end{equation*}
</div>
<p class="continuation">In other words, the geometric multiplicity of an eigenvalue is bounded above by its algebraic multiplicity.</p></article><article class="hiddenproof" id="proof-117"><a href="" data-knowl="" class="id-ref proof-knowl original has-image" data-refid="hk-proof-117"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-117"><article class="hiddenproof"><p id="p-3142">Since <span class="process-math">\(\lambda\)</span> is an eigenvalue, we have <span class="process-math">\(W_\lambda\ne \{\boldzero\}\text{,}\)</span> and thus <span class="process-math">\(\dim W_\lambda\geq 1\text{.}\)</span> Assume by contradiction that <span class="process-math">\(\dim W_{\lambda}\gt m\text{.}\)</span> Let <span class="process-math">\(m'=\dim W_{\lambda}\text{,}\)</span> and let <span class="process-math">\(S_{\lambda}=\{\boldv_1,\boldv_2,\dots, \boldv_{m'}\}\)</span> be a basis for <span class="process-math">\(W_{\lambda}\text{.}\)</span> We can extend <span class="process-math">\(S_{\lambda}\)</span> to an ordered basis</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
B=(\boldv_1, \dots, \boldv_{m'}, \boldv_{m'+1},\dots, \boldv_n)
\end{equation*}
</div>
<p class="continuation">of <span class="process-math">\(V\text{.}\)</span> By definition, the characteristic polynomial of <span class="process-math">\(T\)</span> is given my <span class="process-math">\(p(t)=\det(tI-A)\text{,}\)</span> where <span class="process-math">\(A=[T]_B\)</span>w. Since <span class="process-math">\(\boldv_1,\boldv_2,\dots, \boldv_{m'}\)</span> are <span class="process-math">\(\lambda\)</span>-eigenvectors of <span class="process-math">\(T\text{,}\)</span> the matrix <span class="process-math">\(A=[T]_B\)</span> is of the form <div class="image-box" style="width: 40%; margin-left: 30%; margin-right: 30%;"><img src="generated/latex-image/im_alg_geom_mult.svg" role="img" class="contained"></div> An easy proof by induction on <span class="process-math">\(m'\)</span> shows that for such a matrix <span class="process-math">\(A\)</span> we have  <span class="process-math">\(p(t)=\det(tI-A)=(t-\lambda)^{m'}r(t)\)</span> for some polynomial <span class="process-math">\(r(t)\text{.}\)</span> On the other hand, since <span class="process-math">\(\lambda\)</span> has algebraic multiplicity <span class="process-math">\(m\)</span> we have <span class="process-math">\(p(t)=(t-\lambda)^mq(t)\)</span> for some polynomial <span class="process-math">\(q(t)\)</span> with <span class="process-math">\(q(\lambda)=0\text{.}\)</span> Setting these two expressions equal to one another we see that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
(t-\lambda)^{m'}r(t)=(t-\lambda)^mq(t)\text{,}
\end{equation*}
</div>
<p class="continuation">or equivalently,</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
(t-\lambda)^{m'-m}r(t)=q(t)\text{.}
\end{equation*}
</div>
<p class="continuation">Since <span class="process-math">\(m'\gt m\)</span> it follows that <span class="process-math">\(q(\lambda)=(\lambda-\lambda)^{m'-m}r(\lambda)=0\text{.}\)</span> Contradiction! We conclude that <span class="process-math">\(\dim W_{\lambda}\leq m\text{,}\)</span> as desired.</p></article></div>
<article class="corollary theorem-like" id="cor_alg_geom_mult"><h4 class="heading">
<span class="type">Corollary</span><span class="space"> </span><span class="codenumber">5.5.31</span><span class="period">.</span>
</h4>
<p id="p-3143">Let <span class="process-math">\(T\colon V\rightarrow V\)</span> be a linear transformation, where <span class="process-math">\(\dim V=n\text{,}\)</span> and suppose the characteristic polynomial of <span class="process-math">\(T\)</span> factors over <span class="process-math">\(\mathbb{C}\)</span> as</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_cor_alg_geom_mult">
\begin{equation}
p(t)=(t-\lambda_1)^{m_1}(t-\lambda_2)^{m_2}\cdots (t-\lambda_r)^{m_r}\text{,}\tag{5.5.9}
\end{equation}
</div>
<p class="continuation">where <span class="process-math">\(\lambda_i\ne \lambda_j\)</span> for all <span class="process-math">\(1\leq i\lt j\leq n\text{.}\)</span> The following are equivalent:</p>
<ol class="decimal">
<li id="li-1018"><p id="p-3144"><span class="process-math">\(T\)</span> is diagonalizable.</p></li>
<li id="li-1019"><p id="p-3145">For all <span class="process-math">\(1\leq i\leq n\)</span> we have <span class="process-math">\(\lambda_i\in \R\)</span> and <span class="process-math">\(\dim W_{\lambda_i}=m_i\text{.}\)</span></p></li>
</ol>
<p class="continuation">In other words, <span class="process-math">\(T\)</span> is diagonalizable if and only if all roots of <span class="process-math">\(p(t)\)</span> are real, and the geometric multiplicity of each eigenvalue is equal to its algebraic multiplicity.</p></article><article class="hiddenproof" id="proof-118"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-118"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-118"><article class="hiddenproof"><article class="case" id="case-107"><h5 class="heading">Implication: <span class="process-math">\((2)\implies (1)\)</span>.</h5>
<p id="p-3146">If (2) is true, then each <span class="process-math">\(\lambda_i\)</span> is an eigenvalue of <span class="process-math">\(T\)</span> and we have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_cor_alg_geom_mult.html ./knowl/th_diagonalizability_eigenbasis.html">
\begin{equation*}
\sum_{i=1}^r\dim W_{\lambda_i}=\sum_{i=1}^r m_i=n\text{,}
\end{equation*}
</div>
<p class="continuation">by counting degrees in <a href="" class="xref" data-knowl="./knowl/eq_cor_alg_geom_mult.html" title="Equation 5.5.9">(5.5.9)</a>. It follows from <a href="" class="xref" data-knowl="./knowl/th_diagonalizability_eigenbasis.html" title="Theorem 5.5.2: Diagonalizabilty: basis of eigenvectors">Theorem 5.5.2</a> that <span class="process-math">\(T\)</span> is diagonalizable.</p></article><article class="case" id="case-108"><h5 class="heading">Implication: <span class="process-math">\((1)\implies (2)\)</span>.</h5>
<p id="p-3147">If <span class="process-math">\(T\)</span> is diagonalizable, then there is an ordered basis <span class="process-math">\(B\)</span> of <span class="process-math">\(V\)</span> for which <span class="process-math">\(D=[T]_B\)</span> is diagonal. Letting <span class="process-math">\(d_i\)</span> be the <span class="process-math">\(i\)</span>-th diagonal element of <span class="process-math">\(D\text{,}\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_diagonalizability_eigenspaces.html ./knowl/th_alg_geom_mult.html ./knowl/eq_cor_alg_geom_mult.html ./knowl/eq_cor_alg_geom_mult_proof.html">
\begin{equation*}
p(t)=\det(tI-D)=(t-d_1)(t-d_2)\dots (t-d_n)\text{.}
\end{equation*}
</div>
<p class="continuation">This expression tells us that <span class="process-math">\(d_1, d_2, \dots, d_n\)</span> are the roots of <span class="process-math">\(p(t)\text{,}\)</span> and hence that all roots are real since since <span class="process-math">\(d_i\in \R\)</span> for all <span class="process-math">\(1\leq i\leq n\text{.}\)</span> On the other hand  each <span class="process-math">\(\lambda_i\)</span> is a root of <span class="process-math">\(p(t)\text{,}\)</span> and thus <span class="process-math">\(\lambda_i\in \R\)</span> for all <span class="process-math">\(1\leq i\leq r\text{.}\)</span> It follows that <span class="process-math">\(\lambda_1, \lambda_2, \dots, \lambda_r\)</span> are the distinct eigenvalues of <span class="process-math">\(T\text{.}\)</span> By <a href="" class="xref" data-knowl="./knowl/th_diagonalizability_eigenspaces.html" title="Theorem 5.5.13: Diagonalizability: dimension of eigenspaces">Theorem 5.5.13</a>, since <span class="process-math">\(T\)</span> is diagonalizable we must have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_diagonalizability_eigenspaces.html ./knowl/th_alg_geom_mult.html ./knowl/eq_cor_alg_geom_mult.html ./knowl/eq_cor_alg_geom_mult_proof.html" id="eq_cor_alg_geom_mult_proof">
\begin{equation}
\sum_{i=1}^r\dim W_{\lambda_i}=n\text{.}\tag{5.5.10}
\end{equation}
</div>
<p class="continuation">Since <span class="process-math">\(\dim W_{\lambda_i}\leq m_i\)</span> for all <span class="process-math">\(1\leq i\leq n\)</span> (<a href="" class="xref" data-knowl="./knowl/th_alg_geom_mult.html" title="Theorem 5.5.30: Algebraic and geometric multiplicity">5.5.30</a>), and since <span class="process-math">\(\sum_{i=1}^rm_i=n\)</span> (counting degrees in <a href="" class="xref" data-knowl="./knowl/eq_cor_alg_geom_mult.html" title="Equation 5.5.9">(5.5.9)</a>), for the equality <a href="" class="xref" data-knowl="./knowl/eq_cor_alg_geom_mult_proof.html" title="Equation 5.5.10">(5.5.10)</a> to hold we must have <span class="process-math">\(\dim W_{\lambda_i}=m_i\)</span> for all <span class="process-math">\(1\leq i\leq r\text{,}\)</span> as desired.</p></article></article></div>
<p id="p-3148">From <a href="" class="xref" data-knowl="./knowl/th_alg_geom_mult.html" title="Theorem 5.5.30: Algebraic and geometric multiplicity">Theorem 5.5.30</a> and <a href="" class="xref" data-knowl="./knowl/cor_alg_geom_mult.html" title="Corollary 5.5.31">Corollary 5.5.31</a> we can deduce a much finer picture of the eigenspaces of a linear transformation from its factored characteristic polynomial. This often reduces our workload when treating questions of diagonalizability, as the next examples illustrate.</p>
<article class="example example-like" id="eg_alg_geom_1"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">5.5.32</span><span class="period">.</span>
</h4>
<p id="p-3149">The matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A=\begin{amatrix}[rrrr]
2 \amp -1 \amp 1 \amp 0 \\
-4 \amp 2 \amp 0 \amp -4 \\
-4 \amp 1 \amp 1 \amp -4 \\
-4 \amp 1 \amp -1 \amp -2
\end{amatrix}
\end{equation*}
</div>
<p class="continuation">has characteristic polynomial <span class="process-math">\(p(t)=(t-1)(t+2)(t-2)^2\text{.}\)</span> Decide whether <span class="process-math">\(A\)</span> is diagonalizable.</p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-106" id="solution-106"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-106"><div class="solution solution-like">
<p id="p-3150">The eigenvalues of <span class="process-math">\(A\)</span> are <span class="process-math">\(1,-2, 2\text{.}\)</span> Since the eigenvalues <span class="process-math">\(1\)</span> and <span class="process-math">\(-2\)</span> both have algebraic multiplicity <span class="process-math">\(1\text{,}\)</span> we have by <a href="" class="xref" data-knowl="./knowl/th_alg_geom_mult.html" title="Theorem 5.5.30: Algebraic and geometric multiplicity">Theorem 5.5.30</a></p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_alg_geom_mult.html">
\begin{equation*}
1\leq \dim W_1, \dim W_{-2}\leq 1\text{,}
\end{equation*}
</div>
<p class="continuation">and hence</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_alg_geom_mult.html">
\begin{equation*}
\dim W_1=\dim W_{-2}=1\text{.}
\end{equation*}
</div>
<p class="continuation">It follows that <span class="process-math">\(A\)</span> is diagonalizable if and only if <span class="process-math">\(\dim W_{2}=2\text{.}\)</span> We have <span class="process-math">\(W_{2}=\NS(2I-A)\text{,}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_alg_geom_mult.html">
\begin{equation*}
2I-A=
\begin{amatrix}[rrrr]
0 \amp 1 \amp -1 \amp 0 \\
4 \amp 0 \amp 0 \amp -4 \\
4 \amp -1 \amp 1 \amp -4 \\
4 \amp -1 \amp 1 \amp -4
\end{amatrix}\text{.}
\end{equation*}
</div>
<p class="continuation">This matrix clearly has rank 2 (the first two columns form a basis for its column space), and hence nullity <span class="process-math">\(4-2=2\text{.}\)</span> We conclude that <span class="process-math">\(A\)</span> is diagonalizable.</p>
</div></div>
</div></article><article class="example example-like" id="eg_alg_geom_2"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">5.5.33</span><span class="period">.</span>
</h4>
<p id="p-3151">The matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A=\begin{amatrix}[rrrr]
1 \amp 0 \amp -3 \amp 1 \\
0 \amp 1 \amp 1 \amp 1 \\
0 \amp 0 \amp -2 \amp 1 \\
0 \amp 0 \amp -1 \amp 0  \end{amatrix}
\end{equation*}
</div>
<p class="continuation">has characterisic polynomial <span class="process-math">\(p(t)=(t-1)^2(t+1)^2\text{.}\)</span> Decide whether <span class="process-math">\(A\)</span> is diagonalizable.</p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-107" id="solution-107"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-107"><div class="solution solution-like">
<p id="p-3152">The eigenvalues of <span class="process-math">\(A\)</span> are <span class="process-math">\(1\)</span> and <span class="process-math">\(-1\text{,}\)</span> and each has algebraic multiplicity <span class="process-math">\(2\text{.}\)</span> Thus <span class="process-math">\(1\leq\dim W_1, \dim W_{-1}\leq 2\text{,}\)</span> and <span class="process-math">\(A\)</span> is diagonalizable if and only if</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\dim W_1=\dim W_{-1}=2\text{.}
\end{equation*}
</div>
<p class="continuation">By inspection we see that <span class="process-math">\((1,0,0,0)\)</span> and <span class="process-math">\((0,1,0,0)\)</span> are <span class="process-math">\(1\)</span>-eigenvectors, and thus we must have <span class="process-math">\(\dim W_1=2\text{.}\)</span> Next we have <span class="process-math">\(W_{-1}=\NS(-I-A)\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
-I-A=\begin{amatrix}[rrrr]
-2 \amp 0 \amp 3 \amp -1 \\
0 \amp -2 \amp -1 \amp -1 \\
0 \amp 0 \amp 1 \amp -1 \\
0 \amp 0 \amp 1 \amp -1
\end{amatrix}\text{.}
\end{equation*}
</div>
<p class="continuation">It is not difficult to see (either using Gaussian elimination or inspection) that this matrix has rank 3, and hence nullity 1. We conclude that <span class="process-math">\(\dim W_{-1}=1\lt 2\text{,}\)</span> and hence <span class="process-math">\(A\)</span> is not diagonalizable.</p>
</div></div>
</div></article></section><section class="exercises" id="s_diagonalization_ex"><h3 class="heading hide-type">
<span class="type">Exercises</span> <span class="codenumber">5.5.5</span> <span class="title">Exercises</span>
</h3>
<div class="exercisegroup" id="exercisegroup-37">
<h4 class="heading"><span class="title">Exercise Group.</span></h4>
<div class="introduction" id="introduction-80"><p id="p-3153">For each matrix <span class="process-math">\(A\)</span> use <a href="" class="xref" data-knowl="./knowl/proc_diagonalize.html" title="Procedure 5.5.14: Deciding whether a linear transformation is diagonalizable">Procedure 5.5.14</a> to determine whether it is diagonalizable. If yes, then produce an invertible matrix <span class="process-math">\(P\)</span> and diagonal matrix <span class="process-math">\(D\)</span> satisfying <span class="process-math">\(D=P^{-1}AP\text{.}\)</span> For the last matrix the characteristic polynomial <span class="process-math">\(p(t)\)</span> is provided for convenience.</p></div>
<div class="exercisegroup-exercises">
<article class="exercise exercise-like" id="exercise-340"><h5 class="heading"><span class="codenumber">1<span class="period">.</span></span></h5>
<p id="p-3154"><span class="process-math">\(A=\begin{amatrix}[rrr]
3\amp 0\amp 0 \\ 0\amp 2\amp 0\\ 0\amp 1\amp 2
\end{amatrix}\)</span></p></article><article class="exercise exercise-like" id="exercise-341"><h5 class="heading"><span class="codenumber">2<span class="period">.</span></span></h5>
<p id="p-3155"><span class="process-math">\(A=\begin{amatrix}[rrr]
-1\amp 4\amp -2\\ -3\amp 4\amp 0\\ -3\amp 1\amp 3
\end{amatrix}\)</span></p></article><article class="exercise exercise-like" id="exercise-342"><h5 class="heading"><span class="codenumber">3<span class="period">.</span></span></h5>
<p id="p-3156"><span class="process-math">\(A=\begin{amatrix}[rrr]
0\amp 0\amp 0\\ 0\amp 0\amp 0 \\ 3\amp 0\amp 1
\end{amatrix}\)</span></p></article><article class="exercise exercise-like" id="exercise-343"><h5 class="heading"><span class="codenumber">4<span class="period">.</span></span></h5>
<p id="p-3157"><span class="process-math">\(A=\begin{amatrix}[rrr]
5\amp 0\amp 0\\ 1\amp 5\amp 0 \\ 0\amp 1\amp 5
\end{amatrix}\)</span></p></article><article class="exercise exercise-like" id="exercise-344"><h5 class="heading"><span class="codenumber">5<span class="period">.</span></span></h5>
<p id="p-3158"><span class="process-math">\(A=\begin{amatrix}[rrr]
19\amp -9\amp -6\\ 25\amp -11\amp -9\\ 17\amp -9\amp -4
\end{amatrix}
\text{;}\)</span> <span class="process-math">\(p(t)=t^3-4t^2+5t-2\)</span></p></article>
</div>
</div>
<article class="exercise exercise-like" id="exercise-345"><h4 class="heading"><span class="codenumber">6<span class="period">.</span></span></h4>
<p id="p-3159">Let <span class="process-math">\(A=\begin{bmatrix} a \amp b \\ c \amp d\end{bmatrix} \text{.}\)</span> Show that <span class="process-math">\(A\)</span> is diagonalizable if and only if either <span class="process-math">\((a-d)^2+4bc\gt 0\)</span> or <span class="process-math">\(A=aI\)</span> (i.e., <span class="process-math">\(a=d\)</span> and <span class="process-math">\(b=c=0\)</span>).</p></article><article class="exercise exercise-like" id="exercise-346"><h4 class="heading"><span class="codenumber">7<span class="period">.</span></span></h4>
<p id="p-3160">Prove <a href="" class="xref" data-knowl="./knowl/th_similarity.html" title="Theorem 5.5.21: Properties of similarity">Theorem 5.5.21</a>.</p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-34" id="hint-34"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-34"><div class="hint solution-like"><p id="p-3161">Show that for any <span class="process-math">\(c\in \R\)</span> we have <span class="process-math">\(cI-P^{-1}AP=P^{-1}(cI-A)P\text{.}\)</span></p></div></div>
</div></article><div class="exercisegroup" id="exercisegroup-38">
<h4 class="heading"><span class="title">Exercise Group.</span></h4>
<div class="introduction" id="introduction-81"><p id="p-3162">For each exercise construct a <span class="process-math">\(3\times 3\)</span> matrix <span class="process-math">\(A\)</span> satisfying the given conditions. Begin by showing that the given <span class="process-math">\(A\)</span> must be diagonalizable.</p></div>
<div class="exercisegroup-exercises">
<article class="exercise exercise-like" id="exercise-347"><h5 class="heading"><span class="codenumber">8<span class="period">.</span></span></h5>
<p id="p-3163"><span class="process-math">\(A\)</span> has eigenspaces <span class="process-math">\(W_2=\Span\{(1,0,1),(1,1,1)\)</span> and <span class="process-math">\(W_{-1}=\Span\{(1,0,-1)\}\text{.}\)</span></p></article><article class="exercise exercise-like" id="exercise-348"><h5 class="heading"><span class="codenumber">9<span class="period">.</span></span></h5>
<p id="p-3164"><span class="process-math">\(A\boldw=\boldw\)</span> for all <span class="process-math">\(\boldw\in W=\{(x,y,z)\colon x+y+z=0\}\text{,}\)</span> <span class="process-math">\(A\boldx=\boldzero\)</span> for <span class="process-math">\(\boldx=(1,1,1)\text{.}\)</span></p></article>
</div>
</div>
<article class="exercise exercise-like" id="exercise-349"><h4 class="heading"><span class="codenumber">10<span class="period">.</span></span></h4>
<p id="p-3165">Assume <span class="process-math">\(A\)</span> is a <span class="process-math">\(3\times 3\)</span> matrix with eigenvalues <span class="process-math">\(0\text{,}\)</span> <span class="process-math">\(1\text{,}\)</span> and <span class="process-math">\(-1\text{.}\)</span></p>
<ol class="lower-alpha">
<li id="li-1020"><p id="p-3166">Show that <span class="process-math">\(A\)</span> is diagonalizable. Provide an explicit diagonal matrix <span class="process-math">\(D\)</span> that <span class="process-math">\(A\)</span> is similar to.</p></li>
<li id="li-1021"><p id="p-3167">Prove that <span class="process-math">\(A^n=A\)</span> for all odd integers <span class="process-math">\(n\geq 1\text{.}\)</span></p></li>
</ol></article><article class="exercise exercise-like" id="exercise-350"><h4 class="heading"><span class="codenumber">11<span class="period">.</span></span></h4>
<p id="p-3168">Prove statement (5) of <a href="" class="xref" data-knowl="./knowl/th_characteristic_polynomial.html" title="Theorem 5.4.25: Characteristic polynomial">Theorem 5.4.25</a>.</p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-35" id="hint-35"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-35"><div class="hint solution-like"><p id="p-3169">Use <a href="" class="xref" data-knowl="./knowl/th_similarity_matrixreps.html" title="Theorem 5.3.28: Similarity and matrix representations">Theorem 5.3.28</a> and <a href="" class="xref" data-knowl="./knowl/th_matrixreps_model.html" title="Theorem 5.2.9: Computing with matrix representations">Theorem 5.2.9</a>.</p></div></div>
</div></article><article class="exercise exercise-like" id="exercise-351"><h4 class="heading"><span class="codenumber">12<span class="period">.</span></span></h4>
<p id="p-3170">Prove statement (6) of <a href="" class="xref" data-knowl="./knowl/th_characteristic_polynomial.html" title="Theorem 5.4.25: Characteristic polynomial">Theorem 5.4.25</a>.</p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-36" id="hint-36"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-36"><div class="hint solution-like"><p id="p-3171">Use <a href="" class="xref" data-knowl="./knowl/th_similarity_matrixreps.html" title="Theorem 5.3.28: Similarity and matrix representations">Theorem 5.3.28</a> and <a href="" class="xref" data-knowl="./knowl/proc_eigenspaces_transformation.html" title="Procedure 5.4.23: Computing eigenspaces of a linear transformation">Procedure 5.4.23</a>.</p></div></div>
</div></article><article class="exercise exercise-like" id="exercise-352"><h4 class="heading"><span class="codenumber">13<span class="period">.</span></span></h4>
<p id="p-3172">According to <a href="" class="xref" data-knowl="./knowl/th_similarity.html" title="Theorem 5.5.21: Properties of similarity">Theorem 5.5.21</a> if <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> are similar, then they have the same rank. Show that the converse is false by showing that the matrices</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_similarity.html">
\begin{equation*}
A=\begin{amatrix}[rr]
1\amp 0\\ 0\amp 0
\end{amatrix}, B=\begin{amatrix}[rr]
0\amp 1\\ 0\amp 0
\end{amatrix}
\end{equation*}
</div>
<p class="continuation">have the same rank, but are not similar.</p></article><article class="exercise exercise-like" id="exercise-353"><h4 class="heading"><span class="codenumber">14<span class="period">.</span></span></h4>
<p id="p-3173">According to <a href="" class="xref" data-knowl="./knowl/th_similarity.html" title="Theorem 5.5.21: Properties of similarity">Theorem 5.5.21</a> if <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> are similar, then they have the same characteristic polynomial. Show that the converse is false by showing that the matrices</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_similarity.html">
\begin{equation*}
A=\begin{amatrix}[rr]
1\amp 1\\ 0\amp 1
\end{amatrix}, B=\begin{amatrix}[rr]
1\amp 0\\ 0\amp 1
\end{amatrix}
\end{equation*}
</div>
<p class="continuation">have the same characteristic polynomial, but are not similar.</p></article><article class="exercise exercise-like" id="exercise-354"><h4 class="heading"><span class="codenumber">15<span class="period">.</span></span></h4>
<p id="p-3174">Prove all statements of <a href="" class="xref" data-knowl="./knowl/th_conjugation.html" title="Theorem 5.5.23: Properties of conjugation">Theorem 5.5.23</a>.</p></article><article class="exercise exercise-like" id="exercise-355"><h4 class="heading"><span class="codenumber">16<span class="period">.</span></span></h4>
<p id="p-3175">In each case information about a matrix <span class="process-math">\(A\)</span> is given. Decide whether <span class="process-math">\(A\)</span> is diagonalizable.</p>
<ol class="lower-alpha">
<li id="li-1022"><p id="p-3176"><span class="process-math">\(A\in M_{33}\text{,}\)</span> <span class="process-math">\(p(t)=\det(tI-A)=t^3-t^2\text{,}\)</span> <span class="process-math">\(\nullity A=2\)</span></p></li>
<li id="li-1023"><p id="p-3177"><span class="process-math">\(A\in M_{33}\text{,}\)</span> <span class="process-math">\(p(t)=\det(tI-A)=t^3+t^2-t\)</span></p></li>
<li id="li-1024">
<p id="p-3178"><span class="process-math">\(A\in M_{22}\text{,}\)</span> <span class="process-math">\(\tr A=4\text{,}\)</span> <span class="process-math">\(\det A=3\)</span></p>
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-37" id="hint-37"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-37"><div class="hint solution-like"><p id="p-3179">See <a href="" class="xref" data-knowl="./knowl/rm_char_poly_trick.html" title="Remark 5.4.26: Characteristic polynomial for 2\times 2 matrices">Remark 5.4.26</a>.</p></div></div>
</li>
</ol></article><article class="exercise exercise-like" id="ex_diagonalization"><h4 class="heading"><span class="codenumber">17<span class="period">.</span></span></h4>
<p id="p-3180">Each matrix <span class="process-math">\(A\)</span> below has characteristic polynomial <span class="process-math">\(p(t)=t^3-3t+2\text{.}\)</span> Use <a href="" class="xref" data-knowl="./knowl/proc_diagonalize.html" title="Procedure 5.5.14: Deciding whether a linear transformation is diagonalizable">Procedure 5.5.14</a> to decide whether <span class="process-math">\(A\)</span> is diagonalizable. If yes, provide an inverible <span class="process-math">\(P\)</span> and diagonal <span class="process-math">\(D\)</span> satisfying <span class="process-math">\(D=P^{-1}AP\text{.}\)</span></p>
<ol class="lower-alpha">
<li id="li-1025"><p id="p-3181"><span class="process-math">\(\displaystyle A=\begin{amatrix}[rrr]
-5\amp 0\amp 3\\ -6\amp 1\amp 3\\ -6\amp 0\amp 4
\end{amatrix}\)</span></p></li>
<li id="li-1026"><p id="p-3182"><span class="process-math">\(\displaystyle A=\begin{amatrix}[rrr]
-2\amp -3\amp -3\\ -3\amp -3\amp 4\\ -3\amp -4\amp 5
\end{amatrix}\)</span></p></li>
</ol></article><article class="exercise exercise-like" id="exercise-357"><h4 class="heading"><span class="codenumber">18<span class="period">.</span></span></h4>
<p id="p-3183">Let</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/ex_diagonalization.html">
\begin{equation*}
A=\begin{amatrix}[rrr]
-5\amp 0\amp 3\\ -6\amp 1\amp 3\\ -6\amp 0\amp 4
\end{amatrix}\text{.}
\end{equation*}
</div>
<p class="continuation">Use your work from <a href="" class="xref" data-knowl="./knowl/ex_diagonalization.html" title="Exercise 5.5.5.17">Exercise 5.5.5.17</a> to find a matrix <span class="process-math">\(C\)</span> satisfying <span class="process-math">\(C^3=A\text{.}\)</span></p></article></section></section><div class="hidden-content tex2jax_ignore" id="hk-fn-6"><div class="fn">That we can find a minimal <span class="process-math">\(r\)</span> in this sense is plausible enough, but we are secretly using the well-ordering principle of the integers here.</div></div>
</div></main>
</div>
</body>
</html>
