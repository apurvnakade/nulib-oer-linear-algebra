<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*       on 2022-02-07T10:10:51-06:00       *-->
<!--*   A recent stable commit (2020-08-09):   *-->
<!--* 98f21740783f166a773df4dc83cab5293ab63a4a *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Span and linear independence</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<script>window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    useLabelIds: true,
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore",
    processHtmlClass: "has_am",
  },
  chtml: {
    scale: 0.88,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/lib/jquery.min.js"></script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/0.13/pretext.js"></script><script xmlns:svg="http://www.w3.org/2000/svg">miniversion=0.6</script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/0.13/pretext_add_on.js?x=1"></script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script xmlns:svg="http://www.w3.org/2000/svg">sagecellEvalName='Evaluate (Sage)';
</script><link xmlns:svg="http://www.w3.org/2000/svg" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/pretext.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/pretext_add_on.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/banner_default.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/toc_default.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/knowls_default.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/style_default.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/colors_default.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/setcolors.css" rel="stylesheet" type="text/css">
<!-- 2019-10-12: Temporary - CSS file for experiments with styling --><link xmlns:svg="http://www.w3.org/2000/svg" href="developer.css" rel="stylesheet" type="text/css">
</head>
<body class="pretext-book has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div xmlns:svg="http://www.w3.org/2000/svg" id="latex-macros" class="hidden-content" style="display:none">\(\require{cancel}\newcommand{\Z}{{\mathbb Z}}
\newcommand{\Q}{{\mathbb Q}}
\newcommand{\R}{{\mathbb R}}
\newcommand{\C}{{\mathbb C}}
\newcommand{\T}{{\mathbb T}}
\newcommand{\F}{{\mathbb F}}
\newcommand{\HH}{{\mathbb H}}
\newcommand{\compose}{\circ}
\newcommand{\bolda}{{\mathbf a}}
\newcommand{\boldb}{{\mathbf b}}
\newcommand{\boldc}{{\mathbf c}}
\newcommand{\boldd}{{\mathbf d}}
\newcommand{\bolde}{{\mathbf e}}
\newcommand{\boldi}{{\mathbf i}}
\newcommand{\boldj}{{\mathbf j}}
\newcommand{\boldk}{{\mathbf k}}
\newcommand{\boldn}{{\mathbf n}}
\newcommand{\boldp}{{\mathbf p}}
\newcommand{\boldq}{{\mathbf q}}
\newcommand{\boldr}{{\mathbf r}}
\newcommand{\bolds}{{\mathbf s}}
\newcommand{\boldt}{{\mathbf t}}
\newcommand{\boldu}{{\mathbf u}}
\newcommand{\boldv}{{\mathbf v}}
\newcommand{\boldw}{{\mathbf w}}
\newcommand{\boldx}{{\mathbf x}}
\newcommand{\boldy}{{\mathbf y}}
\newcommand{\boldz}{{\mathbf z}}
\newcommand{\boldzero}{{\mathbf 0}}
\newcommand{\boldmod}{\boldsymbol{ \bmod }}
\newcommand{\boldT}{{\mathbf T}}
\newcommand{\boldN}{{\mathbf N}}
\newcommand{\boldB}{{\mathbf B}}
\newcommand{\boldF}{{\mathbf F}}
\newcommand{\boldS}{{\mathbf S}}
\newcommand{\boldG}{{\mathbf G}}
\newcommand{\boldK}{{\mathbf K}}
\newcommand{\boldL}{{\mathbf L}}
\DeclareMathOperator{\lcm}{lcm}
\DeclareMathOperator{\Span}{span}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\NS}{null}
\DeclareMathOperator{\RS}{row}
\DeclareMathOperator{\CS}{col}
\DeclareMathOperator{\im}{im}
\DeclareMathOperator{\range}{range}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\nullity}{nullity}
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Fix}{Fix}
\DeclareMathOperator{\Aff}{Aff}
\DeclareMathOperator{\Frac}{Frac}
\DeclareMathOperator{\Ann}{Ann}
\DeclareMathOperator{\Tor}{Tor}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\mdeg}{mdeg}
\DeclareMathOperator{\Lt}{Lt}
\DeclareMathOperator{\Lc}{Lc}
\DeclareMathOperator{\disc}{disc}
\DeclareMathOperator{\Frob}{Frob}
\DeclareMathOperator{\adj}{adj}
\DeclareMathOperator{\curl}{curl}
\DeclareMathOperator{\grad}{grad}
\DeclareMathOperator{\diver}{div}
\DeclareMathOperator{\flux}{flux}
\def\Gal{\operatorname{Gal}}
\def\ord{\operatorname{ord}}
\def\ML{\operatorname{M}}
\def\GL{\operatorname{GL}}
\def\PGL{\operatorname{PGL}}
\def\SL{\operatorname{SL}}
\def\PSL{\operatorname{PSL}}
\def\GSp{\operatorname{GSp}}
\def\PGSp{\operatorname{PGSp}}
\def\Sp{\operatorname{Sp}}
\def\PSp{\operatorname{PSp}}
\def\Aut{\operatorname{Aut}}
\def\Inn{\operatorname{Inn}}
\def\Hom{\operatorname{Hom}}
\def\End{\operatorname{End}}
\def\ch{\operatorname{char}}
\def\Zp{\Z/p\Z}
\def\Zm{\Z/m\Z}
\def\Zn{\Z/n\Z}
\def\Fp{\F_p}
\newcommand{\surjects}{\twoheadrightarrow}
\newcommand{\injects}{\hookrightarrow}
\newcommand{\bijects}{\leftrightarrow}
\newcommand{\isomto}{\overset{\sim}{\rightarrow}}
\newcommand{\floor}[1]{\lfloor#1\rfloor}
\newcommand{\ceiling}[1]{\left\lceil#1\right\rceil}
\newcommand{\mclass}[2][m]{[#2]_{#1}}
\newcommand{\val}[2][]{\left\lvert #2\right\rvert_{#1}}
\newcommand{\valuation}[2][]{\left\lvert #2\right\rvert_{#1}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\anpoly}{a_nx^n+a_{n-1}x^{n-1}\cdots +a_1x+a_0}
\newcommand{\anmonic}{x^n+a_{n-1}x^{n-1}\cdots +a_1x+a_0}
\newcommand{\bmpoly}{b_mx^m+b_{m-1}x^{m-1}\cdots +b_1x+b_0}
\newcommand{\pder}[2]{\frac{\partial#1}{\partial#2}}
\newcommand{\normalin}{\trianglelefteq}
\newcommand{\angvec}[1]{\langle #1\rangle}
\newcommand{\varpoly}[2]{#1_{#2}x^{#2}+#1_{#2-1}x^{#2-1}\cdots +#1_1x+#1_0}
\newcommand{\varpower}[1][a]{#1_0+#1_1x+#1_1x^2+\cdots}
\newcommand{\limasto}[2][x]{\lim_{#1\rightarrow #2}}
\def\ntoinfty{\lim_{n\rightarrow\infty}}
\def\xtoinfty{\lim_{x\rightarrow\infty}}
\def\ii{\item}
\def\bb{\begin{enumerate}}
\def\ee{\end{enumerate}}
\def\ds{\displaystyle}
\def\p{\partial}
\newcommand{\abcdmatrix}[4]{\begin{bmatrix}#1\amp #2\\ #3\amp #4 \end{bmatrix}
}
\newenvironment{amatrix}[1][ccc|c]{\left[\begin{array}{#1}}{\end{array}\right]}
\newenvironment{linsys}[2][m]{
\begin{array}[#1]{@{}*{#2}{rc}r@{}}
}{
\end{array}}
\newcommand{\eqsys}{\begin{array}{rcrcrcr}
a_{11}x_{1}\amp +\amp a_{12}x_{2}\amp +\cdots+\amp  a_{1n}x_{n}\amp =\amp b_1\\
a_{21}x_{1}\amp +\amp a_{22}x_{2}\amp +\cdots+\amp a_{2n}x_{n}\amp =\amp b_2\\
\amp \vdots\amp   \amp \vdots \amp  \amp \vdots \amp  \vdots\\
a_{m1}x_{1}\amp +\amp a_{m2}x_{2}\amp +\cdots +\amp a_{mn}x_{n}\amp =\amp b_m
\end{array}
}
\newcommand{\numeqsys}{\begin{array}{rrcrcrcr}
e_1:\amp  a_{11}x_{1}\amp +\amp a_{12}x_{2}\amp +\cdots+\amp  a_{1n}x_{n}\amp =\amp b_1\\
e_2: \amp a_{21}x_{1}\amp +\amp a_{22}x_{2}\amp +\cdots+\amp a_{2n}x_{n}\amp =\amp b_2\\
\amp \vdots\amp   \amp \vdots \amp  \amp \vdots \amp  \vdots\\
e_m: \amp a_{m1}x_{1}\amp +\amp a_{m2}x_{2}\amp +\cdots +\amp a_{mn}x_{n}\amp =\amp b_m
\end{array}
}
\newcommand{\homsys}{\begin{array}{rcrcrcr}
a_{11}x_{1}\amp +\amp a_{12}x_{2}\amp +\cdots+\amp  a_{1n}x_{n}\amp =\amp 0\\
a_{21}x_{1}\amp +\amp a_{22}x_{2}\amp +\cdots+\amp a_{2n}x_{n}\amp =\amp 0\\
\amp \vdots\amp   \amp \vdots \amp  \amp \vdots \amp  \vdots\\
a_{m1}x_{1}\amp +\amp a_{m2}x_{2}\amp +\cdots +\amp a_{mn}x_{n}\amp =\amp 0
\end{array}
}
\newcommand{\vareqsys}[4]{
\begin{array}{ccccccc}
#3_{11}x_{1}\amp +\amp #3_{12}x_{2}\amp +\cdots+\amp  #3_{1#2}x_{#2}\amp =\amp #4_1\\
#3_{21}x_{1}\amp +\amp #3_{22}x_{2}\amp +\cdots+\amp #3_{2#2}x_{#2}\amp =\amp #4_2\\
\vdots \amp \amp \vdots \amp  \amp \vdots \amp =\amp  \vdots\\
#3_{#1 1}x_{1}\amp +\amp #3_{#1 2}x_{2}\amp +\cdots +\amp #3_{#1 #2}x_{#2}\amp =\amp #4_{#1}
\end{array}
}
\newcommand{\genmatrix}[1][a]{
\begin{bmatrix}
#1_{11} \amp  #1_{12} \amp  \cdots \amp  #1_{1n} \\
#1_{21} \amp  #1_{22} \amp  \cdots \amp  #1_{2n} \\
\vdots  \amp  \vdots  \amp  \ddots \amp  \vdots  \\
#1_{m1} \amp  #1_{m2} \amp  \cdots \amp  #1_{mn}
\end{bmatrix}
}
\newcommand{\varmatrix}[3]{
\begin{bmatrix}
#3_{11} \amp  #3_{12} \amp  \cdots \amp  #3_{1#2} \\
#3_{21} \amp  #3_{22} \amp  \cdots \amp  #3_{2#2} \\
\vdots  \amp  \vdots  \amp  \ddots \amp  \vdots  \\
#3_{#1 1} \amp  #3_{#1 2} \amp  \cdots \amp  #3_{#1 #2}
\end{bmatrix}
}
\newcommand{\augmatrix}{
\begin{amatrix}[cccc|c]
a_{11} \amp  a_{12} \amp  \cdots \amp  a_{1n} \amp b_{1}\\
a_{21} \amp  a_{22} \amp  \cdots \amp  a_{2n} \amp b_{2}\\
\vdots  \amp  \vdots  \amp  \ddots \amp  \vdots  \amp \vdots\\
a_{m1} \amp  a_{m2} \amp  \cdots \amp  a_{mn}\amp b_{m}
\end{amatrix}
}
\newcommand{\varaugmatrix}[4]{
\begin{amatrix}[cccc|c]
#3_{11} \amp  #3_{12} \amp  \cdots \amp  #3_{1#2} \amp #4_{1}\\
#3_{21} \amp  #3_{22} \amp  \cdots \amp  #3_{2#2} \amp #4_{2}\\
\vdots  \amp  \vdots  \amp  \ddots \amp  \vdots  \amp \vdots\\
#3_{#1 1} \amp  #3_{#1 2} \amp  \cdots \amp  #3_{#1 #2}\amp #4_{#1}
\end{amatrix}
}
\newcommand{\spaceforemptycolumn}{\makebox[\wd\boxofmathplus]{\ }}

\newcommand{\generalmatrix}[3]{
\left(
\begin{array}{cccc}
#1_{1,1}  \amp #1_{1,2}  \amp \ldots  \amp #1_{1,#2}  \\
#1_{2,1}  \amp #1_{2,2}  \amp \ldots  \amp #1_{2,#2}  \\
\amp \vdots                         \\
#1_{#3,1} \amp #1_{#3,2} \amp \ldots  \amp #1_{#3,#2}
\end{array}
\right)  }
\newcommand{\colvec}[2][c]{\begin{bmatrix}[#1] #2 \end{bmatrix}}
\DeclareMathOperator{\size}{size}
\DeclareMathOperator{\adjoint}{adj}
\DeclareMathOperator{\sgn}{sgn}
\newcommand{\restrictionmap}[2]{{#1}\mathpunct\upharpoonright\hbox{}_{#2}}
\renewcommand{\emptyset}{\varnothing}

\newcommand{\proj}[2]{\mbox{proj}_{#2}({#1}) }
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\)</div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href="http://linear-algebra.northwestern.pub/" target="_blank"><img src="external/images/im_holycomm.svg" alt="Logo image"></a><div class="title-container">
<h1 class="heading"><a href="book-1.html"><span class="title">Linear algebra: the theory of vector spaces and linear transformations</span></a></h1>
<p class="byline">Aaron Greicius</p>
</div>
</div></div>
<nav xmlns:svg="http://www.w3.org/2000/svg" id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<a class="index-button toolbar-item button" href="index-1.html" title="Index">Index</a><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="s_subspace.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="c_vectorspace.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="s_basis_dimension.html" title="Next">Next</a></span>
</div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="s_subspace.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="c_vectorspace.html" title="Up">Up</a><a class="next-button button toolbar-item" href="s_basis_dimension.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div xmlns:svg="http://www.w3.org/2000/svg" id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link frontmatter"><a href="frontmatter-1.html" data-scroll="frontmatter-1"><span class="title">Front Matter</span></a></li>
<li class="link">
<a href="c_foundations.html" data-scroll="c_foundations"><span class="codenumber">1</span> <span class="title">Foundations</span></a><ul>
<li><a href="s_sets_functions.html" data-scroll="s_sets_functions">Sets and functions</a></li>
<li><a href="s_logic.html" data-scroll="s_logic">Logic</a></li>
<li><a href="s_proof_technique.html" data-scroll="s_proof_technique">Proof techniques</a></li>
</ul>
</li>
<li class="link">
<a href="c_linear_systems.html" data-scroll="c_linear_systems"><span class="codenumber">2</span> <span class="title">Systems of linear equations</span></a><ul>
<li><a href="s_systems.html" data-scroll="s_systems">Systems of linear equations</a></li>
<li><a href="s_ge.html" data-scroll="s_ge">Gaussian elimination</a></li>
<li><a href="s_solving.html" data-scroll="s_solving">Solving linear systems</a></li>
</ul>
</li>
<li class="link">
<a href="c_matrices.html" data-scroll="c_matrices"><span class="codenumber">3</span> <span class="title">Matrices, their arithmetic, and their algebra</span></a><ul>
<li><a href="s_matrix.html" data-scroll="s_matrix">Matrices and their arithmetic</a></li>
<li><a href="s_algebraic.html" data-scroll="s_algebraic">Algebra of matrices</a></li>
<li><a href="s_invertible_matrices.html" data-scroll="s_invertible_matrices">Invertible matrices</a></li>
<li><a href="s_invertibility_theorem.html" data-scroll="s_invertibility_theorem">The invertibility theorem</a></li>
<li><a href="s_det.html" data-scroll="s_det">The determinant</a></li>
</ul>
</li>
<li class="link">
<a href="c_vectorspace.html" data-scroll="c_vectorspace"><span class="codenumber">4</span> <span class="title">Vector spaces and linear transformations</span></a><ul>
<li><a href="s_vectorspace.html" data-scroll="s_vectorspace">Real vector spaces</a></li>
<li><a href="s_transformation.html" data-scroll="s_transformation">Linear transformations</a></li>
<li><a href="s_subspace.html" data-scroll="s_subspace">Subspaces</a></li>
<li><a href="s_span_independence.html" data-scroll="s_span_independence" class="active">Span and linear independence</a></li>
<li><a href="s_basis_dimension.html" data-scroll="s_basis_dimension">Bases and dimension</a></li>
<li><a href="s_rank_nullity.html" data-scroll="s_rank_nullity">Rank-nullity theorem and fundamental spaces</a></li>
<li><a href="s_isom.html" data-scroll="s_isom">Isomorphisms</a></li>
</ul>
</li>
<li class="link">
<a href="c_innerproductspaces.html" data-scroll="c_innerproductspaces"><span class="codenumber">5</span> <span class="title">Inner product spaces</span></a><ul>
<li><a href="s_innerproducts.html" data-scroll="s_innerproducts">Inner product spaces</a></li>
<li><a href="s_orthogonality.html" data-scroll="s_orthogonality">Orthogonal bases and orthogonal projection</a></li>
</ul>
</li>
<li class="link">
<a href="c_transbasis.html" data-scroll="c_transbasis"><span class="codenumber">6</span> <span class="title">Eigenvectors and diagonalization</span></a><ul>
<li><a href="s_coordinatevectors_isomorphisms.html" data-scroll="s_coordinatevectors_isomorphisms">Coordinate vectors and isomorphisms</a></li>
<li><a href="s_matrixreps.html" data-scroll="s_matrixreps">Matrix representations of linear transformations</a></li>
<li><a href="s_changeofbasis.html" data-scroll="s_changeofbasis">Change of basis</a></li>
<li><a href="ss_eigenvectors.html" data-scroll="ss_eigenvectors">Eigenvectors and eigenvalues</a></li>
<li><a href="ss_diagonalization.html" data-scroll="ss_diagonalization">Diagonalization</a></li>
</ul>
</li>
<li class="link backmatter"><a href="backmatter-1.html" data-scroll="backmatter-1"><span class="title">Back Matter</span></a></li>
<li class="link"><a href="appendix-notation.html" data-scroll="appendix-notation"><span class="codenumber">A</span> <span class="title">Notation</span></a></li>
<li class="link"><a href="appendix-defs.html" data-scroll="appendix-defs"><span class="codenumber">B</span> <span class="title">Definitions</span></a></li>
<li class="link"><a href="appendix-thms.html" data-scroll="appendix-thms"><span class="codenumber">C</span> <span class="title">Theory and procedures</span></a></li>
<li class="link"><a href="appendix-egs.html" data-scroll="appendix-egs"><span class="codenumber">D</span> <span class="title">Examples</span></a></li>
<li class="link"><a href="appendix-vids.html" data-scroll="appendix-vids"><span class="codenumber">E</span> <span class="title">Video examples and figures</span></a></li>
<li class="link"><a href="index-1.html" data-scroll="index-1"><span class="title">Index</span></a></li>
</ul></nav><div class="extras"><nav><a class="pretext-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content"><section xmlns:svg="http://www.w3.org/2000/svg" class="section" id="s_span_independence"><h2 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber">4.4</span> <span class="title">Span and linear independence</span>
</h2>
<section class="introduction" id="introduction-32"><p id="p-1245">There are many situations in mathematics where we want to describe an infinite set in a concise manner. We saw this at work already in <a href="s_solving.html" class="internal" title="Section 2.3: Solving linear systems">Section 2.3</a>, where infinite sets of solutions to linear systems were neatly described with parametric expressions.</p>
<p id="p-1246">A similar issue arises when describing vector spaces and their subspaces. As we know, any vector space is either the zero space or infinite (<a href="" class="xref" data-knowl="./knowl/ex_vs_zero_or_infinite.html" title="Exercise 4.1.4.11">Exercise 4.1.4.11</a>). If we happen to be dealing with a subspace of \(\R^n\text{,}\) then there is the possibility of giving a parametric description; but how do we proceed when working in one of our more exotic vector spaces like \(C^1(\R)\text{?}\)</p>
<p id="p-1247">As we will see in <a href="s_basis_dimension.html" class="internal" title="Section 4.5: Bases and dimension">Section 4.5</a> the relevant linear algebraic tool for this purpose is the concept of a <em class="emphasis">basis</em>. Loosely speaking, a basis for a vector space \(V\) is a set of vectors that is large enough to <em class="emphasis">generate</em> the entire space, and small enough to contain <em class="emphasis">no redundancies</em>. What exactly we mean by “generate” is captured by the rigorous notion of <em class="emphasis">span</em>; and what we mean by “no redundancies” is captured by <em class="emphasis">linear independence</em>.</p></section><section class="subsection" id="subsection-42"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.4.1</span> <span class="title">Span</span>
</h3>
<p id="p-1248">Recall that a linear combination in a vector space \(V\) is a vector of the form</p>
<div class="displaymath">
\begin{equation*}
\boldv=c_1\boldv_1+c_2\boldv_2\cdots +c_r\boldv_r\text{,}
\end{equation*}
</div>
<p class="continuation">where \(c_i\in \R\) are scalars. We use this notion to define the <em class="emphasis">span</em> of a set of vectors.</p>
<article class="definition definition-like" id="d_span"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">4.4.1</span><span class="period">.</span><span class="space"> </span><span class="title">Span.</span>
</h4>
<p id="p-1249">Let \(V\) be a vector space, and let \(S\subseteq V\) be any subset of \(V\text{.}\) The <dfn class="terminology">span of \(S\)</dfn>, denoted \(\Span S\text{,}\) is the subset of \(V\) defined as follows:</p>
<ul class="disc">
<li id="li-363"><p id="p-1250">If \(S=\emptyset\text{,}\) then \(\Span S=\{\boldzero_V\}\text{.}\)</p></li>
<li id="li-364">
<p id="p-1251">Otherwise we define \(\Span S\) to be the set of all linear combinations of elements of \(S\text{:}\) i.e.,</p>
<div class="displaymath">
\begin{equation*}
\Span S=\{\boldv\in V\colon \boldv=c_1\boldv_1+c_2\boldv_2\cdots +c_r\boldv_r \text{ for some } \boldv_i\in S \text{ and } c_i\in \R\}\text{.}
\end{equation*}
</div>
</li>
</ul></article><article class="remark remark-like" id="rm_span"><h4 class="heading">
<span class="type">Remark</span><span class="space"> </span><span class="codenumber">4.4.2</span><span class="period">.</span>
</h4>
<p id="p-1252">Let \(S\) be a subset of \(V\text{.}\) Some simple observations:</p>
<ol class="decimal">
<li id="li-365"><p id="p-1253">The zero vector is always an element of \(\Span S\text{.}\)  Indeed, if \(S=\emptyset\text{,}\) then \(\Span S=\{\boldzero\}\) by definition. Otherwise, given any \(\boldv\in S\text{,}\) the linear combination \(0\boldv=\boldzero\) is an element of \(\Span S\text{.}\)</p></li>
<li id="li-366"><p id="p-1254">We have \(S\subseteq \Span S\text{:}\) i.e., \(\Span S\) includes \(S\) itself. Indeed, given any \(\boldv\in S\text{,}\) the linear combination \(1\boldv=\boldv\) is an element of \(\Span S\text{.}\)</p></li>
<li id="li-367">
<p id="p-1255">If \(S=\{\boldv\}\) contains exactly one element, then \(\Span S=\{c\boldv\colon c\in \R\}\) is simply the set of all scalar multiples of \(\boldv\text{.}\)</p>
<p id="p-1256">If \(\boldv\ne \boldzero\text{,}\) then we know that this set is infinite (<a href="" class="xref" data-knowl="./knowl/ex_vs_zero_or_infinite.html" title="Exercise 4.1.4.11">Exercise 4.1.4.11</a>). Thus even when \(S\) is <em class="emphasis">finite</em>, \(\Span S\) will be <em class="emphasis">infinite</em>, as long as \(S\) contains nonzero vectors.</p>
</li>
</ol></article><article class="example example-like" id="eg_span_2space"><a href="" data-knowl="" class="id-ref example-knowl original" data-refid="hk-eg_span_2space"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.4.3</span><span class="period">.</span><span class="space"> </span><span class="title">Examples in \(\R^2\).</span>
</h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-eg_span_2space"><article class="example example-like"><p id="p-1257">Let \(V=\R^2\text{.}\) For each \(S\text{,}\) identify \(\Span S\) as a familiar geometric object.</p>
<ol class="decimal">
<li id="li-368"><p id="p-1258">\(S=\{ \}\text{.}\)</p></li>
<li id="li-369"><p id="p-1259">\(\displaystyle S=\{(0,0)\}\)</p></li>
<li id="li-370"><p id="p-1260">\(S=\{\boldv\}\text{,}\) \(\boldv=(a,b)\ne (0,0)\)</p></li>
<li id="li-371"><p id="p-1261">\(\displaystyle S=\{ (1,0), (0,1)\}\)</p></li>
<li id="li-372"><p id="p-1262">\(\displaystyle S=\{ (1,1), (2,2)\}\)</p></li>
<li id="li-373"><p id="p-1263">\(\displaystyle S=\{(1,1),(1,2)\}\)</p></li>
<li id="li-374"><p id="p-1264">\(\displaystyle S=\R^2\)</p></li>
</ol>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-43" id="solution-43"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-43"><div class="solution solution-like"><ol id="p-1265" class="decimal">
<li id="li-375"><p id="p-1266">\(\Span S=\{\boldzero\}\text{,}\) the set containing just the origin, by definition.</p></li>
<li id="li-376"><p id="p-1267">\(\Span S\) is the set of all scalar multiples of \((0,0)\text{.}\) Thus \(\Span S=\{\boldzero\}\text{.}\)</p></li>
<li id="li-377"><p id="p-1268">\(\Span S\) is the set of all scalar multiples of the nonzero vector \((a,b)\text{.}\) Geometrically, this is the line that passes through the the origin and the point \((a,b)\text{.}\)</p></li>
<li id="li-378">
<p id="p-1269">By definition</p>
<div class="displaymath">
\begin{equation*}
S=\{a(1,0)+b(0,1)\colon a,b\in \R\}=\{(a,b)\colon a,b\in\R\}\text{.}
\end{equation*}
</div>
<p class="continuation">Thus \(S=\R^2\text{,}\) the entire \(xy\)-plane.</p>
</li>
<li id="li-379">
<p id="p-1270">By definition</p>
<div class="displaymath">
\begin{equation*}
S=\{a(1,1)+b(2,2)\colon a,b\in \R\}=\{(a+2b,a+2b)\colon a,b\in\R\}\text{.}
\end{equation*}
</div>
<p class="continuation">It is easy to see that \(S=\{(c,c)\colon t\in \R\}\text{,}\) the line with equation \(y=x\text{.}\) Note that in this case we have</p>
<div class="displaymath">
\begin{equation*}
S=\Span\{(1,1), (2,2)\}=\Span \{(1,1)\}\text{,}
\end{equation*}
</div>
<p class="continuation">and thus that the vector \((2,2)\) is in some sense redundant.</p>
</li>
<li id="li-380">
<p id="p-1271">By definition</p>
<div class="displaymath">
\begin{equation*}
S=\{a(1,1)+b(1,2)\colon a,b\in \R\}=\{(a+b,a+2b)\colon a,b\in\R\}\text{.}
\end{equation*}
</div>
<p class="continuation">Claim: \(\Span S=\R^2\text{.}\) Proving the claim amounts to showing that for all \((c,d)\in \R^2\) there exist \(a,b\in \R\) such that</p>
<div class="displaymath">
\begin{equation*}
\begin{array}{ccccc}
a \amp +\amp b \amp =\amp c\\
a \amp +\amp 2b \amp =\amp d
\end{array}\text{.}
\end{equation*}
</div>
<p class="continuation">Solving this system using Gaussian elimination, we see that the system has the unique solution</p>
<div class="displaymath">
\begin{align*}
a\amp =2c-d \amp b\amp =d-c\text{,}
\end{align*}
</div>
<p class="continuation">and thus that</p>
<div class="displaymath">
\begin{equation*}
(2c-d)(1,1)+(d-c)(1,2)=(c,d)\text{.}
\end{equation*}
</div>
<p class="continuation">This proves \(\Span S=\R^2\text{,}\) as claimed.</p>
</li>
<li id="li-381"><p id="p-1272">By <a href="" class="xref" data-knowl="./knowl/rm_span.html" title="Remark 4.4.2">Remark 4.4.2</a>, we have \(S\subseteq \Span S\text{.}\) Thus \(\R^2\subseteq \Span \R^2\text{.}\) Since \(\Span \R^2\subseteq \R^2\) by definition, we conclude that \(\Span S=\R^2\text{.}\)</p></li>
</ol></div></div>
</div></article></div>
<p id="p-1273">You may have noticed that each span computation in the previous example produced a subspace of \(\R^2\text{.}\) This is no accident!</p>
<article class="theorem theorem-like" id="th_span"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">4.4.4</span><span class="period">.</span><span class="space"> </span><span class="title">Spans are subspaces.</span>
</h4>
<p id="p-1274">Let \(S\) be a subset of the vector space \(V\text{.}\)</p>
<ol class="decimal">
<li id="li-382"><p id="p-1275">The set \(\Span S\) is a subspace of \(V\text{.}\)</p></li>
<li id="li-383"><p id="p-1276">If \(W\) is any subspace containing \(S\text{,}\) then \(\Span S\subseteq W\text{.}\)</p></li>
</ol>
<p class="continuation">Taken together, (1) and (2) imply that \(\Span S\) is the <em class="emphasis">smallest subspace of \(V\) containing \(S\)</em>.</p></article><article class="hiddenproof" id="proof-53"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-53"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-53"><article class="hiddenproof"><p id="p-1277">We prove each statement separately.</p>
<article class="case" id="case-87"><h5 class="heading">Statement (1).</h5>
<p id="p-1278">To show \(\Span S\) is a subspace, we use the two-step technique.</p>
<ol class="decimal">
<li id="li-384"><p id="p-1279">By <a href="" class="xref" data-knowl="./knowl/rm_span.html" title="Remark 4.4.2">Remark 4.4.2</a> we know that \(\boldzero\in \Span S \text{.}\)</p></li>
<li id="li-385">
<p id="p-1280">Suppose \(\boldv, \boldw\in S\text{.}\) By definition we have</p>
<div class="displaymath">
\begin{align*}
\boldv \amp =c_1\boldv_1+c_2\boldv_2+\cdots +c_r\boldv_r \amp \boldw \amp = c_{r+1}\boldv_{r+1}+c_{r+2}\boldv_{r+2}+\cdots +c_{r+s}\boldv_{r+s}
\end{align*}
</div>
<p class="continuation">for some vectors \(\boldv_1, \boldv_2, \dots, \boldv_{r+s}\in S\) and scalars \(c_1,c_2,\dots, c_{r+s}\text{.}\) Then for any \(c,d\in \R\) we have</p>
<div class="displaymath">
\begin{equation*}
c\boldv+d\boldw=cc_1\boldv_1+cc_2\boldv_2+\cdots +cc_r\boldv_r+dc_{r+1}\boldv_{r+1}+dc_{r+2}\boldv_{r+2}+\cdots +dc_{r+s}\boldv_{r+s}\text{,}
\end{equation*}
</div>
<p class="continuation">which is clearly a linear combination of elements of \(S\text{.}\) Thus \(c\boldv+d\boldw\in \Span S\text{,}\) as desired.</p>
</li>
</ol></article><article class="case" id="case-88"><h5 class="heading">Statement (2).</h5>
<p id="p-1281">Let \(W\subseteq V\) be a subspace that contains all elements of \(S\text{.}\) Since \(W\) is closed under arbitrary linear combinations, it must contain any linear combination of elements of \(S\text{,}\) and thus \(\Span S\subseteq W\text{.}\)</p></article></article></div>
<p id="p-1282">The results of <a href="" class="xref" data-knowl="./knowl/th_span.html" title="Theorem 4.4.4: Spans are subspaces">Theorem 4.4.4</a> motivate the following additional terminology.</p>
<article class="definition definition-like" id="d_spanning_set"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">4.4.5</span><span class="period">.</span><span class="space"> </span><span class="title">Spanning set.</span>
</h4>
<p id="p-1283">Let \(S\)  be a subset of the vector space \(V\text{.}\) We call \(W=\Span S\) the subspace of \(V\) <dfn class="terminology">generated by S</dfn>, and we call \(S\) a <dfn class="terminology">spanning set</dfn> for \(W\text{.}\)</p></article><article class="remark remark-like" id="rm_spanning_sets"><h4 class="heading">
<span class="type">Remark</span><span class="space"> </span><span class="codenumber">4.4.6</span><span class="period">.</span><span class="space"> </span><span class="title">Some standard spanning sets.</span>
</h4>
<p id="p-1284">For most of the vector spaces we've met a natural spanning set springs to mind. We will refer to these loosely as <em class="emphasis">standard</em> spanning sets. Some examples:</p>
<ul class="disc">
<li id="li-386">
<span class="heading"><span class="title">Zero space.</span></span><p id="p-1285">Let \(V=\{\boldzero\}\text{.}\) By definition the empty set \(S=\emptyset=\{ \}\) is a spanning set of \(V\text{.}\)</p>
</li>
<li id="li-387">
<span class="heading"><span class="title">Tuples.</span></span><p id="p-1286">Let \(V=\R^n\text{.}\) For \(1\leq i\leq n\text{,}\) define \(\bolde_i\) to be the \(n\)-tuple with a one in the \(i\)-th entry, and zeros elsewhere. Then \(S=\{\bolde_1, \bolde_2,\dots, \bolde_n\}\) is a spanning set for \(\R^n\text{.}\)</p>
</li>
<li id="li-388">
<span class="heading"><span class="title">Matrices.</span></span><p id="p-1287">Let \(V=M_{mn}\text{.}\) For each \((i,j)\) with \(1\leq i\leq m\) and \(1\leq j\leq n\text{,}\) define \(E_{ij}\) to be the \(m\times n\) matrix with a one in the \(ij\)-th entry, and zeros elsewhere. Then \(S=\{E_{ij}\colon 1\leq i\leq m, 1\leq j\leq n\}\) is a spanning set for \(M_{mn}\text{.}\)</p>
</li>
<li id="li-389">
<span class="heading"><span class="title">Polynomials of bounded degree.</span></span><p id="p-1288">Let \(V=P_n\text{.}\) The set \(S=\{x^n, x^{n-1}, \dots, x, 1\}\) clearly spans \(P_n\text{.}\) This is just another way of saying that the <em class="emphasis">monomials</em> of degree at most \(n\) generate the polynomials of degree at most \(n\text{.}\)</p>
</li>
<li id="li-390">
<span class="heading"><span class="title">Polynomials.</span></span><p id="p-1289">Let \(V=P\text{,}\) the space of <em class="emphasis">all</em> polynomials. In a similar vein, the set</p>
<div class="displaymath">
\begin{equation*}
S=\{1, x, x^2, \dots\}=\{x^i\colon i\geq 0\} 
\end{equation*}
</div>
<p class="continuation">of <em class="emphasis">all</em> monomials is a spanning set for \(P\text{.}\)</p>
</li>
</ul>
<p class="continuation">Note the glaring difference between the first three examples, and the last: our standard spanning set for \(P\) is <em class="emphasis">infinite</em>, whereas the previous examples are all finite spanning sets. You suspect, no doubt, that there is no finite spanning set for \(P\text{.}\) We will be able to prove this shortly.</p></article><p id="p-1290">It is important to observe that spanning sets for vector spaces are not unique. Far from it! In general, for any nonzero vector space there are infinitely many choices of spanning sets.</p>
<article class="example example-like" id="example-40"><a href="" data-knowl="" class="id-ref example-knowl original" data-refid="hk-example-40"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.4.7</span><span class="period">.</span><span class="space"> </span><span class="title">Spanning sets are not unique.</span>
</h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-example-40"><article class="example example-like"><p id="p-1291">For each \(V\) and \(S\) below, verify that \(S\) is a spanning set for \(V\text{.}\)</p>
<ol class="decimal">
<li id="li-391"><p id="p-1292">\(V=\R^2\text{,}\) \(S=\{(1,1), (1,2)\}\)</p></li>
<li id="li-392">
<p id="p-1293">\(V=M_{22}\text{,}\) \(S=\{A_1, A_2, A_3, A_4\}\text{,}\)</p>
<div class="displaymath">
\begin{equation*}
A_1=\begin{amatrix}[rr]1\amp 1\\ 1\amp 1  \end{amatrix},
A_2=\begin{amatrix}[rr]1\amp -1\\ 0\amp 0  \end{amatrix},
A_3=\begin{amatrix}[rr]0\amp 0\\ 1\amp -1  \end{amatrix},
A_4=\begin{amatrix}[rr]1\amp 1\\ -1\amp -1  \end{amatrix}\text{.}
\end{equation*}
</div>
</li>
<li id="li-393"><p id="p-1294">\(V=P_2\text{,}\) \(S=\{x^2+x+1, x^2-x, x-1\}\)</p></li>
</ol>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-44" id="solution-44"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-44"><div class="solution solution-like"><ol id="p-1295" class="decimal">
<li id="li-394"><p id="p-1296">This was shown in <a href="" class="xref" data-knowl="./knowl/eg_span_2space.html" title="Example 4.4.3: Examples in \(\R^2\)">Example 4.4.3</a></p></li>
<li id="li-395">
<p id="p-1297">We must show, given any \(A=\begin{amatrix}[rr]a\amp b\\ c\amp d  \end{amatrix}\text{,}\) we can find \(c_1, c_2, c_3, c_4\in \R\) such that</p>
<div class="displaymath">
\begin{equation*}
c_1A_1+c_2A_2+c_3A_3+c_4A_4=\begin{amatrix}[rr]a\amp b\\ c\amp d  \end{amatrix}\text{,}
\end{equation*}
</div>
<p class="continuation">or</p>
<div class="displaymath">
\begin{equation*}
\begin{amatrix}[rr]c_1+c_2+c_4 \amp c_1-c_2+c_4\\
c_1+c_3-c_4\amp c_1-c_3-c_4  \end{amatrix}
=
\begin{amatrix}[rr]a\amp b \\ c\amp d  \end{amatrix}\text{.}
\end{equation*}
</div>
<p class="continuation">We can find such \(c_i\) if and only if the system with augmented matrix</p>
<div class="displaymath">
\begin{equation*}
\begin{amatrix}[rrrr|r]
1\amp 1\amp 0\amp 1\amp a\\
1\amp -1\amp 0\amp 1\amp b \\
1\amp 0\amp 1\amp -1\amp c\\
1\amp 0\amp -1\amp -1\amp d
\end{amatrix}
\end{equation*}
</div>
<p class="continuation">is consistent. This matrix row reduces to</p>
<div class="displaymath">
\begin{equation*}
\begin{amatrix}[rrrr|r]
\boxed{1}\amp 1\amp 0\amp 1\amp a\\
0\amp \boxed{1}\amp 0\amp 0\amp \frac{a-b}{2} \\
0\amp 0\amp \boxed{1}\amp -2\amp c-\frac{a+b}{2}\\
0\amp 0\amp 0\amp \boxed{1}\amp \frac{a+b-c-d}{4}
\end{amatrix}\text{.}
\end{equation*}
</div>
<p class="continuation">Since the last column will never contain a leading one, we conclude that the system is consistent for any choice of \(a,b,c,d\text{,}\) and thus that \(\Span S=M_{22}\text{,}\) as claimed.</p>
</li>
<li id="li-396">
<p id="p-1298">We must show that given any \(p(x)=ax^2+bx+c\) we can find \(c_1,c_2,c_3\) such that</p>
<div class="displaymath">
\begin{equation*}
c_1(x^2+x+1)+c_2(x^2-1)+c_3(x-1)=ax^2+bx+c\text{,}
\end{equation*}
</div>
<p class="continuation">or</p>
<div class="displaymath">
\begin{equation*}
(c_1+c_2)x^2+(c_1+c_3)x+(c_1-c_2-c_3)=ax^2+bx+c\text{.}
\end{equation*}
</div>
<p class="continuation">According to <a href="" class="xref" data-knowl="./knowl/rm_polynomial_equality.html" title="Remark 4.3.10: Polynomial equality">Remark 4.3.10</a> this equality is true if and only if</p>
<div class="displaymath">
\begin{equation*}
\begin{linsys}{3}
c_1 \amp +\amp c_2 \amp  \amp \amp = \amp a\\
c_1 \amp \amp \amp + \amp c_3 \amp = \amp b\\
c_1 \amp -\amp c_2 \amp - \amp c_3 \amp = \amp c
\end{linsys}\text{.}
\end{equation*}
</div>
<p class="continuation">As in the examples above, our reasoning implies  \(\Span S=P_2\) if and only if this system is consistent for <em class="emphasis">any</em> choice of \(a,b,c\text{.}\) Thus usual Gaussian elimination procedure tells us that this is indeed so. We leave the details to you.</p>
</li>
</ol></div></div>
</div></article></div></section><section class="subsection" id="ss_linear_independence"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.4.2</span> <span class="title">Linear independence</span>
</h3>
<p id="p-1299">As it turns out, the notion of <em class="emphasis">linear independence</em> defined below is precisely what we need to guarantee that a given spanning set has no “redundancies”.</p>
<article class="definition definition-like" id="d_linear_independence"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">4.4.8</span><span class="period">.</span><span class="space"> </span><span class="title">Linear independence.</span>
</h4>
<p id="p-1300">A subset \(S\) of a vector space \(V\) is <dfn class="terminology">linear independent</dfn> if the following condition holds:</p>
<div class="displaymath">
\begin{equation*}
\text{if } c_1\boldv_1+c_2\boldv_2+\cdots +c_r\boldv_r=\boldzero \text{ for some distinct vectors } \boldv_i\in S \text{ and scalars } c_i\in \R , \text{ then } c_i=0 \text{ for all } i\text{.}
\end{equation*}
</div>
<p class="continuation">The set \(S\) is <dfn class="terminology">linearly dependent</dfn> if it is not linearly independent; i.e., if we have</p>
<div class="displaymath">
\begin{equation*}
c_1\boldv_1+c_2\boldv_2+\cdots +c_r\boldv_r=\boldzero
\end{equation*}
</div>
<p class="continuation">for some distinct \(\boldv_i\in S\) and \(c_i\in \R\text{,}\) <em class="emphasis">and</em> we have \(c_i\ne 0\) for some \(i\text{.}\)</p>
<p id="p-1301">We call a linear combination \(c_1\boldv_1+c_2\boldv_2+\cdots c_r\boldv_r\)  <dfn class="terminology">trivial</dfn> if \(c_i=0\) for all \(i\text{,}\) and <dfn class="terminology">nontrivial</dfn> if \(c_i\ne 0\) for some \(i\text{.}\) Using this terminology, a set \(S\) is linearly independent if the only linear combination of elements of \(S\) yielding the zero vector is the trivial one.</p></article><article class="remark remark-like" id="rm_linear_independence"><h4 class="heading">
<span class="type">Remark</span><span class="space"> </span><span class="codenumber">4.4.9</span><span class="period">.</span>
</h4>
<p id="p-1302">The definition of linear independence is quite a mouthful! Some clarifying remarks:</p>
<ol class="decimal">
<li id="li-397">
<p id="p-1303">To prove a subset \(S\) of a vector space \(V\) is linearly independent, we must prove an <em class="emphasis">implication</em>:</p>
<div class="displaymath">
\begin{equation*}
c_1\boldv_1+c_2\boldv_2+\cdots +c_r\boldv_r=\boldzero \implies c_1=c_2=\dots=c_r=0\text{.}
\end{equation*}
</div>
<p class="continuation">More often than not you will do so in the direct manner: i.e., assume you have a linear combination equal to the zero vector, then show that all coefficients must be zero.</p>
</li>
<li id="li-398"><p id="p-1304">By the same token, to show a set \(S\) is linearly dependent, we must produce a <em class="emphasis">nontrivial</em> linear combination of elements of \(S\) equal to the zero vector.</p></li>
<li id="li-399">
<p id="p-1305">It is easy to see that \(S\) is linearly dependent if and only if some element of \(S\) can be written as a linear combination of other elements of \(S\text{:}\) just take the nontrivial linear combination yielding the zero vector, and solve for the vector in this combination with the nonzero coefficient.</p>
<p id="p-1306">This makes precise what it means for a spanning set \(S\) to have redundancies or not.  If \(S\) is linearly dependent, then one of its vectors can be written as a linear combination of the others, and thus can be “thrown out” when computing \(\Span S\text{,}\) the set of all linear combinations of \(S\text{.}\) Conversely, if \(S\) is linearly independent, then no element of \(S\) can be written as a linear combination of the others; throwing any element out would thus result in \(\Span S\) being strictly smaller.</p>
</li>
<li id="li-400"><p id="p-1307">If \(\boldzero\in S\text{,}\) then \(S\) is linearly dependent: indeed, we have the nontrivial linear combination \(1\boldzero=\boldzero\text{.}\)</p></li>
<li id="li-401">
<p id="p-1308">If \(S=\{\boldv\}\text{,}\) then \(S\) is linearly independent if and only if \(\boldv\ne \boldzero\text{.}\) The previous comment shows why \(\boldv\ne \boldzero\) is a necessary condition. Let's see why it is sufficient.</p>
<p id="p-1309">Suppose \(\boldv\ne\boldzero\text{,}\) and suppose we have \(c\boldv=\boldzero\text{.}\) By <a href="" class="xref" data-knowl="./knowl/th_vectorspace_props.html" title="Theorem 4.1.13: Basic vector space properties">Theorem 4.1.13</a> we have \(c=0\) or \(\boldv=\boldzero\) (<a href="" class="xref" data-knowl="./knowl/th_vectorspace_props.html" title="Theorem 4.1.13: Basic vector space properties">Theorem 4.1.13</a>). Since \(\boldv\ne 0\text{,}\) we conclude \(c=0\text{.}\) This shows that the only linear combination of \(S\) yielding \(\boldzero\) is the trivial one.</p>
</li>
<li id="li-402">
<p id="p-1310">Suppose \(S=\{\boldv, \boldw\}\) contains exactly two distinct elements. From the last remark, it follows that \(S\) is linearly independent if and only if one of its elements is a scalar multiple of the other.</p>
<p id="p-1311">This makes it very easy to decide whether a two-element set is linearly independent. Note however, that the same observation does not apply to larger sets: e.g., \(S=\{(1,1),(1,0), (0,1)\}\) can be shown to be linearly dependent, and yet no element of \(S\) is a scalar multiple of any other element.</p>
</li>
</ol></article><p id="p-1312">Deciding whether a specific subset \(S\) of a specific vector space \(V\) is linearly independent usually boils down to a question about the solutions to a certain system of linear equations. The procedure below outlines the steps necessary to extract the relevant linear system and draw the relevant conclusions.</p>
<article class="algorithm theorem-like" id="proc_linear_independence"><h4 class="heading">
<span class="type">Procedure</span><span class="space"> </span><span class="codenumber">4.4.10</span><span class="period">.</span><span class="space"> </span><span class="title">Investigating linear independence.</span>
</h4>
<ol class="decimal">
<li id="li-403">
<p id="p-1313">Write out the general <em class="emphasis">vector equation</em></p>
<div class="displaymath">
\begin{equation*}
c_1\boldv_1+c_2\boldv_2+\cdots +c_r\boldv_r=\boldzero
\end{equation*}
</div>
<p class="continuation">where the \(\boldv_i\) are arbitrary elements of the given set \(S\text{.}\)</p>
</li>
<li id="li-404"><p id="p-1314">Translate this vector equation into a <em class="emphasis">homogeneous linear system</em> in the unknowns \(c_1,c_2,\dots, c_r \text{,}\) using the definition of equality for your vector space.</p></li>
<li id="li-405"><p id="p-1315">Decide, using Gaussian elimination, whether this system has any nonzero (i.e., nontrivial) solutions.</p></li>
</ol></article><p id="p-1316">As you can see, even as we move into more and more abstract realms of linear algebra, Gaussian elimination remains our most important tool. We memorialize this in a new principle.</p>
<article class="principle theorem-like" id="princ_GE"><h4 class="heading">
<span class="type">Mantra</span><span class="space"> </span><span class="codenumber">4.4.11</span><span class="period">.</span><span class="space"> </span><span class="title">Gaussian elimination mantra.</span>
</h4>
<p id="p-1317">Gaussian elimination is the workhorse of linear algebra.</p>
<p id="p-1318">Most linear algebraic computations (\(\NS T\text{,}\) \(\im T\text{,}\)\(\Span S\text{,}\) questions of linear independence, etc.) boil down to a question about a certain system of linear equations. The trick is to produce the <em class="emphasis">relevant</em> linear system for a given question.</p></article><article class="example example-like" id="ex_linear_independence"><a href="" data-knowl="" class="id-ref example-knowl original" data-refid="hk-ex_linear_independence"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.4.12</span><span class="period">.</span><span class="space"> </span><span class="title">Linear independence.</span>
</h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-ex_linear_independence"><article class="example example-like"><p id="p-1319">For each subset \(S\) of the given vector space \(V\text{,}\) decide whether \(S\) is linearly independent.</p>
<ol class="decimal">
<li id="li-406"><p id="p-1320">\(V=\R^3\text{,}\) \(S=\{(1,1,2),(1,0,1), (-2,1,-1)\}\)</p></li>
<li id="li-407"><p id="p-1321">\(V=P_2\text{,}\) \(S=\{x^2+x-2, 2x^2+1, x^2-x\}\)</p></li>
<li id="li-408">
<p id="p-1322">\(V=M_{22}\text{,}\) \(S=\{A_1, A_2, A_3, A_4\}\text{,}\) where</p>
<div class="displaymath">
\begin{equation*}
A_1=\begin{bmatrix}3\amp 1\\ 2\amp -3 \end{bmatrix} , A_2= \begin{bmatrix}0\amp 4\\ 2\amp 0 \end{bmatrix} , A_3=\begin{bmatrix}-2\amp -2\\ -2\amp 2 \end{bmatrix}\text{.}
\end{equation*}
</div>
</li>
</ol>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-45" id="solution-45"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-45"><div class="solution solution-like"><ol class="decimal">
<li id="li-409">
<p id="p-1323">We have</p>
<div class="displaymath">
\begin{equation*}
a(1,1,2)+b(1,0,1)+c(-2,1,-1)=(0,0,0)
\end{equation*}
</div>
<p class="continuation">if and only if</p>
<div class="displaymath">
\begin{equation*}
\begin{linsys}{3}
a \amp +\amp b\amp -\amp 2c\amp =0\\
a \amp \amp \amp +\amp c\amp =0\\
2a \amp +\amp b\amp -\amp c\amp =0\\
\end{linsys}\text{.}
\end{equation*}
</div>
<p class="continuation">After a little Gaussian elimination we see that \((a,b,c)=(1,-3,-1)\) is a nonzero solution to this system, and thus that</p>
<div class="displaymath">
\begin{equation*}
(1,1,2)-3(1,0,1)-(-2,1,-1)=(0,0,0)
\end{equation*}
</div>
<p class="continuation">Since there is a nontrivial linear combination of elements of \(S\) yielding the zero vector, we conclude \(S\) is linearly dependent.</p>
</li>
<li id="li-410">
<p id="p-1324">Recall that the zero vector of \(P_2\) is the zero polynomial \(\boldzero=0x^2+0x+0\text{.}\) We have</p>
<div class="displaymath">
\begin{align*}
a(x^2+x-2)+b(2x^2+1)+c(x^2-x)=\boldzero \amp \iff
(a+2b+c)x^2+(a-c)x+(-2a+b)=0x^2+0x+0 \\
\amp \\
\amp \iff
\begin{linsys}{3} a\amp +\amp 2b\amp +\amp c\amp =\amp 0\\ a\amp \amp \amp -\amp c\amp =\amp 0\\ -2a\amp +\amp b \amp \amp  \amp =\amp 0 \end{linsys}
\amp (\knowl{./knowl/rm_polynomial_equality.html}{\text{Remark 4.3.10}})\text{.}
\end{align*}
</div>
<p class="continuation">Gaussian elimination shows that \((a,b,c)=(0,0,0)\) is the unique solution to this last system. We conclude that \(S\) is linearly independent.</p>
</li>
<li id="li-411">
<p id="p-1325">We have</p>
<div class="displaymath">
\begin{align*}
a\begin{bmatrix}3\amp 1\\ 2\amp -3 \end{bmatrix} +b\begin{bmatrix}0\amp 4\\ 2\amp 0 \end{bmatrix} +c\begin{bmatrix}-2\amp -2\\ -2\amp 2 \end{bmatrix}= \begin{bmatrix}0\amp 0\\0\amp 0 \end{bmatrix}
\amp \iff
\begin{bmatrix}3a-2c\amp a+4b-2c\\ 2a+2b-2c\amp -3a+2c \end{bmatrix}=\begin{bmatrix}0\amp 0\\0\amp 0 \end{bmatrix}\\
\amp \\
\amp \iff \begin{linsys}{3} 3a\amp \amp \amp -\amp 2c\amp =\amp 0\\ a\amp +\amp 4b\amp -\amp 2c\amp =\amp 0\\ 2a\amp +\amp 2b \amp -\amp 2c \amp =\amp 0\\ -3a\amp \amp \amp +\amp 2c\amp =\amp 0 \end{linsys} \text{.}
\end{align*}
</div>
<p class="continuation">Row reduction reveals that this last linear system has a free variable, and hence that there are infinitely many solutions to this system: e.g., \((a,b,c)=(2,1,3)\text{.}\) We conclude that \(S\) is linearly dependent.</p>
</li>
</ol></div></div>
</div></article></div></section><section class="subsection" id="ss_linear_independence_functionspace"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.4.3</span> <span class="title">Linear independence in function spaces</span>
</h3>
<p id="p-1326">In each part of <a href="" class="xref" data-knowl="./knowl/ex_linear_independence.html" title="Example 4.4.12: Linear independence">Example 4.4.12</a> it was easy to derive a relevant linear system as the notion of equality in these spaces amounts to checking a <em class="emphasis">finite</em> number of numeric equalities: e.g., between the entries of two triples, the coefficients of two polynomials, or the entries of two \(2\times 2\) matrices.</p>
<p id="p-1327">Things are slightly more complicated when working in function spaces on an interval \(X\) (e.g. \(C(X), C^\infty(X)\text{,}\) etc.), since by definition functions \(f\) and \(g\) are equal if and only if \(f(x)=g(x)\) for all \(x\in X\text{.}\) Thus, in principle verifying two functions are equal amounts to showing <em class="emphasis">infinitely many</em> equalities hold: one for each \(x\in X\text{.}\) Despite this added complexity, we can still investigate linear independence of functions with certain linear systems, as described in the procedure below.</p>
<article class="algorithm theorem-like" id="proc_linear_independence_functions"><h4 class="heading">
<span class="type">Procedure</span><span class="space"> </span><span class="codenumber">4.4.13</span><span class="period">.</span><span class="space"> </span><span class="title">Investigating linear independence of functions.</span>
</h4>
<p id="p-1328">Let \(X\subseteq \R\) be an interval and let \(S=\{f_1,f_2,\dots, f_r\}\) be a subset of \(F(X,\R)\text{.}\)</p>
<ul class="disc">
<li id="li-412">
<p id="p-1329">If you believe \(S\) is linearly independent:</p>
<ul class="circle">
<li id="li-413">
<p id="p-1330">Write out the <em class="emphasis">function equation</em></p>
<div class="displaymath">
\begin{equation*}
c_1f+c_2f_2+\cdots +c_rf_r=\boldzero\text{.}
\end{equation*}
</div>
<p class="continuation">Since the zero vector of \(F(X,\R)\) is the zero function, the definition of function equality implies</p>
<div class="displaymath">
\begin{equation}
c_1f(x)+c_2f_2(x)+\cdots +c_rf(x)_r=0\label{eq_function_equality}\tag{4.4.1}
\end{equation}
</div>
<p class="continuation">for <em class="emphasis">all</em>  \(x\in X\text{.}\)</p>
</li>
<li id="li-414">
<p id="p-1331">Since <a href="" class="xref" data-knowl="./knowl/eq_function_equality.html" title="Equation 4.4.1">(4.4.1)</a> is true for all \(x\in X\text{,}\) we can produce a homogeneous system of linear equations in the unknowns \(c_j\) by picking elements \(x_1,x_2,\dots \) of \(X\text{,}\) and <em class="emphasis">evaluating</em>  <a href="" class="xref" data-knowl="./knowl/eq_function_equality.html" title="Equation 4.4.1">(4.4.1)</a> at \(x_i\text{.}\) The \(i\)-th equation of the resulting system is thus</p>
<div class="displaymath">
\begin{equation*}
f_1(x_i)c_1+f_2(x_i)c_2+\cdots +f_r(x_i)c_r=0\text{.}
\end{equation*}
</div>
</li>
<li id="li-415"><p id="p-1332">If you can find elements \(x_1, x_2, \dots, x_t\in X\) so that the resulting homogeneous system in the unknowns \(c_j\) has the unique solution \(c_1=c_2=\dots=c_r=0\text{,}\) then we conclude that \(S\) is linearly independent.</p></li>
</ul>
</li>
<li id="li-416">
<p id="p-1333">If you believe \(S\) is linearly dependent:</p>
<ul class="circle"><li id="li-417"><p id="p-1334">A nontrivial linear combination of the \(f_i\) equal to the zero function amounts to a function identity. Either cite a well-known function identity involving the \(f_i\text{,}\) or else prove an identity of your own.</p></li></ul>
</li>
</ul></article><article class="remark remark-like" id="rm_linear_independence_functions"><h4 class="heading">
<span class="type">Remark</span><span class="space"> </span><span class="codenumber">4.4.14</span><span class="period">.</span>
</h4>
<p id="p-1335">When using <a href="" class="xref" data-knowl="./knowl/proc_linear_independence_functions.html" title="Procedure 4.4.13: Investigating linear independence of functions">Procedure 4.4.13</a> to show \(S=\{f_1, f_2, \dots, f_r\}\) is linearly independent, you want to produce enough linear equations to <em class="emphasis">force</em> the unknowns \(c_i\) to all be equal to 0. Note that since you you have \(r\) unknowns, you need at <em class="emphasis">at least</em> \(r\) equations, and so must pick at least \(r\) elements \(x_i\in X\text{.}\) Do so judiciously in order to (a) force the \(c_i\) to all be equal to 0, and (b) make the necessary computations palatable.</p></article><p id="p-1336">We illustrate <a href="" class="xref" data-knowl="./knowl/proc_linear_independence_functions.html" title="Procedure 4.4.13: Investigating linear independence of functions">Procedure 4.4.13</a> in the following example.</p>
<article class="example example-like" id="example-42"><a href="" data-knowl="" class="id-ref example-knowl original" data-refid="hk-example-42"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.4.15</span><span class="period">.</span><span class="space"> </span><span class="title">Linear independence of functions.</span>
</h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-example-42"><article class="example example-like"><p id="p-1337">Let \(V=F((-2\pi, 2\pi), \R)\text{.}\) Determine whether the given subset \(S\) is linearly independent.</p>
<ol class="decimal">
<li id="li-418"><p id="p-1338">\(\displaystyle S=\{f(x)=x, g(x)=\cos x, h(x)=\sin x\}\)</p></li>
<li id="li-419"><p id="p-1339">\(S=\{f(x)=1, g(x)=\cos 2x, g(x)=\cos^2 x\}\text{.}\)</p></li>
</ol>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-46" id="solution-46"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-46"><div class="solution solution-like"><ol class="decimal">
<li id="li-420">
<p id="p-1340">We claim \(S\) is linearly dependent. If</p>
<div class="displaymath">
\begin{equation*}
c_1f+c_2g+c_3h=\boldzero\text{,}
\end{equation*}
</div>
<p class="continuation">then</p>
<div class="displaymath">
\begin{equation*}
c_1x+c_2\cos x+c_3\sin x=0\text{,}
\end{equation*}
</div>
<p class="continuation">for all \(x\in (-2\pi, 2\pi)\text{.}\) In particular, the equality is true when evaluated at \(x=0, \pi/2, \pi\text{,}\) yielding the following linear system:</p>
<div class="displaymath">
\begin{equation*}
\begin{linsys}{4}
x=0 \colon \amp \amp 0c_1\amp +\amp \cos(0)c_2\amp +\amp \sin(0) c_3\amp= \amp 0\\
x=\pi/2 \colon \amp \amp (\pi/2)c_1\amp +\amp \cos(\pi/2)c_2\amp +\amp \sin(\pi/2)c_3 \amp = \amp 0\\
x=\pi \colon \amp  \amp \pi c_1\amp +\amp \cos(\pi)c_2\amp +\amp \sin(\pi)c_3 \amp= \amp 0
\end{linsys}\text{,}
\end{equation*}
</div>
<p class="continuation">or</p>
<div class="displaymath">
\begin{equation*}
\begin{linsys}{4}
x=0 \colon  \amp \amp \amp \amp c_2\amp \amp \amp = \amp 0\\
x=\pi/2 \colon \amp  \amp (\pi/2)c_1\amp +\amp \amp +\amp c_3 \amp = \amp 0\\
x=\pi \colon \amp  \amp \pi c_1\amp - \amp c_2 \amp \amp  \amp= \amp 0
\end{linsys}\text{.}
\end{equation*}
</div>
<p class="continuation">This system can be now be solved essentially by inspection: the first equation implies \(c_2=0\text{;}\) setting \(c_2=0\text{,}\) in the third equation, we conclude \(c_1=0\text{;}\) the second equation now implies \(c_3=0\text{.}\) We conclude that \(c_1=c_2=c_3=0\text{.}\) Thus the only linear combination of \(f, g, h\) yielding the zero function is the trivial one, showing that \(S\) is linearly independent.</p>
</li>
<li id="li-421">
<p id="p-1341">We claim \(S\) is linearly dependent. As discussed in <a href="" class="xref" data-knowl="./knowl/proc_linear_independence_functions.html" title="Procedure 4.4.13: Investigating linear independence of functions">Procedure 4.4.13</a>, to prove this we have to produce an identity involving these functions. The double-angle formula from trigonometry tells us that</p>
<div class="displaymath">
\begin{equation*}
\cos 2x=\cos^2 x-\sin^2x=2\cos^2x+1
\end{equation*}
</div>
<p class="continuation">for all \(x\in (-2\pi, 2\pi)\) (in fact for all \(x\in \R\)). It follows that</p>
<div class="displaymath">
\begin{equation*}
1-\cos 2x+2\cos^2x=0
\end{equation*}
</div>
<p class="continuation">for all \(x\in (-2\pi, 2\pi)\text{,}\) or</p>
<div class="displaymath">
\begin{equation*}
f-g+2h=\boldzero\text{.}
\end{equation*}
</div>
<p class="continuation">Since we have found a nontrivial linear combination of elements of \(S\) yielding the zero vector, we conclude that \(S\) is linearly dependent.</p>
</li>
</ol></div></div>
</div></article></div></section><section class="exercises" id="s_span_independence_ex"><h3 class="heading hide-type">
<span class="type">Exercises</span> <span class="codenumber">4.4.4</span> <span class="title">Exercises</span>
</h3>
<div class="exercisegroup" id="exercisegroup-12">
<h4 class="heading"><span class="title">Exercise Group.</span></h4>
<div class="introduction" id="introduction-33"><p id="p-1342">A subset \(S\) of a vector space is given in each exercise below. Determine whether the given elements are elements of \(\Span S\text{.}\) Justify your answer by either providing a linear combination of \(S\) yielding the given element, or else showing that no such linear combination exists.</p></div>
<div class="exercisegroup-exercises">
<article class="exercise exercise-like" id="exercise-121"><h5 class="heading"><span class="codenumber">1<span class="period">.</span></span></h5>
<p id="p-1343">\(V=\R^3\text{,}\) \(S=\{(1,0,1),(1,1,1), (1,2,1) \}\)</p>
<ol class="lower-alpha">
<li id="li-422"><p id="p-1344">\(\displaystyle \boldv=(0,0,0)\)</p></li>
<li id="li-423"><p id="p-1345">\(\displaystyle \boldw=(1,2,1)\)</p></li>
<li id="li-424"><p id="p-1346">\(\displaystyle \boldu=(7,1,0)\)</p></li>
</ol></article><article class="exercise exercise-like" id="exercise-122"><h5 class="heading"><span class="codenumber">2<span class="period">.</span></span></h5>
<p id="p-1347">\(V=M_{22}\text{,}\) \(S=\{A, B, C\}\text{,}\) where</p>
<div class="displaymath">
\begin{equation*}
A = \begin{bmatrix}4\amp 0\\ -2\amp -2 \end{bmatrix} \hspace{5pt}, B = \begin{bmatrix}1\amp -1\\ 2\amp 3 \end{bmatrix} \hspace{5pt}, C= \begin{bmatrix}0\amp 2\\ 1\amp 4 \end{bmatrix}\text{.}
\end{equation*}
</div>
<ol class="lower-alpha">
<li id="li-425"><p id="p-1348">\(\displaystyle A_1=\begin{bmatrix}6\amp -8\\ -1\amp -8 \end{bmatrix}\)</p></li>
<li id="li-426"><p id="p-1349">\(\displaystyle A_2=\begin{bmatrix}-1\amp 5\\ 7\amp 1 \end{bmatrix}\)</p></li>
</ol></article><article class="exercise exercise-like" id="exercise-123"><h5 class="heading"><span class="codenumber">3<span class="period">.</span></span></h5>
<p id="p-1350">\(V=C(\R)\text{,}\) \(S=\{f_1(x)=\cos^2 x, f_2(x)=\sin^2 x\}\)</p>
<ol class="lower-alpha">
<li id="li-427"><p id="p-1351">\(\displaystyle f(x)=x\)</p></li>
<li id="li-428"><p id="p-1352">\(\displaystyle g(x)=\cos 2x\)</p></li>
<li id="li-429"><p id="p-1353">\(\displaystyle h(x)=\sin x\)</p></li>
</ol></article>
</div>
</div>
<article class="exercise exercise-like" id="exercise-124"><h4 class="heading"><span class="codenumber">4<span class="period">.</span></span></h4>
<p id="p-1354">Determine whether \(S\) is a spanning set of \(V\text{.}\)</p>
<ol class="lower-alpha">
<li id="li-430"><p id="p-1355">\(V=\R^3\text{,}\) \(S=\{(1,-1,1),(0,1,-2), (1,0,1)\} \)</p></li>
<li id="li-431"><p id="p-1356">\(V=\R^3\text{,}\) \(S=\{(1,-1,1), (0,1,-2), (-3,2,-1)\}\)</p></li>
<li id="li-432"><p id="p-1357">\(V=P_2\text{,}\) \(S=\{ x^2-1, x^2+1, x^2+2x \}\)</p></li>
<li id="li-433"><p id="p-1358">\(V=\R_{&gt;0}\) (see <a href="" class="xref" data-knowl="./knowl/ex_vs_positivereals.html" title="Definition 4.1.10: Vector space of positive real numbers">Definition 4.1.10</a>), \(S=\{3\}\)</p></li>
</ol></article><div class="exercisegroup" id="exercisegroup-13">
<h4 class="heading"><span class="title">Exercise Group.</span></h4>
<div class="introduction" id="introduction-34"><p id="p-1359">In each exercise, determine whether the given subset \(S\) of the vector space \(V\) is linearly independent. Justify your answer.</p></div>
<div class="exercisegroup-exercises">
<article class="exercise exercise-like" id="exercise-125"><h5 class="heading"><span class="codenumber">5<span class="period">.</span></span></h5>
<p id="p-1360">\(V=\R^4\text{,}\) \(S=\{(3,8,7,-3), (1,5,3,-1), (2,-1,2,6), (4,2,6,4)\}\)</p></article><article class="exercise exercise-like" id="exercise-126"><h5 class="heading"><span class="codenumber">6<span class="period">.</span></span></h5>
<p id="p-1361">\(V=P_2\text{,}\) \(S=\{2x^2-x-1, x^2-2x+1, x^2+x+1 \}\)</p></article><article class="exercise exercise-like" id="exercise-127"><h5 class="heading"><span class="codenumber">7<span class="period">.</span></span></h5>
<p id="p-1362">\(V=C([0,1])\text{,}\) \(S=\{f(x)=x, g(x)=2\val{x} \}\)</p></article><article class="exercise exercise-like" id="exercise-128"><h5 class="heading"><span class="codenumber">8<span class="period">.</span></span></h5>
<p id="p-1363">\(V=C([-1,1])\text{,}\) \(S=\{f(x)=x, g(x)=2\val{x} \}\)</p></article>
</div>
</div>
<article class="exercise exercise-like" id="exercise-129"><h4 class="heading"><span class="codenumber">9<span class="period">.</span></span></h4>
<p id="p-1364">Let \(V=M_{22}\) and let \(S=\{ A_1, A_2, A_3\}\text{,}\) where</p>
<div class="displaymath">
\begin{equation*}
A_1=\begin{bmatrix}1\amp 0\\ 1\amp c \end{bmatrix},  A_2=\begin{bmatrix}-1\amp 0\\ c\amp 1 \end{bmatrix},  A_3=\begin{bmatrix}2\amp 0\\ 1\amp 3 \end{bmatrix}\text{.}
\end{equation*}
</div>
<p class="continuation">Determine all values \(c\in \R\) for which \(S\) is linearly independent.</p></article><article class="exercise exercise-like" id="exercise-130"><h4 class="heading"><span class="codenumber">10<span class="period">.</span></span></h4>
<p id="p-1365">Let \(V=M_{22}\text{,}\) and define \(A_1=\begin{bmatrix}1\amp 1\\1\amp 1 \end{bmatrix}\text{,}\) \(A_2=\begin{bmatrix}0\amp 1\\1\amp 0 \end{bmatrix}\text{,}\) \(A_3=\begin{bmatrix}1\amp 1\\ 1\amp 0 \end{bmatrix}\text{.}\)</p>
<ol class="lower-alpha">
<li id="li-434"><p id="p-1366">Compute \(W=\Span(\{A_1,A_2,A_3\})\text{,}\) identifying it as a certain <em class="emphasis">familiar</em> set of matrices.</p></li>
<li id="li-435"><p id="p-1367">Decide whether \(S=\{A_1,A_2,A_3\}\) is independent.</p></li>
</ol></article><article class="exercise exercise-like" id="ex_span_independence_inveribility"><h4 class="heading">
<span class="codenumber">11<span class="period">.</span></span><span class="space"> </span><span class="title">Span, independence, and invertibility.</span>
</h4>
<p id="p-1368">In this exercise we identify elements of \(V=\R^n\) with \(n\times 1\) column vectors.</p>
<p id="p-1369">Let \(S=\{\boldv_1,\boldv_2,\dots, \boldv_n\}\) be a subset of \(\R^n\text{,}\) and let \(A\) be the \(n\times n\) matrix whose \(j\)-th column is \(\boldv_j\text{:}\) i.e.,</p>
<div class="displaymath">
\begin{equation*}
A=\begin{bmatrix}\vert \amp \vert \amp \cdots \amp \vert\\ \boldv_1\amp \boldv_2\amp  \amp \boldv_n\\ \vert \amp \vert \amp \cdots \amp \vert \end{bmatrix}\text{.}
\end{equation*}
</div>
<ol class="lower-alpha">
<li id="li-436"><p id="p-1370">Prove: \(\Span S=\R^n\) if and only if \(A\) is invertible.</p></li>
<li id="li-437"><p id="p-1371">Prove: \(S\) is linearly independent if and only if \(A\) is invertible.</p></li>
</ol>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-10" id="hint-10"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-10"><div class="hint solution-like"><p id="p-1372">Use the column method (<a href="" class="xref" data-knowl="./knowl/th_column_method.html" title="Theorem 3.1.19: Column method of matrix multiplication">Theorem 3.1.19</a>) and the invertibilty theorem (<a href="" class="xref" data-knowl="./knowl/th_invertibility_expanded.html" title="Theorem 3.5.26: Invertibility theorem (extended cut)">Theorem 3.5.26</a>)</p></div></div>
</div></article><article class="exercise exercise-like" id="ex_span_independence_transform"><h4 class="heading">
<span class="codenumber">12<span class="period">.</span></span><span class="space"> </span><span class="title">Linear transformations, span, and independence.</span>
</h4>
<p id="p-1373">Suppose \(T\colon V\rightarrow W\) is a linear transformation.   Let \(S=\{\boldv_1,\boldv_2,\dots ,\boldv_r\}\) be a subset of \(V\text{,}\) and let \(S'=\{\boldw_1, \boldw_2, \dots, \boldw_r\}\text{,}\) where \(\boldw_i=T(\boldv_i)\text{.}\)</p>
<p id="p-1374">Answer true or false. If true, provide a proof; if false, provide an explicit counterexample. Note: for a complete counterexample you need to specify \(V\text{,}\) \(W\text{,}\) \(T\colon V\rightarrow W\text{,}\) and \(S\text{.}\)</p>
<ol class="lower-alpha">
<li id="li-438"><p id="p-1375">If \(S\) is linearly independent, then \(S'\) is linearly independent.</p></li>
<li id="li-439"><p id="p-1376">If \(S'\) is linearly independent, then \(S\) is linearly independent.</p></li>
<li id="li-440"><p id="p-1377">If \(S\) is a spanning set for \(V\text{,}\) then \(S'\) is a spanning set for \(\im T\text{.}\)</p></li>
</ol></article></section></section></div></main>
</div>
</body>
</html>
