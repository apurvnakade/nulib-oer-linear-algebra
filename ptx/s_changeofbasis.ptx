<section xml:id="s_changeofbasis">
  <title>Change of basis</title>
  <introduction>
    <p>
      We have seen how the coordinate vector map
      <m>[\hspace{10pt}]_B</m> and matrix representations
      <m>[T]_B^{B'}</m> are two invaluable computational tools for dealing with abstract vector spaces.
    </p>
    <p>
      As the notation indicates,
      both of these operations depend essentially on your
      <em>choice of basis or bases</em>.
      This gives rise to the following questions:
      <ol>
        <li>
          <p>
            Given <m>V</m> and two choices of basis, <m>B</m> and <m>B'</m>,
            what is the relation between
            <m>[\boldv]_B</m> and <m>[\boldv]_{B'}</m>?
          </p>
        </li>
        <li>
          <p>
            Given <m>T\colon V\rightarrow W</m> and two choices of pairs of bases,
            <m>(B, B')</m> and <m>(B'', B''')</m>,
            what is the relation between
            <m>[T]_{B}^{B'}</m> and <m>[T]_{B''}^{B'''}</m>?
          </p>
        </li>
      </ol>
    </p>
    <p>
      We will tackle each question in turn.
      Both answers rely on something called a
      <em>change of basis matrix</em>
      <m>\underset{B\rightarrow B'}{P}</m>.
    </p>

  </introduction>
<subsection xml:id="ss_change_of_basis" >
  <title>Change of basis matrices</title>
  <definition xml:id="d_change_of_basis">
    <title>Change of basis matrix</title>
    <idx><h>change of basis matrix</h></idx>
    <notation>
      <usage><m>[P]_B^{B'}</m></usage>
      <description>change of basis matrix</description>
    </notation>
    <statement>
      <p>
        Let <m>B=(\boldv_1, \boldv_2, \dots, \boldv_n)</m> and <m>B'</m> be two ordered bases for the vector space <m>V</m>. The <term>change of basis from <m>B</m> to <m>B'</m></term> is the <m>n\times n</m> matrix <m>\underset{B\rightarrow B'}{P}</m> defined as
        <me>
        \underset{B\rightarrow B'}{P}=
        \begin{bmatrix}
          \vert \amp \vert \amp \amp \vert \\
          [\boldv_1]_{B'} \amp [\boldv_2]_{B'}\amp \dots \amp [\boldv_n]_{B}
        \end{bmatrix}
        </me>.
        In other words, the <m>j</m>-th column of <m>\underset{B\rightarrow B'}{P}</m> is obtained by computing the coordinate vector of the <m>j</m>-th element of the <em>original</em> basis <m>B</m> with respect to the <em>new</em> basis <m>B'</m>.
      </p>
    </statement>
  </definition>
  <theorem xml:id="th_change_of_basis_coordinates">
    <title>Change of basis for coordinate vectors</title>
    <statement>
      <p>
        Let <m>B</m> and <m>B'</m> be two ordered bases of the <m>n</m>-dimensional vector space <m>V</m>. For all <m>\boldv\in V</m> we have
        <me>
        \underset{B\rightarrow B'}{P}[\boldv]_B=[\boldv]_{B'}
        </me>.
        In other words, to convert the <m>B</m>-coordinates of a vector <m>\boldv\in V</m> to <m>B'</m>-coordinates, simply multiply on the left by <m>\underset{B\rightarrow B'}{P}</m>.
      </p>
    </statement>
    <proof>
      <p>
        Let <m>I_V\colon V\rightarrow V</m> be the identity transformation: <ie />, <m>I_V(\boldv)=\boldv</m> for all <m>\boldv\in V</m>. By <xref ref="th_matrixrep"/> the matrix <m>[I_V]_B^{B'}</m> is the unique matrix satisfying
        <me>
        [I_V]_B^{B'}[\boldv]_B=[I_V(\boldv)]_{B'}=[\boldv]_{B'}
        </me>.
        Comparing the formulas for <m>[I_V]_{B}^{B'}</m> and <m></m> we see directly that
        <me>
        [I_V]_B^{B'} = \underset{B\rightarrow B'}{P}
        </me>.
      </p>
    </proof>

  </theorem>

</subsection>


  <subsection>
    <title>Example</title>
    <p>
      Let <m>V=\R^2</m>.
      Compute <m>\underset{B\rightarrow B'}{P}</m> where
      <m>B=\{\boldv_1=(1,1),\boldv_2=(1,-1)\}</m> and <m>B'=\{(1,2),(2,1)\}</m>.
    </p>
  </subsection>
  <p>
    Test that the matrix converts correctly using the vector
    <m>\boldv=1(1,1)+3(1,-1)=(4,-2)</m>. \begin{bsolution} The recipe tells us that
    <md>
    <mrow>\underset{B\rightarrow B'}{P}\amp =\amp \begin{bmatrix}\vert \amp \vert \\ \hspace{7pt}[\boldv_1]_{B'} \amp \hspace{7pt}[\boldv_2]_{B'}\\ \vert \amp \vert \end{bmatrix}</mrow>
    <mrow>\amp =\amp \begin{bmatrix}1/3\amp -1\\ 1/3\amp 1 \end{bmatrix}  \hspace{8pt}\text{ (after some computation) }</mrow>
    </md>
  </p>
  <p>
    For <m>\boldv=1(1,1)+3(1,-1)=(4,-2)</m>,
    we have <m>(\boldv)_B=(1,3)</m>.
    Thus we should have
    <me>
    [\boldv]_{B'}=\underset{B\rightarrow B'}{P}[\boldv]_B=\begin{bmatrix}1/3\amp -1\\ 1/3\amp 1 \end{bmatrix} \begin{bmatrix}1\\ 3 \end{bmatrix} =\begin{bmatrix}-8/3\\ 10/3 \end{bmatrix}
    </me>.
  </p>
  <p>
    Indeed, one easily verifies that <m>(4,-2)=-8/3(1,2)+10/3(2,1)</m>. \end{bsolution}
  </p>
  <subsection>
    <title>Example</title>
    <p>
      Take <m>V=P_2</m>,
      <m>B=\{1,x,x^2\}</m> and <m>B'=\{1,(x-2), (x-2)^2\}</m>.
      Compute <m>\underset{B\rightarrow B'}{P}</m>.
    </p>
    <p>
      Follow the recipe:
      let <m>\boldp_j</m> be the <m>j</m>-th column of <m>\underset{B\rightarrow B'}{P}</m>.
      We have (after some computation)
      <me>
      \boldp_1=[1]_{B'}=(1,0,0), \ \boldp_2=[x]_{B'}=(2,1,0), \ \boldp_3=[x^2]_{B'}=(4,4,1)
      </me>.
    </p>
    <p>
      Thus <m>\underset{B\rightarrow B'}{P}=\begin{bmatrix}1\amp 2\amp 4\\ 0\amp 1\amp 4\\ 0\amp 0\amp 1 \end{bmatrix}</m>
    </p>
    <p>
      Let's check with the test vector <m>p(x)=1+x+x^2</m>.
      We have <m>(p)_B=(1,1,1)</m>.
      Thus we should have <m>[p]_{B'}=\underset{B\rightarrow B'}{P}[p]_B=\begin{bmatrix}1\amp 2\amp 4\\ 0\amp 1\amp 4\\ 0\amp 0\amp 1 \end{bmatrix} \begin{bmatrix}1 \\ 1 \\ 1 \end{bmatrix} =\begin{bmatrix}7\\ 5\\ 1 \end{bmatrix}</m>.
      Equivalently, this means that
      <m>p(x)=7+5(x-2)+(x-2)^2</m>, as one easily verifies.
    </p>

    <subsection>
      <title>Cool fact</title>
      <p>
        We could have derived the last equality using the theory of Taylor series.
        Namely any polynomial can be
        <q>expanded around <m>x=a</m></q>
        as <m>p(x)=\sum_{i=0}^n\frac{p^{(i)}(a)}{a!}(x-a)^i</m>.
      </p>
    </subsection>
    <p>
      More generally, this means
      <me>
      (p(x))_{B'}=(p(a), p'(a), p''(a)/2, \dots , p^{(n)}(a)/n!)
      </me>
      where <m>B'=\{1,x-a, (x-a)^2,\dots , (x-a)^n\}</m>.
    </p>
  </subsection>
  <theorem xml:id="th_change_of_basis_properties">
    <title>Change of basis matrix properties</title>
    <statement>
      <p>
        Let <m>B, B', B''</m> be ordered bases for the <m>n</m>-dimensional vector space <m>V</m>.
      </p>
      <ol>
        <li>
          <p>
            We have
            <me>
            \underset{B\rightarrow B}{P}=I
            </me>.
          </p>
        </li>
        <li>
          <p>
            The matrix <m>\underset{B\rightarrow B'}{P}</m> is invertible. In fact, we have
            <me>
            \underset{B\rightarrow B'}{P}^{-1}=\underset{B'\rightarrow B}{P}
            </me>
          </p>
        </li>
        <li>
          <p>
            We have
            <me>
            \underset{B\rightarrow B''}{P}=\underset{B'\rightarrow B''}{P}\, \underset{B\rightarrow B'}{P}
            </me>.
          </p>
        </li>
      </ol>
    </statement>
  </theorem>


  <subsection>
    <title>Example: <m>V=\R^n</m> and <m>B</m> is standard</title>
    <p>
      Consider the simple example where <m>V=\R^n</m>,
      <m>B</m> is the standard basis,
      and <m>B'=\{\boldv_1,\dots,\boldv_n\}</m> is some nonstandard basis.
      I claim the matrix <m>P=\begin{bmatrix}\vert\amp \dots \amp \vert \\ \boldv_1\amp \cdots\amp \boldv_n\\ \vert\amp \dots \amp \vert \end{bmatrix}</m> whose columns are the elements of <m>B'</m> is the change of basis matrix <m>\underset{B'\rightarrow B} P</m>.
      This follows from our recipe since <m>\boldv_j=[\boldv_j]_B</m>. (Recall:
      when <m>B</m> is the standard basis
      <m>[(a_1,a_2,\dots, a_n)]_B=(a_1,a_2,\dots,
      a_n)</m> for all <m>(a_1,a_2,\dots, a_n)\in\R^n</m>. )
    </p>
    <p>
      Since <m>\underset{B\rightarrow B'}{P}=(\underset{B'\rightarrow B}{P})^{-1}</m>,
      we see that in this special case we can compute
      <m>\underset{B'\rightarrow B}{P}</m> by placing the elements of <m>B'</m> as columns of a matrix,
      and then compute <m>\underset{B\rightarrow B'}{P}</m> by taking the inverse of this matrix!
    </p>
    <subsection>
      <title>Example</title>
      <p>
        Let <m>V=\R^2</m>, <m>B</m> the standard basis for <m>\R^2</m>,
        and <m>B'=\{(1,\sqrt{3}),(-\sqrt{3},1)\}</m>.
      </p>
    </subsection>
    <p>
      Find <m>P_{B\rightarrow B'}</m>. \begin{bsolution} The recipe above tells us that <m>\underset{B'\rightarrow B}{P}=\begin{bmatrix}1\amp -\sqrt{3}\\ \sqrt{3}\amp 1 \end{bmatrix}</m> and hence that
      <me>
      \underset{B\rightarrow B'}{P}=(\underset{B'\rightarrow B}{P})^{-1}=\left(\begin{bmatrix}1\amp -\sqrt{3}\\ \sqrt{3}\amp 1 \end{bmatrix} \right)^{-1}=\frac{1}{4}\begin{bmatrix}1\amp \sqrt{3}\\ -\sqrt{3}\amp 1 \end{bmatrix}
      </me>.
    </p>
    <p>
      \end{bsolution}
    </p>
  </subsection>

  <subsection>
    <title>Change of basis for transformations</title>
    <p>
      We now investigate how our choice of basis affects matrix representations of linear transformations.
      We will only consider the special case where
      <m>T\colon V\rightarrow V</m> and we are comparing matrix representations <m>[T]_B</m> and
      <m>[T]_{B'}</m> for two different ordered bases of <m>V</m>.
    </p>
    <theorem xml:id="th_change_of_basis_transformations">
      <title>Change of basis for transformations</title>
      <statement>
        <p>
          Let <m>V</m> be finite-dimensional,
          let <m>T\colon V\rightarrow V</m> be linear,
          and let <m>B</m> and <m>B'</m> be two bases for <m>V</m>. The matrices <m>[T]_B</m> and <m>[T]_{B'}</m> representing <m>T</m> with respect to <m>B</m> and <m>B'</m>, respectively,  are related as follows:
          <md>
          <mrow>[T]_{B'}\amp =\underset{B\rightarrow B'}{P}\, [T]_B\, \underset{B'\rightarrow B}{P}</mrow>[2ex]
          <mrow>\amp =\underset{B'\rightarrow B}{P}^{-1}\, [T]_B\, \underset{B'\rightarrow B}{P}</mrow>
          </md>.
        </p>
      </statement>
    </theorem>
  </subsection>
  <remark xml:id="rm_change_of_basis_transformations">
    <title>Getting change of basis formulas correct</title>
    <statement>
      <p>
        It is easy to get the various details of the change of basis formula wrong.
        Here is a potential way to keep things organized in your mind.
        <ol>
          <li>
            <p>
              We wish to relate <m>[T]_{B'}</m> and <m>[T]_B</m> with an equation of the form <m>[T]_{B'}=*[T]_B*</m>,
              where the asterisks are to be replaced with change of basis matrices or their inverses.
              Think of the three matrices on the right-hand side of this equation  as a sequence of three things done to coordinate vectors,
              reading from right to left.
            </p>
          </li>
          <li>
            <p>
              <m>[T]_{B'}</m> takes as inputs <m>B'</m>-coordinates of vectors,
              and outputs <m>B'</m>-coordinates.
              Thus the same should be true for <m>*[T]_B*</m>.
            </p>
          </li>
          <li>
            <p>
              Since <m>[T]_B</m> takes as inputs <m>B</m>-coordinates,
              we must <em>first</em> convert from <m>B'</m>-coordinates to <m>B</m>-coordinates.
              So we should have <m>[T]_{B'}=*[T]_B\underset{B'\rightarrow B}{P}</m>.
            </p>
          </li>
          <li>
            <p>
              Since <m>[T]_B</m> outputs <m>B</m>-coordinates,
              we need to then convert back to <m>B'</m>-coordinates.
              Thus <m>[T]_{B'}=\underset{B\rightarrow B'}{P}[T]_B\underset{B'\rightarrow B}{P}</m>.
            </p>
          </li>
          <li>
            <p>
              If desired you may replace
              <m>\underset{B\rightarrow B'}{P}</m> with <m> \underset{B'\rightarrow B}{P}^{-1}</m>.
            </p>
          </li>
        </ol>
      </p>
    </statement>
  </remark>

  <subsection>
    <title>Example</title>
    <p>
      Let <m>T\colon P_2\rightarrow P_2</m> be defined as <m>T(p(x))=p(x)+2p'(x)+xp''(x)</m>.
      <ol>
        <li>
          <p>
            Let <m>B=\{1, x, x^2\}</m>.
            Compute <m>[T]_B</m>.
          </p>
        </li>
        <li>
          <p>
            Let <m>B'=\{1+x+x^2, 1+x, 1+x^2\}</m>.
            Use the change of basis formula to compute <m>[T]_{B'}</m>.
          </p>
        </li>
      </ol>
    </p>
    <p>
      We easily compute <m>[T]_B=\begin{bmatrix}1\amp 2\amp 0\\ 0\amp 1\amp 4\\ 0\amp 0\amp 1 \end{bmatrix}</m> using our usual recipe.
    </p>
    <p>
      We can also easily compute <m>\underset{B'\rightarrow B}{P}=\begin{bmatrix}1\amp 1\amp 1\\ 1\amp 1\amp 0\\ 1\amp 0\amp 1 \end{bmatrix}</m>,
      essentially by inspection.
    </p>
    <p>
      (In general it is easy to compute the change of basis matrix from a nonstandard basis to the standard basis.)
    </p>
    <p>
      It follows that
      <md>
      <mrow>_B'\amp =\underset{B\rightarrow B'}{P}[T]_B\underset{B'\rightarrow B}{P}=\left( \underset{B'\rightarrow B}{P}\right)^{-1}[T]_B\underset{B'\rightarrow B}{P}</mrow>
      <mrow>\amp =\left( \begin{bmatrix} 1\amp 1\amp 1</mrow>
      <mrow>1\amp 1\amp 0</mrow>
      <mrow>1\amp 0\amp 1 \end{bmatrix}\right)^{-1}\begin{bmatrix} 1\amp 2\amp 0</mrow>
      <mrow>0\amp 1\amp 4</mrow>
      <mrow>0\amp 0\amp 1 \end{bmatrix} \begin{bmatrix} 1\amp 1\amp 1</mrow>
      <mrow>1\amp 1\amp 0</mrow>
      <mrow>1\amp 0\amp 1 \end{bmatrix}= \begin{amatrix}[rrr] 3\amp -2\amp 4</mrow>
      <mrow>2\amp 3\amp 0</mrow>
      <mrow>-2\amp 2\amp -3 \end{amatrix}</mrow>
      </md>
    </p>
  </subsection>
  <definition>
    <statement>
      <p>
        Matrices <m>A, A'\in M_{nn}</m> are <term>similar</term>
        if there is an invertible matrix <m>P</m> such that <m>A'=P^{-1}AP</m>.
      </p>
    </statement>
  </definition>
  <p>
    As we will see in coming sections,
    matrices that are similar in this technical sense do indeed share many of the same properties.
    We now have the theoretical foundation to understand why this is so:
    they simply inherit these common properties from the overlying linear transformation <m>T</m>,
    of which they are but earthly shadows.
  </p>
  <figure xml:id="fig_comm_tent">
    <caption>Holy commutative tent of linear algebra: <m>P=\underset{B\rightarrow B'}{P}</m>, <m>B=P^{-1}AP</m></caption>
    <image xml:id="im_holycomm">
      <latex-image>
        \begin{tikzcd}
        \amp V \arrow[rrr, "T"] \arrow[ddl, leftrightarrow, "{[\hspace{5pt}]_B}"'] \arrow[drr, leftrightarrow,"{[\hspace{5pt}]_{B'}}"]  \amp \amp \amp V \arrow[ddl, leftrightarrow,"{[\hspace{5pt}]_B}", pos=11/20] \arrow[drr, leftrightarrow, "{[\hspace{5pt}]_{B'}}"]\\
        \amp  \amp   \amp\R^n \arrow[rrr, "T_B"] \arrow[dlll, "P^{-1}"', pos=.4] \amp \amp \amp \R^n \\
        \R^n \arrow[rrr, "T_A"']\amp   \amp \amp \R^n  \arrow[urrr, "P"']\amp
        \end{tikzcd}
      </latex-image>
    </image>

  </figure><!--
  <figure xml:id="fig_comm_tent">
    <caption>Holy commutative tent of linear algebra: <m>P=\underset{B\rightarrow B'}{P}</m>, <m>B=P^{-1}AP</m>
  </caption>
    <image xml:id="im_holycomm" source="./images/im_holycomm.svg"/>

  </figure>-->
  <p>
    There is but one true <m>T</m>!
  </p>
  <subsection>
    <title>Change of basis for <m>V=\R^n</m></title>

    <p>
      Let's consider the special case where <m>T\colon \R^n\rightarrow \R^n</m>: that is, when <m>V=\R^n</m> is a space of <m>n</m>-tuples. We know from <xref ref="cor_matrix_transformations"/> that <m>T=T_A</m> for a unique <m>n\times n</m> matrix <m>A</m>; in fact we know from the proof that <m>A=[T]_B</m>, where <m>B=(\bolde_1, \bolde_2, \dots, \bolde_n)</m> is the <em>standard</em> ordered basis of <m>\R^n</m>.
    </p>
    <p>
      To compute <m>A=[T]_B</m> directly, we must compute <m>T(\bolde_j)</m> for each of the standard basis elements <m>\bolde_j</m>. However, for many naturally occuring transformations <m>T</m>, computing with respect to the standard basis is often not as convenient as computing with respect to some other basis <m>B'</m>: <ie />, it is often easier to compute <m>A'=[T]_{B'}</m> for some nonstandard basis <m>B'</m>. When this is the case <xref ref="th_change_of_basis_transformations"/> allows to us derive the desired matrix <m>A</m> from the more conveniently computed <m>A'</m>: namely, we have
      <me>
        A=P^{-1}A'P
      </me>,
      where <m>P=\underset{B\rightarrow B'}{P}</m>.
    </p>
    <p>
      This gives us a powerful technique for computing matrix formulas for many interesting geometric linear transformations of <m>\R^n</m> whose very definitions involve an implicit choice nonstandard basis. Rotations, reflections and orthogonal projections are all examples of such transformations.
    </p>


  </subsection>

  <subsection>
    <title>Example: orthogonal projection revisited</title>
    <p>
      Let <m>T\colon \R^3\rightarrow\R^3</m> be orthogonal projection onto the plane <m>\mathcal{P}: x+y+z=0</m>,
      as defined earlier.
      We would like to derive a formula for <m>T</m>,
      which amounts to finding the <m>A</m> such that <m>T=T_A</m>.
    </p>
    <p>
      As previously observed we have <m>A=[T]_B</m>,
      where <m>B</m> is the <em>standard basis</em> for <m>\R^3</m>.
      We can compute <m>[T]_B</m> by first computing
      <m>[T]_{B'}</m> for a cleverly chosen
      <em>nonstandard</em> basis <m>B'</m>,
      and then using the change of basis formula.
    </p>
    <p>
      As done previously, we let <m>B'=\{(1,-1,0), (1,0,-1), (1,1,1)</m>.
      Since <m>T</m> maps the first two vectors to themselves,
      and the third vector to <m>(0,0,0)</m>,
      we have <m>[T]_{B'}=\begin{bmatrix}1\amp 0\amp 0\\ 0\amp 1\amp 0\\ 0\amp 0\amp 0 \end{bmatrix}</m>.
      (Go back to original example for details.)
    </p>
    <p>
      Then
      <md>
        <mrow>A\amp =[T]_B=\underset{B'\rightarrow B}{P}[T]_{B'}\underset{B\rightarrow B'}{P}</mrow>
        <mrow>\amp =\begin{amatrix}[rrr] 1\amp 1\amp 1</mrow>
        <mrow>-1\amp 0\amp 1</mrow>
        <mrow>0\amp -1\amp 1 \end{amatrix} \begin{bmatrix} 1\amp 0\amp 0</mrow>
        <mrow>0\amp 1\amp 0</mrow>
        <mrow>0\amp 0\amp 0 \end{bmatrix} \left( \begin{amatrix}[rrr] 1\amp 1\amp 1</mrow>
        <mrow>-1\amp 0\amp 1</mrow>
        <mrow>0\amp -1\amp 1 \end{amatrix}\right)^{-1} =\frac{1}{3}\begin{amatrix}[rrr] 2\amp -1\amp -1</mrow>
        <mrow>-1\amp 2\amp -1</mrow>
        <mrow>-1\amp -1\amp 2 \end{amatrix}</mrow>
      </md>
    </p>
    <p>
      Lo and behold,
      we have rediscovered our matrix formula for orthogonal projection onto <m>\mathcal{P}</m>!!
    </p>
    <p>
      (Note: since <m>B</m> is the standard basis in this case,
      <m>\underset{B'\rightarrow B}{P}</m> was easy to compute. )
    </p>
  </subsection>

</section>
