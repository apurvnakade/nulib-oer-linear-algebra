<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*       on 2022-07-22T11:48:25-07:00       *-->
<!--*   A recent stable commit (2020-08-09):   *-->
<!--* 98f21740783f166a773df4dc83cab5293ab63a4a *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>The spectral theorem</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="Linear algebra: the theory of vector spaces and linear transformations">
<meta property="book:author" content="Aaron Greicius">
<script>window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|ignore-math",
    processHtmlClass: "process-math",
    renderActions: {
        findScript: [10, function (doc) {
            document.querySelectorAll('script[type^="math/tex"]').forEach(function(node) {
                var display = !!node.type.match(/; *mode=display/);
                var math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                var text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = {node: text, delim: '', n: 0};
                math.end = {node: text, delim: '', n: 0};
                doc.math.push(math);
            });
        }, '']
    },
  },
  chtml: {
    scale: 0.88,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><link href="https://webwork-ptx.aimath.org/webwork2_files/js/apps/MathView/mathview.css" rel="stylesheet">
<script src="https://pretextbook.org/js/0.13/pretext-webwork.js"></script><script src="https://webwork-ptx.aimath.org/webwork2_files/node_modules/iframe-resizer/js/iframeResizer.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.13/pretext.js"></script><script>miniversion=0.674</script><script src="https://pretextbook.org/js/0.13/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/colors_blue_red.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/setcolors.css" rel="stylesheet" type="text/css">
<!--** eBookCongig is necessary to configure interactive       **-->
<!--** Runestone components to run locally in reader's browser **-->
<!--** No external communication:                              **-->
<!--**     log level is 0, Runestone Services are disabled     **-->
<script type="text/javascript">
eBookConfig = {};
eBookConfig.useRunestoneServices = false;
eBookConfig.host = 'http://127.0.0.1:8000';
eBookConfig.course = 'PTX Course: Title Here';
eBookConfig.basecourse = 'PTX Base Course';
eBookConfig.isLoggedIn = false;
eBookConfig.email = '';
eBookConfig.isInstructor = false;
eBookConfig.logLevel = 0;
eBookConfig.username = '';
eBookConfig.readings = null;
eBookConfig.activities = null;
eBookConfig.downloadsEnabled = false;
eBookConfig.allow_pairs = false;
eBookConfig.enableScratchAC = false;
eBookConfig.build_info = "";
eBookConfig.python3 = null;
eBookConfig.acDefaultLanguage = 'python';
eBookConfig.runestone_version = '5.0.1';
eBookConfig.jobehost = '';
eBookConfig.proxyuri_runs = '';
eBookConfig.proxyuri_files = '';
eBookConfig.enable_chatcodes =  false;
</script>
<!--*** Runestone Services ***-->
<script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/runtime.b0f8547c48f16a9f.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/637.d54be67956c5c660.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/runestone.0e9550fe42760516.bundle.js"></script><link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/6.2.1/637.fafafbd97df8a0d1.css">
<link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/6.2.1/runestone.e4d5592da655219f.css">
</head>
<body class="pretext-book ignore-math has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\require{cancel}\newcommand{\Z}{{\mathbb Z}}
\newcommand{\Q}{{\mathbb Q}}
\newcommand{\R}{{\mathbb R}}
\newcommand{\C}{{\mathbb C}}
\newcommand{\T}{{\mathbb T}}
\newcommand{\F}{{\mathbb F}}
\newcommand{\HH}{{\mathbb H}}
\newcommand{\compose}{\circ}
\newcommand{\bolda}{{\mathbf a}}
\newcommand{\boldb}{{\mathbf b}}
\newcommand{\boldc}{{\mathbf c}}
\newcommand{\boldd}{{\mathbf d}}
\newcommand{\bolde}{{\mathbf e}}
\newcommand{\boldi}{{\mathbf i}}
\newcommand{\boldj}{{\mathbf j}}
\newcommand{\boldk}{{\mathbf k}}
\newcommand{\boldn}{{\mathbf n}}
\newcommand{\boldp}{{\mathbf p}}
\newcommand{\boldq}{{\mathbf q}}
\newcommand{\boldr}{{\mathbf r}}
\newcommand{\bolds}{{\mathbf s}}
\newcommand{\boldt}{{\mathbf t}}
\newcommand{\boldu}{{\mathbf u}}
\newcommand{\boldv}{{\mathbf v}}
\newcommand{\boldw}{{\mathbf w}}
\newcommand{\boldx}{{\mathbf x}}
\newcommand{\boldy}{{\mathbf y}}
\newcommand{\boldz}{{\mathbf z}}
\newcommand{\boldzero}{{\mathbf 0}}
\newcommand{\boldmod}{\boldsymbol{ \bmod }}
\newcommand{\boldT}{{\mathbf T}}
\newcommand{\boldN}{{\mathbf N}}
\newcommand{\boldB}{{\mathbf B}}
\newcommand{\boldF}{{\mathbf F}}
\newcommand{\boldS}{{\mathbf S}}
\newcommand{\boldG}{{\mathbf G}}
\newcommand{\boldK}{{\mathbf K}}
\newcommand{\boldL}{{\mathbf L}}
\DeclareMathOperator{\lcm}{lcm}
\DeclareMathOperator{\Span}{span}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\NS}{null}
\DeclareMathOperator{\RS}{row}
\DeclareMathOperator{\CS}{col}
\DeclareMathOperator{\im}{im}
\DeclareMathOperator{\range}{range}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\nullity}{nullity}
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Fix}{Fix}
\DeclareMathOperator{\Aff}{Aff}
\DeclareMathOperator{\Frac}{Frac}
\DeclareMathOperator{\Ann}{Ann}
\DeclareMathOperator{\Tor}{Tor}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\mdeg}{mdeg}
\DeclareMathOperator{\Lt}{Lt}
\DeclareMathOperator{\Lc}{Lc}
\DeclareMathOperator{\disc}{disc}
\DeclareMathOperator{\Frob}{Frob}
\DeclareMathOperator{\adj}{adj}
\DeclareMathOperator{\curl}{curl}
\DeclareMathOperator{\grad}{grad}
\DeclareMathOperator{\diver}{div}
\DeclareMathOperator{\flux}{flux}
\def\Gal{\operatorname{Gal}}
\def\ord{\operatorname{ord}}
\def\ML{\operatorname{M}}
\def\GL{\operatorname{GL}}
\def\PGL{\operatorname{PGL}}
\def\SL{\operatorname{SL}}
\def\PSL{\operatorname{PSL}}
\def\GSp{\operatorname{GSp}}
\def\PGSp{\operatorname{PGSp}}
\def\Sp{\operatorname{Sp}}
\def\PSp{\operatorname{PSp}}
\def\Aut{\operatorname{Aut}}
\def\Inn{\operatorname{Inn}}
\def\Hom{\operatorname{Hom}}
\def\End{\operatorname{End}}
\def\ch{\operatorname{char}}
\def\Zp{\Z/p\Z}
\def\Zm{\Z/m\Z}
\def\Zn{\Z/n\Z}
\def\Fp{\F_p}
\newcommand{\surjects}{\twoheadrightarrow}
\newcommand{\injects}{\hookrightarrow}
\newcommand{\bijects}{\leftrightarrow}
\newcommand{\isomto}{\overset{\sim}{\rightarrow}}
\newcommand{\floor}[1]{\lfloor#1\rfloor}
\newcommand{\ceiling}[1]{\left\lceil#1\right\rceil}
\newcommand{\mclass}[2][m]{[#2]_{#1}}
\newcommand{\val}[2][]{\left\lvert #2\right\rvert_{#1}}
\newcommand{\abs}[2][]{\left\lvert #2\right\rvert_{#1}}
\newcommand{\valuation}[2][]{\left\lvert #2\right\rvert_{#1}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\anpoly}{a_nx^n+a_{n-1}x^{n-1}\cdots +a_1x+a_0}
\newcommand{\anmonic}{x^n+a_{n-1}x^{n-1}\cdots +a_1x+a_0}
\newcommand{\bmpoly}{b_mx^m+b_{m-1}x^{m-1}\cdots +b_1x+b_0}
\newcommand{\pder}[2]{\frac{\partial#1}{\partial#2}}
\newcommand{\normalin}{\trianglelefteq}
\newcommand{\angvec}[1]{\langle #1\rangle}
\newcommand{\varpoly}[2]{#1_{#2}x^{#2}+#1_{#2-1}x^{#2-1}\cdots +#1_1x+#1_0}
\newcommand{\varpower}[1][a]{#1_0+#1_1x+#1_1x^2+\cdots}
\newcommand{\limasto}[2][x]{\lim_{#1\rightarrow #2}}
\def\ntoinfty{\lim_{n\rightarrow\infty}}
\def\xtoinfty{\lim_{x\rightarrow\infty}}
\def\ii{\item}
\def\bb{\begin{enumerate}}
\def\ee{\end{enumerate}}
\def\ds{\displaystyle}
\def\p{\partial}
\newcommand{\abcdmatrix}[4]{\begin{bmatrix}#1\amp #2\\ #3\amp #4 \end{bmatrix}
}
\newenvironment{amatrix}[1][ccc|c]{\left[\begin{array}{#1}}{\end{array}\right]}
\newenvironment{linsys}[2][m]{
\begin{array}[#1]{@{}*{#2}{rc}r@{}}
}{
\end{array}}
\newcommand{\eqsys}{\begin{array}{rcrcrcr}
a_{11}x_{1}\amp +\amp a_{12}x_{2}\amp +\cdots+\amp  a_{1n}x_{n}\amp =\amp b_1\\
a_{21}x_{1}\amp +\amp a_{22}x_{2}\amp +\cdots+\amp a_{2n}x_{n}\amp =\amp b_2\\
\amp \vdots\amp   \amp \vdots \amp  \amp \vdots \amp  \vdots\\
a_{m1}x_{1}\amp +\amp a_{m2}x_{2}\amp +\cdots +\amp a_{mn}x_{n}\amp =\amp b_m
\end{array}
}
\newcommand{\numeqsys}{\begin{array}{rrcrcrcr}
e_1:\amp  a_{11}x_{1}\amp +\amp a_{12}x_{2}\amp +\cdots+\amp  a_{1n}x_{n}\amp =\amp b_1\\
e_2: \amp a_{21}x_{1}\amp +\amp a_{22}x_{2}\amp +\cdots+\amp a_{2n}x_{n}\amp =\amp b_2\\
\amp \vdots\amp   \amp \vdots \amp  \amp \vdots \amp  \vdots\\
e_m: \amp a_{m1}x_{1}\amp +\amp a_{m2}x_{2}\amp +\cdots +\amp a_{mn}x_{n}\amp =\amp b_m
\end{array}
}
\newcommand{\homsys}{\begin{array}{rcrcrcr}
a_{11}x_{1}\amp +\amp a_{12}x_{2}\amp +\cdots+\amp  a_{1n}x_{n}\amp =\amp 0\\
a_{21}x_{1}\amp +\amp a_{22}x_{2}\amp +\cdots+\amp a_{2n}x_{n}\amp =\amp 0\\
\amp \vdots\amp   \amp \vdots \amp  \amp \vdots \amp  \vdots\\
a_{m1}x_{1}\amp +\amp a_{m2}x_{2}\amp +\cdots +\amp a_{mn}x_{n}\amp =\amp 0
\end{array}
}
\newcommand{\vareqsys}[4]{
\begin{array}{ccccccc}
#3_{11}x_{1}\amp +\amp #3_{12}x_{2}\amp +\cdots+\amp  #3_{1#2}x_{#2}\amp =\amp #4_1\\
#3_{21}x_{1}\amp +\amp #3_{22}x_{2}\amp +\cdots+\amp #3_{2#2}x_{#2}\amp =\amp #4_2\\
\vdots \amp \amp \vdots \amp  \amp \vdots \amp =\amp  \vdots\\
#3_{#1 1}x_{1}\amp +\amp #3_{#1 2}x_{2}\amp +\cdots +\amp #3_{#1 #2}x_{#2}\amp =\amp #4_{#1}
\end{array}
}
\newcommand{\genmatrix}[1][a]{
\begin{bmatrix}
#1_{11} \amp  #1_{12} \amp  \cdots \amp  #1_{1n} \\
#1_{21} \amp  #1_{22} \amp  \cdots \amp  #1_{2n} \\
\vdots  \amp  \vdots  \amp  \ddots \amp  \vdots  \\
#1_{m1} \amp  #1_{m2} \amp  \cdots \amp  #1_{mn}
\end{bmatrix}
}
\newcommand{\varmatrix}[3]{
\begin{bmatrix}
#3_{11} \amp  #3_{12} \amp  \cdots \amp  #3_{1#2} \\
#3_{21} \amp  #3_{22} \amp  \cdots \amp  #3_{2#2} \\
\vdots  \amp  \vdots  \amp  \ddots \amp  \vdots  \\
#3_{#1 1} \amp  #3_{#1 2} \amp  \cdots \amp  #3_{#1 #2}
\end{bmatrix}
}
\newcommand{\augmatrix}{
\begin{amatrix}[cccc|c]
a_{11} \amp  a_{12} \amp  \cdots \amp  a_{1n} \amp b_{1}\\
a_{21} \amp  a_{22} \amp  \cdots \amp  a_{2n} \amp b_{2}\\
\vdots  \amp  \vdots  \amp  \ddots \amp  \vdots  \amp \vdots\\
a_{m1} \amp  a_{m2} \amp  \cdots \amp  a_{mn}\amp b_{m}
\end{amatrix}
}
\newcommand{\varaugmatrix}[4]{
\begin{amatrix}[cccc|c]
#3_{11} \amp  #3_{12} \amp  \cdots \amp  #3_{1#2} \amp #4_{1}\\
#3_{21} \amp  #3_{22} \amp  \cdots \amp  #3_{2#2} \amp #4_{2}\\
\vdots  \amp  \vdots  \amp  \ddots \amp  \vdots  \amp \vdots\\
#3_{#1 1} \amp  #3_{#1 2} \amp  \cdots \amp  #3_{#1 #2}\amp #4_{#1}
\end{amatrix}
}
\newcommand{\spaceforemptycolumn}{\makebox[\wd\boxofmathplus]{\ }}

\newcommand{\generalmatrix}[3]{
\left(
\begin{array}{cccc}
#1_{1,1}  \amp #1_{1,2}  \amp \ldots  \amp #1_{1,#2}  \\
#1_{2,1}  \amp #1_{2,2}  \amp \ldots  \amp #1_{2,#2}  \\
\amp \vdots                         \\
#1_{#3,1} \amp #1_{#3,2} \amp \ldots  \amp #1_{#3,#2}
\end{array}
\right)  }
\newcommand{\colvec}[2][c]{\begin{amatrix}[#1] #2 \end{amatrix}}
\DeclareMathOperator{\size}{size}
\DeclareMathOperator{\adjoint}{adj}
\DeclareMathOperator{\sgn}{sgn}
\newcommand{\restrictionmap}[2]{{#1}\mathpunct\upharpoonright\hbox{}_{#2}}
\renewcommand{\emptyset}{\varnothing}

\newcommand{\proj}[2]{\mbox{proj}_{#2}({#1}) }
\renewcommand{\Re}{\operatorname{Re}}
 \renewcommand{\Im}{\operatorname{Im}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href="http://linear-algebra.northwestern.pub/" target="_blank"><img src="external/images/im_holycomm.svg" alt="Logo image"></a><div class="title-container">
<h1 class="heading"><a href="book-1.html"><span class="title">Linear algebra: the theory of vector spaces and linear transformations</span></a></h1>
<p class="byline">Aaron Greicius</p>
</div>
</div></div>
<nav id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<a class="index-button toolbar-item button" href="index-1.html" title="Index">Index</a><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="s_diagonalization.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="c_transbasis.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="backmatter-1.html" title="Next">Next</a></span>
</div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="s_diagonalization.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="c_transbasis.html" title="Up">Up</a><a class="next-button button toolbar-item" href="backmatter-1.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link frontmatter">
<a href="frontmatter-1.html" data-scroll="frontmatter-1" class="internal"><span class="title">Front Matter</span></a><ul>
<li><a href="colophon-1.html" data-scroll="colophon-1" class="internal">Colophon</a></li>
<li><a href="acknowledgement-1.html" data-scroll="acknowledgement-1" class="internal">Acknowledgements</a></li>
</ul>
</li>
<li class="link">
<a href="c_foundations.html" data-scroll="c_foundations" class="internal"><span class="codenumber">0</span> <span class="title">Foundations</span></a><ul>
<li><a href="s_sets_functions.html" data-scroll="s_sets_functions" class="internal">Sets and functions</a></li>
<li><a href="s_logic.html" data-scroll="s_logic" class="internal">Logic</a></li>
<li><a href="s_proof_technique.html" data-scroll="s_proof_technique" class="internal">Proof techniques</a></li>
<li><a href="s_complex_numbers.html" data-scroll="s_complex_numbers" class="internal">Complex numbers</a></li>
<li><a href="s_polynomials.html" data-scroll="s_polynomials" class="internal">Polynomials</a></li>
</ul>
</li>
<li class="link">
<a href="c_linear_systems.html" data-scroll="c_linear_systems" class="internal"><span class="codenumber">1</span> <span class="title">Systems of linear equations</span></a><ul>
<li><a href="s_systems.html" data-scroll="s_systems" class="internal">Systems of linear equations</a></li>
<li><a href="s_ge.html" data-scroll="s_ge" class="internal">Gaussian elimination</a></li>
<li><a href="s_solving.html" data-scroll="s_solving" class="internal">Solving linear systems</a></li>
</ul>
</li>
<li class="link">
<a href="c_matrices.html" data-scroll="c_matrices" class="internal"><span class="codenumber">2</span> <span class="title">Matrices, their arithmetic, and their algebra</span></a><ul>
<li><a href="s_matrix.html" data-scroll="s_matrix" class="internal">Matrices and their arithmetic</a></li>
<li><a href="s_algebraic.html" data-scroll="s_algebraic" class="internal">Algebra of matrices</a></li>
<li><a href="s_invertible_matrices.html" data-scroll="s_invertible_matrices" class="internal">Invertible matrices</a></li>
<li><a href="s_invertibility_theorem.html" data-scroll="s_invertibility_theorem" class="internal">The invertibility theorem</a></li>
<li><a href="s_det.html" data-scroll="s_det" class="internal">The determinant</a></li>
</ul>
</li>
<li class="link">
<a href="c_vectorspace.html" data-scroll="c_vectorspace" class="internal"><span class="codenumber">3</span> <span class="title">Vector spaces and linear transformations</span></a><ul>
<li><a href="s_vectorspace.html" data-scroll="s_vectorspace" class="internal">Real vector spaces</a></li>
<li><a href="s_transformation.html" data-scroll="s_transformation" class="internal">Linear transformations</a></li>
<li><a href="s_subspace.html" data-scroll="s_subspace" class="internal">Subspaces</a></li>
<li><a href="s_nullspace_image.html" data-scroll="s_nullspace_image" class="internal">Null space and image</a></li>
<li><a href="s_span_independence.html" data-scroll="s_span_independence" class="internal">Span and linear independence</a></li>
<li><a href="s_basis.html" data-scroll="s_basis" class="internal">Bases</a></li>
<li><a href="s_dimension.html" data-scroll="s_dimension" class="internal">Dimension</a></li>
<li><a href="s_rank_nullity.html" data-scroll="s_rank_nullity" class="internal">Rank-nullity theorem and fundamental spaces</a></li>
<li><a href="s_isom.html" data-scroll="s_isom" class="internal">Isomorphisms</a></li>
</ul>
</li>
<li class="link">
<a href="c_innerproductspaces.html" data-scroll="c_innerproductspaces" class="internal"><span class="codenumber">4</span> <span class="title">Inner product spaces</span></a><ul>
<li><a href="s_innerproducts.html" data-scroll="s_innerproducts" class="internal">Inner product spaces</a></li>
<li><a href="s_orthogonality.html" data-scroll="s_orthogonality" class="internal">Orthogonal bases</a></li>
<li><a href="s_orthogonal_projection.html" data-scroll="s_orthogonal_projection" class="internal">Orthogonal projection</a></li>
</ul>
</li>
<li class="link">
<a href="c_transbasis.html" data-scroll="c_transbasis" class="internal"><span class="codenumber">5</span> <span class="title">Eigenvectors and diagonalization</span></a><ul>
<li><a href="s_coordinatevectors.html" data-scroll="s_coordinatevectors" class="internal">Coordinate vectors</a></li>
<li><a href="s_matrixreps.html" data-scroll="s_matrixreps" class="internal">Matrix representations of linear transformations</a></li>
<li><a href="s_changeofbasis.html" data-scroll="s_changeofbasis" class="internal">Change of basis</a></li>
<li><a href="s_eigenvectors.html" data-scroll="s_eigenvectors" class="internal">Eigenvectors and eigenvalues</a></li>
<li><a href="s_diagonalization.html" data-scroll="s_diagonalization" class="internal">Diagonalization</a></li>
<li><a href="s_spectral_theorem.html" data-scroll="s_spectral_theorem" class="active">The spectral theorem</a></li>
</ul>
</li>
<li class="link backmatter"><a href="backmatter-1.html" data-scroll="backmatter-1" class="internal"><span class="title">Back Matter</span></a></li>
<li class="link"><a href="appendix-notation.html" data-scroll="appendix-notation" class="internal"><span class="codenumber">A</span> <span class="title">Notation</span></a></li>
<li class="link"><a href="appendix-defs.html" data-scroll="appendix-defs" class="internal"><span class="codenumber">B</span> <span class="title">Definitions</span></a></li>
<li class="link"><a href="appendix-thms.html" data-scroll="appendix-thms" class="internal"><span class="codenumber">C</span> <span class="title">Theory and procedures</span></a></li>
<li class="link"><a href="appendix-egs.html" data-scroll="appendix-egs" class="internal"><span class="codenumber">D</span> <span class="title">Examples</span></a></li>
<li class="link"><a href="appendix-mantras.html" data-scroll="appendix-mantras" class="internal"><span class="codenumber">E</span> <span class="title">Video examples and figures</span></a></li>
<li class="link"><a href="appendix-vids.html" data-scroll="appendix-vids" class="internal"><span class="codenumber">F</span> <span class="title">Mantras and fiats</span></a></li>
<li class="link"><a href="index-1.html" data-scroll="index-1" class="internal"><span class="title">Index</span></a></li>
</ul></nav><div class="extras"><nav><a class="pretext-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content"><section class="section" id="s_spectral_theorem"><h2 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber">5.6</span> <span class="title">The spectral theorem</span>
</h2>
<section class="introduction" id="introduction-82"><p id="p-2759">Among the many takeaways from <a href="s_diagonalization.html" class="internal" title="Section 5.5: Diagonalization">Section 5.5</a> is the simple fact that not all matrices are diagonalizable. In principle <a href="" class="xref" data-knowl="./knowl/th_diagonalizability_eigenspaces.html" title="Theorem 5.5.13: Diagonalizability: dimension of eigenspaces">Theorem 5.5.13</a> gives a complete answer to the question of diagonalizability in terms of eigenspaces. However, you should not be mislead by the artificially simple examples treated in  <a href="s_diagonalization.html" class="internal" title="Section 5.5: Diagonalization">Section 5.5</a>. In practice even the determination (or approximation) of the distinct eigenvalues of an <span class="process-math">\(n\times n\)</span> matrix poses a very challenging computational problem as <span class="process-math">\(n\)</span> gets large. As such the general question of whether a matrix is diagonalizable remains an intractable one. This makes all the more welcoming the main result of this section: <em class="emphasis">all</em> symmetric matrices are diagonalizable! This surprising fact is a consequence of the <a href="" class="xref" data-knowl="./knowl/th_spectral.html" title="Theorem 5.6.8: Spectral theorem for self-adjoint operators">spectral theorem for self-adjoint operators</a>: a result which itself fits into a larger suite of spectral theorems that treat the diagonalizability of various families of linear transformations of inner product spaces (both finite and infinite dimensional).</p></section><section class="subsection" id="ss_self-adjoint"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">5.6.1</span> <span class="title">Self-adjoint operators</span>
</h3>
<p id="p-2760">Though we are mainly interested in the diagonalizability of symmetric matrices, our arguments are made more elegant by abstracting somewhat to the realm of linear transformations of inner product spaces. In this setting the appropriate analogue of a symmetric matrix is a <em class="emphasis">self-adjoint</em> linear transformation.</p>
<article class="definition definition-like" id="d_self-adjoint"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">5.6.1</span><span class="period">.</span><span class="space"> </span><span class="title">Self-adjoint operators.</span>
</h4>
<p id="p-2761">Let <span class="process-math">\((V, \langle\, , \rangle)\)</span> be a finite-dimensional inner product space. A linear transformation <span class="process-math">\(T\colon V\rightarrow V\)</span> is called a <dfn class="terminology">self-adjoint operator</dfn> if</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_self-adjoint">
\begin{equation}
\langle T(\boldv), \boldw\rangle=\langle \boldv, T(\boldw)\rangle\tag{5.6.1}
\end{equation}
</div>
<p class="continuation">for all <span class="process-math">\(\boldv, \boldw\in V\text{.}\)</span></p></article><p id="p-2762">The next theorem makes explicit the connection between self-adjoint operators and symmetric matrices.</p>
<article class="theorem theorem-like" id="th_self-adjoint_symmetric"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">5.6.2</span><span class="period">.</span><span class="space"> </span><span class="title">Self-adjoint operators and symmetry.</span>
</h4>
<p id="p-2763">Let <span class="process-math">\((V, \langle\, , \rangle)\)</span> be a finite-dimensional inner product space, let <span class="process-math">\(T\colon V\rightarrow V\)</span> be a linear transformation, and let <span class="process-math">\(B\)</span> be an orthonormal ordered basis of <span class="process-math">\(V\text{.}\)</span> The following statements are equivalent.</p>
<ol class="decimal">
<li id="li-1012"><p id="p-2764"><span class="process-math">\(T\)</span> is self-adjoint.</p></li>
<li id="li-1013"><p id="p-2765"><span class="process-math">\(A=[T]_B\)</span> is symmetric.</p></li>
</ol></article><article class="hiddenproof" id="proof-119"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-119"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-119"><article class="hiddenproof"><p id="p-2766">Let <span class="process-math">\(B=(\boldv_1, \boldv_2, \dots, \boldv_n)\text{.}\)</span> We have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_orthogonal_basis_formula.html ./knowl/d_innerproduct.html ./knowl/eq_self-adjoint.html ./knowl/ex_self-adjoint_symmetric.html">
\begin{equation*}
A=\begin{amatrix}[cccc]\vert \amp \vert \amp \amp\vert \\
\left[T(\boldv_1)\right]_B\amp [T(\boldv_2)]_B\amp \cdots \amp [T(\boldv_n)]_B\\
\vert \amp \vert \amp \amp\vert
\end{amatrix}\text{.}
\end{equation*}
</div>
<p class="continuation">Furthermore, since <span class="process-math">\(B\)</span> is orthonormal, the <span class="process-math">\(i\)</span>-th entry of <span class="process-math">\([T(\boldv_j)]_B\)</span> is computed as <span class="process-math">\(\langle T(\boldv_j), \boldv_i\rangle\)</span> (<a href="" class="xref" data-knowl="./knowl/th_orthogonal_basis_formula.html" title="Theorem 4.2.7: Calculating with orthogonal bases">4.2.7</a>). Thus <span class="process-math">\(A=[a_{ij}]\text{,}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_orthogonal_basis_formula.html ./knowl/d_innerproduct.html ./knowl/eq_self-adjoint.html ./knowl/ex_self-adjoint_symmetric.html">
\begin{equation*}
a_{ij}=\langle T(\boldv_j), \boldv_i\rangle.
\end{equation*}
</div>
<p class="continuation">It follows that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_orthogonal_basis_formula.html ./knowl/d_innerproduct.html ./knowl/eq_self-adjoint.html ./knowl/ex_self-adjoint_symmetric.html" id="md-266">
\begin{align*}
A \text{ symmetric} \amp\iff a_{ij}=a_{ji} \text{ for all } 1\leq i,j\leq n  \\
\amp\iff \langle T(\boldv_j), \boldv_i\rangle=\langle T(\boldv_i), \boldv_j\rangle \text{ for all } 1\leq i,j\leq n \\
\amp \iff \langle T(\boldv_j), \boldv_i\rangle=\langle \boldv_j, T(\boldv_i)\rangle \text{ for all } 1\leq i,j\leq n \amp (\knowl{./knowl/d_innerproduct.html}{\text{4.1.1}}, ii)\text{.}
\end{align*}
</div>
<p class="continuation">The last equality in this chain of equivalences states that <span class="process-math">\(T\)</span> satisfies property <a href="" class="xref" data-knowl="./knowl/eq_self-adjoint.html" title="Equation 5.6.1">(5.6.1)</a> for all elements of <span class="process-math">\(B\text{.}\)</span> Not surprisingly, this is equivalent to <span class="process-math">\(T\)</span> satisfying the property for <em class="emphasis">all</em> elements in <span class="process-math">\(V\text{.}\)</span> (See <a href="" class="xref" data-knowl="./knowl/ex_self-adjoint_symmetric.html" title="Exercise 5.6.3.9">Exercise 5.6.3.9</a>.) We conclude that <span class="process-math">\(A\)</span> is symmetric if and only if <span class="process-math">\(T\)</span> is self-adjoint.</p></article></div>
<article class="corollary theorem-like" id="cor_self-adjoint_symmetric"><h4 class="heading">
<span class="type">Corollary</span><span class="space"> </span><span class="codenumber">5.6.3</span><span class="period">.</span><span class="space"> </span><span class="title">Self-adjoint operators and symmetry.</span>
</h4>
<p id="p-2767">Let <span class="process-math">\(A\in M_{nn}\text{.}\)</span> The following statements are equivalent.</p>
<ol class="decimal">
<li id="li-1014"><p id="p-2768"><span class="process-math">\(A\)</span> is symmetric.</p></li>
<li id="li-1015"><p id="p-2769"><span class="process-math">\(T_A\)</span> is self-adjoint with respect to the dot product.</p></li>
<li id="li-1016"><p id="p-2770"><span class="process-math">\(A\boldx\, \cdot \boldy=\boldx\cdot A\boldy\)</span> for all <span class="process-math">\(\boldx, \boldy\in\R^n\text{.}\)</span></p></li>
</ol></article><article class="hiddenproof" id="proof-120"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-120"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-120"><article class="hiddenproof"><p id="p-2771">Since <span class="process-math">\(A=[T_A]_B\text{,}\)</span> where <span class="process-math">\(B\)</span> is the standard ordered basis of <span class="process-math">\(\R^n\text{,}\)</span> and since <span class="process-math">\(B\)</span> is orthonormal with respect to the dot product, it follows from <a href="" class="xref" data-knowl="./knowl/th_self-adjoint_symmetric.html" title="Theorem 5.6.2: Self-adjoint operators and symmetry">Theorem 5.6.2</a> that statements (1) and (2) are equivalent. Statements (2) and (3) are equivalent since by definition <span class="process-math">\(T_A(\boldx)=A\boldx\)</span> for all <span class="process-math">\(\boldx\in \R^n\text{.}\)</span></p></article></div>
<p id="p-2772">The next result, impressive in its own right, is also key to the induction argument we will use to prove <a href="" class="xref" data-knowl="./knowl/th_spectral.html" title="Theorem 5.6.8: Spectral theorem for self-adjoint operators">Theorem 5.6.8</a>. A proper proof would require a careful treatment of complex vector spaces: a topic which lies just outside the scope of this text. The “proof sketch” we provide can easily be upgraded to a complete argument simply by justifying a few statements about <span class="process-math">\(\C^n\)</span> and its standard inner product.</p>
<article class="theorem theorem-like" id="th_self-adjoint_eigenvalue"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">5.6.4</span><span class="period">.</span><span class="space"> </span><span class="title">Eigenvalues of self-adjoint operators.</span>
</h4>
<p id="p-2773">Let <span class="process-math">\((V, \langle\, , \rangle)\)</span> be a finite-dimensional inner product space. If <span class="process-math">\(T\colon V\rightarrow V\)</span> is self adjoint, then all roots of its characteristic polynomial <span class="process-math">\(p(x)\)</span> are real: i.e., we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
p(x)=(x-\lambda_1)(x-\lambda_2)\cdots (x-\lambda_n)\text{,}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(\lambda_i\in \R\)</span> for all <span class="process-math">\(1\leq i\leq n\text{.}\)</span></p></article><article class="hiddenproof" id="proof_sketch"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof_sketch"><h4 class="heading"><span class="title">Proof sketch of Theorem 5.6.2.</span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof_sketch"><article class="hiddenproof"><p id="p-2774">Pick an orthonormal ordered basis <span class="process-math">\(B\)</span> of <span class="process-math">\(V\text{,}\)</span> and let <span class="process-math">\(A=[T]_B\text{.}\)</span> By <a href="" class="xref" data-knowl="./knowl/th_self-adjoint_symmetric.html" title="Theorem 5.6.2: Self-adjoint operators and symmetry">Theorem 5.6.2</a>, <span class="process-math">\(A\)</span> is symmetric. To prove that all roots of the characteristic polynomial <span class="process-math">\(p(t)=\det(tI-A)\)</span> are real, we make a slight detour into complex vector spaces. The set</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_self-adjoint_symmetric.html ./knowl/d_vector_space.html">
\begin{equation*}
\C^n=\{(z_1,z_2,\dots, z_n)\colon z_i\in \C \text{ for all } 1\leq i\leq n\}
\end{equation*}
</div>
<p class="continuation">of all complex <span class="process-math">\(n\)</span>-tuples, together with the operations</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_self-adjoint_symmetric.html ./knowl/d_vector_space.html">
\begin{equation*}
(z_1,z_2,\dots, z_n)+(w_1, w_2,\dots, w_n)=(z_1+w_1, z_2+w_2, \dots, z_n+w_n)
\end{equation*}
</div>
<p class="continuation">and</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_self-adjoint_symmetric.html ./knowl/d_vector_space.html">
\begin{equation*}
\alpha (z_1, z_2, \dots, z_n)=(\alpha z_1, \alpha z_2, \dots, \alpha z_n),
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(\alpha\in \C\text{,}\)</span> forms what is called a <em class="emphasis">vector space over <span class="process-math">\(\C\)</span></em>. This means that <span class="process-math">\(V=\C^n\)</span> satisfies the strengthened axioms of <a href="" class="xref" data-knowl="./knowl/d_vector_space.html" title="Definition 3.1.1: Vector space">Definition 3.1.1</a> obtained by replacing every mention of a scalar <span class="process-math">\(c\in \R\)</span> with a scalar <span class="process-math">\(\alpha\in \C\text{.}\)</span> Additionally, the vector space <span class="process-math">\(\C^n\)</span> has the structure of a complex inner product defined as</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_self-adjoint_symmetric.html ./knowl/d_vector_space.html">
\begin{equation*}
\langle (z_1,z_2,\dots, z_n), (w_1,w_2,\dots, w_n)\rangle=z_1\overline{w_1}+z_2\overline{w_2}+\cdots +z_n\overline{w_n}\text{,}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(\overline{w_i}\)</span> denotes the complex conjugate of <span class="process-math">\(w_i\)</span> for each <span class="process-math">\(i\text{.}\)</span> Essentially all of our theory of real vector spaces can be “transported” to complex vector spaces, including definitions and results about eigenvectors and inner products. The rest of this argument makes use of this principle by citing without proof some of these properties, and this is why it has been downgraded to a “proof sketch”.</p>
<p id="p-2775">We now return to <span class="process-math">\(A\)</span> and its characteristic polynomial <span class="process-math">\(p(x)\text{.}\)</span> Recall that we want to show that all roots of <span class="process-math">\(p(x)\)</span> are real.  Let <span class="process-math">\(\lambda\in \C\)</span> be a root of <span class="process-math">\(p(x)\text{.}\)</span> The complex theory of eigenvectors implies that there is a nonzero vector <span class="process-math">\(\boldz\in \C^n\)</span> satisfying <span class="process-math">\(A\boldz=\lambda \boldz\text{.}\)</span> On the one hand, we have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/cor_self-adjoint_symmetric.html">
\begin{equation*}
\langle A\boldz, \boldz\rangle =\langle \lambda\boldz, \boldz\rangle=\lambda\langle \boldz, \boldz\rangle
\end{equation*}
</div>
<p class="continuation">using properties of our complex inner product. On the other hand, since <span class="process-math">\(A^T=A\)</span> it is easy to see that <a href="" class="xref" data-knowl="./knowl/cor_self-adjoint_symmetric.html" title="Corollary 5.6.3: Self-adjoint operators and symmetry">Corollary 5.6.3</a> extends to our complex inner product: i.e.,</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/cor_self-adjoint_symmetric.html">
\begin{equation*}
\langle A\boldz, \boldw\rangle=\langle \boldz, A\boldw\rangle
\end{equation*}
</div>
<p class="continuation">for all <span class="process-math">\(\boldz, \boldw\in \C^n\text{.}\)</span> Thus</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/cor_self-adjoint_symmetric.html" id="md-267">
\begin{align*}
\langle A\boldz, \boldz\rangle  \amp=  \\
\amp= \langle \boldz, A\boldz\rangle \\
\amp = \langle \boldz, \lambda\boldz\rangle\\
\amp =\overline{\lambda}\langle \boldz, \boldz\rangle \text{.}
\end{align*}
</div>
<p class="continuation">(In the last equality we use the fact that our complex inner product satisfies <span class="process-math">\(\langle \boldz, \alpha\boldw\rangle=\overline{\alpha} \langle \boldz, \boldw\rangle\)</span> for any <span class="process-math">\(\alpha\in \C\)</span> and vectors <span class="process-math">\(\boldz, \boldw\in \C^n\text{.}\)</span>) It follows that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/cor_self-adjoint_symmetric.html">
\begin{equation*}
\lambda\langle \boldz, \boldz\rangle=\overline{\lambda}\langle \boldz, \boldz\rangle\text{.}
\end{equation*}
</div>
<p class="continuation">Since <span class="process-math">\(\boldz\ne \boldzero\text{,}\)</span> we have <span class="process-math">\(\langle \boldz, \boldz\rangle\ne 0\)</span> (another property of our complex inner product), and thus <span class="process-math">\(\lambda=\overline{\lambda}\text{.}\)</span> Since a complex number <span class="process-math">\(z=a+bi\)</span> satisfies <span class="process-math">\(\overline{z}=z\)</span> if and only if <span class="process-math">\(b=0\)</span> if and only if <span class="process-math">\(z\)</span> is real, we conclude that <span class="process-math">\(\lambda\)</span> is a real number, as claimed.</p></article></div>
<article class="corollary theorem-like" id="cor_self-adjoint_eigenvalue"><h4 class="heading">
<span class="type">Corollary</span><span class="space"> </span><span class="codenumber">5.6.5</span><span class="period">.</span><span class="space"> </span><span class="title">Eigenvalues of self-adjoint operators.</span>
</h4>
<p id="p-2776">If <span class="process-math">\(T\)</span> is a self-adjoint operator on a finite-dimensional inner product space <span class="process-math">\(V\text{,}\)</span> then <span class="process-math">\(T\)</span> has an eigenvalue: i.e., there is a <span class="process-math">\(\lambda\in \R\)</span> and nonzero <span class="process-math">\(\boldv\in V\)</span> such that <span class="process-math">\(T(\boldv)=\lambda\boldv\text{.}\)</span></p></article><article class="hiddenproof" id="proof-122"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-122"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-122"><article class="hiddenproof"><p id="p-2777">The corollary follows from <a href="" class="xref" data-knowl="./knowl/th_self-adjoint_eigenvalue.html" title="Theorem 5.6.4: Eigenvalues of self-adjoint operators">Theorem 5.6.4</a> and the fact that the eigenvalues of <span class="process-math">\(T\)</span> are the real roots of its characteristic polynomial (<a href="" class="xref" data-knowl="./knowl/th_characteristic_polynomial.html" title="Theorem 5.4.25: Characteristic polynomial">5.4.25</a>).</p></article></div>
<p id="p-2778">From <a href="" class="xref" data-knowl="./knowl/th_self-adjoint_eigenvalue.html" title="Theorem 5.6.4: Eigenvalues of self-adjoint operators">Theorem 5.6.4</a> and <a href="" class="xref" data-knowl="./knowl/cor_self-adjoint_symmetric.html" title="Corollary 5.6.3: Self-adjoint operators and symmetry">Corollary 5.6.3</a> it follows that the characterisitic polynomial of any symmetric matrix must factor as a product of linear terms over <span class="process-math">\(\R\text{,}\)</span> as illustrated by the next two examples.</p>
<article class="example example-like" id="eg_symmetric_matrix"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">5.6.6</span><span class="period">.</span><span class="space"> </span><span class="title">Symmetric <span class="process-math">\(2\times 2\)</span> matrices.</span>
</h4>
<p id="p-2779">Verify that the characteristic polynomial of any symmetric <span class="process-math">\(2\times 2\)</span> matrix factors into linear terms over <span class="process-math">\(\R\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-104" id="solution-104"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-104"><div class="solution solution-like">
<p id="p-2780">Given a symmetric <span class="process-math">\(2\times 2\)</span> matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A=\begin{bmatrix}
a\amp b\\
b\amp c
\end{bmatrix}\text{,}
\end{equation*}
</div>
<p class="continuation">we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
p(x)=\det(xI-A)=x^2-(a+c)x+(ac-b^2).\text{.}
\end{equation*}
</div>
<p class="continuation">Using the quadratic formula and some algebra, we see that the roots of <span class="process-math">\(p(x)\)</span> are given by where (using the quadratic formula)</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\frac{(a+c)\pm \sqrt{(a+c)^2-4ac+4b^2}}{2}=\frac{(a+c)\pm \sqrt{(a-c)^2+4b^2}}{2}\text{.}
\end{equation*}
</div>
<p class="continuation">Since <span class="process-math">\((a-c)^2+4b^2\geq 0\text{,}\)</span> we see that both these roots are real. Thus <span class="process-math">\(p(x)=(x-\lambda_1)(x-\lambda_2)\text{,}\)</span> where <span class="process-math">\(\lambda_1, \lambda_2\in \R\text{.}\)</span></p>
</div></div>
</div></article><article class="example example-like" id="example-135"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">5.6.7</span><span class="period">.</span><span class="space"> </span><span class="title">Symmetric <span class="process-math">\(4\times 4\)</span> matrix.</span>
</h4>
<p id="p-2781">Verify that the characteristic polynomial of the symmetric matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A=\begin{amatrix}[rrrr]
6 \amp 2\amp 4\amp 0\\
2\amp 6\amp 0\amp 4\\
4\amp 0\amp -6\amp -2\\
0\amp 4\amp -2\amp -6
\end{amatrix}
\end{equation*}
</div>
<p class="continuation">factors into linear terms over <span class="process-math">\(\R\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-105" id="solution-105"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-105"><div class="solution solution-like">
<p id="p-2782">The characteristic polynomial of <span class="process-math">\(A\)</span> is <span class="process-math">\(p(x)=x^4-112x^2+2560\text{.}\)</span> We can use the quadratic equation to solve <span class="process-math">\(p(x)=0\)</span> for <span class="process-math">\(u=x^2\text{,}\)</span> yielding</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
u=\frac{112\pm\sqrt{(112)^2-4(2560)}}{2}=56\pm 24\text{.}
\end{equation*}
</div>
<p class="continuation">We conclude that <span class="process-math">\(x^2=32\)</span> or <span class="process-math">\(x^2=80\text{,}\)</span> and thus <span class="process-math">\(x=\pm 4\sqrt{2}\)</span> or <span class="process-math">\(x=\pm 4\sqrt{5}\text{.}\)</span> It follows that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
p(x)=(x-4\sqrt{2})(x+4\sqrt{2})(x-4\sqrt{5})(x+4\sqrt{5})\text{.}
\end{equation*}
</div>
</div></div>
</div></article></section><section class="subsection" id="ss_spectal_theorem_operators"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">5.6.2</span> <span class="title">The spectral theorem for self-adjoint operators</span>
</h3>
<section class="introduction" id="introduction-83"><p id="p-2783">Our version of the spectral theorem concerns self-adjoint linear transformations on a finite-dimensional inner product space. It tells us two remarkable things: (a) every such linear transformation has an eigenbasis (and hence is diagonalizable); and furthermore, (b) the eigenbasis can be chosen to be orthogonal, or even orthonormal.</p></section><article class="theorem theorem-like" id="th_spectral"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">5.6.8</span><span class="period">.</span><span class="space"> </span><span class="title">Spectral theorem for self-adjoint operators.</span>
</h4>
<p id="p-2784">Let <span class="process-math">\((V, \angvec{\, , \,})\)</span> be a finite-dimensional vector space, and let <span class="process-math">\(T\colon V\rightarrow V\)</span> be a linear transformation. The following statements are equivalent.</p>
<ol class="decimal">
<li id="li-1017"><p id="p-2785"><span class="process-math">\(T\)</span> is self-adjoint.</p></li>
<li id="li-1018"><p id="p-2786"><span class="process-math">\(T\)</span> is diagonalizable and eigenvectors with distinct eigenvalues are orthogonal.</p></li>
<li id="li-1019"><p id="p-2787"><span class="process-math">\(T\)</span> has an orthogonal eigenbasis.</p></li>
<li id="li-1020"><p id="p-2788"><span class="process-math">\(T\)</span> has an orthonormal eigenbasis.</p></li>
</ol></article><article class="hiddenproof" id="proof-123"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-123"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-123"><article class="hiddenproof"><p id="p-2789">We will prove the cycle of implications <span class="process-math">\((1)\implies (2)\implies (3)\implies (4)\implies (1)\text{.}\)</span></p>
<article class="hiddenproof" id="proof-124"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-124"><h5 class="heading"><span class="title">Implication: <span class="process-math">\((1)\implies (2)\)</span>.</span></h5></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-124"><article class="hiddenproof"><p id="p-2790">Assume <span class="process-math">\(T\)</span> is self adjoint. First we show that eigenvectors with distinct eigenvalues are orthogonal. To this end, suppose we have <span class="process-math">\(T(\boldv)=\lambda\boldv\)</span> and <span class="process-math">\(T(\boldv')=\lambda'\boldv'\text{,}\)</span> where <span class="process-math">\(\lambda\ne \lambda'\text{.}\)</span> Using the definition of self-adjoint, we have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/cor_self-adjoint_eigenvalue.html ./knowl/ex_selfadjoint_complement.html" id="md-268">
\begin{align*}
\angvec{T(\boldv), \boldv'}=\angvec{\boldv, T(\boldv')} \amp\implies \angvec{\lambda\boldv, \boldv'}=\angvec{\boldv, \lambda'\boldv'} \\
\amp\implies \lambda\angvec{\boldv, \boldv'}=\lambda'\angvec{\boldv, \boldv'} \\
\amp \implies \angvec{\boldv, \boldv'}=0 \amp (\lambda\ne \lambda')\text{.}
\end{align*}
</div>
<p class="continuation">We now prove by induction on <span class="process-math">\(\dim V\)</span> that if <span class="process-math">\(T\)</span> is self-adjoint, then <span class="process-math">\(T\)</span> is diagonalizable. The base case <span class="process-math">\(\dim V=1\)</span> is trivial. Assume the result is true of any <span class="process-math">\(n\)</span>-dimensional inner product space, and suppose <span class="process-math">\(\dim V=n+1\text{.}\)</span> By <a href="" class="xref" data-knowl="./knowl/cor_self-adjoint_eigenvalue.html" title="Corollary 5.6.5: Eigenvalues of self-adjoint operators">Corollary 5.6.5</a> there is a nonzero <span class="process-math">\(\boldv\in V\)</span> with <span class="process-math">\(T(\boldv)=\lambda\boldv\text{.}\)</span> Let <span class="process-math">\(W=\Span\{\boldv\}\text{.}\)</span> Since <span class="process-math">\(\dim W=1\text{,}\)</span> we have <span class="process-math">\(\dim W^\perp=\dim V-1=n\text{.}\)</span> The following two facts are crucial for the rest of the argument and are left as an exercise (<a href="" class="xref" data-knowl="./knowl/ex_selfadjoint_complement.html" title="Exercise 5.6.3.10">5.6.3.10</a>).</p>
<ol class="decimal">
<li id="li-1021"><p id="p-2791">For all <span class="process-math">\(\boldv\in W^\perp\)</span> we have <span class="process-math">\(T(\boldv)\in W^\perp\text{,}\)</span> and thus by restricting <span class="process-math">\(T\)</span> to <span class="process-math">\(W^\perp\)</span> we get a linear transformation <span class="process-math">\(T\vert_{W^{\perp}}\colon W^\perp\rightarrow W^\perp\text{.}\)</span></p></li>
<li id="li-1022"><p id="p-2792">The restriction <span class="process-math">\(T\vert_{W^\perp}\)</span> is self-adjoint, considered as a linear transformation of the inner product space <span class="process-math">\(W^\perp\text{.}\)</span>  Here the inner product on the subspace <span class="process-math">\(W^\perp\)</span> is inherited from <span class="process-math">\((V, \angvec{\, , \,})\)</span> by restriction.</p></li>
</ol>
<p class="continuation">Now since <span class="process-math">\(\dim W^\perp=n-1\)</span> and <span class="process-math">\(T\vert_{W^\perp}\)</span> is self-adjoint, we may assume by induction that <span class="process-math">\(T\vert_{W^\perp}\)</span> has an eigenbasis <span class="process-math">\(B'=(\boldv_1, \boldv_2,\dots, \boldv_n)\text{.}\)</span> We claim that <span class="process-math">\(B=(\boldv, \boldv_2, \dots, \boldv_n)\)</span> is an eigenbasis of <span class="process-math">\(V\text{.}\)</span> Since by definition <span class="process-math">\(T\vert_{W^\perp}(\boldw')=T(\boldw')\)</span> for all <span class="process-math">\(\boldw'\in W^\perp\text{,}\)</span> we see that the vectors <span class="process-math">\(\boldv_i\)</span> are also eigenvectors of <span class="process-math">\(T\text{,}\)</span> and thus that <span class="process-math">\(B\)</span> consists of eigenvectors. To show <span class="process-math">\(B\)</span> is a basis it is enought to prove linear independence, since  <span class="process-math">\(\dim V=n+1\text{.}\)</span> Suppose we have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/cor_self-adjoint_eigenvalue.html ./knowl/ex_selfadjoint_complement.html">
\begin{equation*}
c\boldv+c_1\boldv_1+\cdots +c_n\boldv_n=\boldzero
\end{equation*}
</div>
<p class="continuation">for scalars <span class="process-math">\(c, c_i\in \R\text{.}\)</span> Taking the inner product with <span class="process-math">\(\boldv\text{,}\)</span> we have :</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/cor_self-adjoint_eigenvalue.html ./knowl/ex_selfadjoint_complement.html" id="md-269">
\begin{align*}
c\boldv+c_1\boldv_1+\cdots +c_n\boldv_n=\boldzero\amp\implies\\
\langle\boldv, c\boldv+c_1\boldv_1+\cdots +c_n\boldv_n\rangle=\langle\boldv, \boldzero\rangle
\amp\implies c\angvec{\boldv, \boldv}+\sum_{i=1}^nc_i\angvec{\boldv, \boldv_i}=0 \\
\amp \implies
c\angvec{\boldv, \boldv}=0 \amp (\angvec{\boldv, \boldv_i}=0)\\
\amp \implies c=0 \amp (\angvec{\boldv, \boldv}\ne 0)\text{.}
\end{align*}
</div>
<p class="continuation">It follows that we have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/cor_self-adjoint_eigenvalue.html ./knowl/ex_selfadjoint_complement.html">
\begin{equation*}
c_1\boldv_1+\cdots +c_n\boldv_n=\boldzero\text{,}
\end{equation*}
</div>
<p class="continuation">and thus <span class="process-math">\(c_i=0\)</span> for all <span class="process-math">\(1\leq i\leq n\text{,}\)</span> since <span class="process-math">\(B'\)</span> is linearly independent. Having proved that <span class="process-math">\(B\)</span> is an eigenbasis, we conclude that <span class="process-math">\(T\)</span> is diagonalizable.</p></article></div>
<article class="hiddenproof" id="proof-125"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-125"><h5 class="heading"><span class="title">Implication: <span class="process-math">\((2)\implies (3)\)</span>.</span></h5></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-125"><article class="hiddenproof"><p id="p-2793">Let <span class="process-math">\(\lambda_1, \lambda_2, \dots, \lambda_r\)</span> be the distinct eigenvalues of <span class="process-math">\(T\text{.}\)</span> Since <span class="process-math">\(T\)</span> is assumed to be diagonalizable, following <a href="" class="xref" data-knowl="./knowl/proc_diagonalize.html" title="Procedure 5.5.14: Deciding whether a linear transformation is diagonalizable">Procedure 5.5.14</a> we can create an eigenbasis <span class="process-math">\(B\)</span> by picking bases <span class="process-math">\(B_i\)</span> of each eigenspace <span class="process-math">\(W_{\lambda_i}\)</span> and combining them. We can always choose these bases so that each <span class="process-math">\(B_i\)</span> is orthogonal. When we do so, the assembled <span class="process-math">\(B\)</span> will be orthogonal as a whole. Indeed given any two elements <span class="process-math">\(\boldv, \boldv'\)</span> of <span class="process-math">\(B\text{,}\)</span> if both vectors are elements of <span class="process-math">\(B_i\)</span> for some <span class="process-math">\(i\text{,}\)</span> then they are orthogonal <em class="emphasis">by design</em>; furthermore, if <span class="process-math">\(\boldv\)</span> is an element of basis <span class="process-math">\(B_i\)</span> and <span class="process-math">\(\boldv'\)</span> is an element of basis <span class="process-math">\(B_j\)</span> with <span class="process-math">\(i\ne j\text{,}\)</span> then they are eigenvectors with distinct eigenvalues, and hence orthogonal <em class="emphasis">by assumption</em>!</p></article></div>
<article class="hiddenproof" id="proof-126"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-126"><h5 class="heading"><span class="title">Implication: <span class="process-math">\((3)\implies (4)\)</span>.</span></h5></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-126"><article class="hiddenproof"><p id="p-2794">This is easy to see since an orthonormal eigenbasis can be obtained from an orthogonal eigenbasis by scaling each element by the reciprocal of its norm.</p></article></div>
<article class="hiddenproof" id="proof-127"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-127"><h5 class="heading"><span class="title">Implication: <span class="process-math">\((4)\implies (1)\)</span>.</span></h5></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-127"><article class="hiddenproof"><p id="p-2795">Assume <span class="process-math">\(B\)</span> is an orthonormal eigenbasis of <span class="process-math">\(T\text{.}\)</span> Since <span class="process-math">\(B\)</span> is an eigenbasis, <span class="process-math">\([T]_B\)</span> is a diagonal matrix, and hence symmetric. Since <span class="process-math">\(B\)</span> is orthonormal with respect to the dot product, we conclude from <a href="" class="xref" data-knowl="./knowl/th_self-adjoint_symmetric.html" title="Theorem 5.6.2: Self-adjoint operators and symmetry">Theorem 5.6.2</a> that <span class="process-math">\(T\)</span> is self-adjoint.</p></article></div></article></div>
<p id="p-2796">An operator that admits an orthogonal (and hence an orthonormal) eigenbasis is called  <em class="emphasis">orthogonally diagonalizable</em>.</p>
<article class="definition definition-like" id="d_orthogonally_diagable"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">5.6.9</span><span class="period">.</span><span class="space"> </span><span class="title">Orthogonally diagonalizable.</span>
</h4>
<p id="p-2797">Let <span class="process-math">\(V\)</span> be a finite-dimensional inner product space. A linear transformation <span class="process-math">\(T\colon V\rightarrow V\)</span> is <dfn class="terminology">orthogonally diagonalizable</dfn> if there exists an orthogonal (equivalently, an orthonormal) eigenbasis of <span class="process-math">\(T\text{.}\)</span></p></article><p id="p-2798">This new language affords us a more succinct articulation of <a href="" class="xref" data-knowl="./knowl/th_spectral.html" title="Theorem 5.6.8: Spectral theorem for self-adjoint operators">Theorem 5.6.8</a>: to be self-adjoint is to be orthogonally diagonalizable. Think of this as a sort of “diagonalizable+” condition.</p>
<article class="principle theorem-like" id="mantra_self-adjoint"><h4 class="heading">
<span class="type">Mantra</span><span class="space"> </span><span class="codenumber">5.6.10</span><span class="period">.</span><span class="space"> </span><span class="title">Self-adjoint mantra.</span>
</h4>
<p id="p-2799">To be self-adjoint on a finite-dimensional inner product space is to be “diagonalizable+”. In more detail:</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_self_adjoint">
\begin{equation}
T \text{ is self-adjoint} \iff T \text{ is orthogonally diagonalizable}\text{.}\tag{5.6.2}
\end{equation}
</div></article><p id="p-2800">As an immediate consequence of <a href="" class="xref" data-knowl="./knowl/th_spectral.html" title="Theorem 5.6.8: Spectral theorem for self-adjoint operators">Theorem 5.6.8</a>, we have the following result about symmetric matrices.</p>
<article class="corollary theorem-like" id="cor_spectral"><h4 class="heading">
<span class="type">Corollary</span><span class="space"> </span><span class="codenumber">5.6.11</span><span class="period">.</span><span class="space"> </span><span class="title">Spectral theorem for symmetric matrices.</span>
</h4>
<p id="p-2801">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n\times n\)</span> matrix. The following statements are equivalent.</p>
<ol class="decimal">
<li id="li-1023"><p id="p-2802"><span class="process-math">\(A\)</span> is symmetric.</p></li>
<li id="li-1024"><p id="p-2803"><span class="process-math">\(A\)</span> is diagonalizable and eigenvectors with distinct eigenvalues are orthogonal with respect to the dot product.</p></li>
<li id="li-1025"><p id="p-2804"><span class="process-math">\(A\)</span> is orthogonally diagonalizable.</p></li>
<li id="li-1026">
<p id="p-2805">There exists an <a href="" class="xref" data-knowl="./knowl/d_orthogonal_matrix.html" title="Definition 5.3.12: Orthogonal matrices">orthogonal matrix</a> <span class="process-math">\(Q\)</span> and diagonal matrix <span class="process-math">\(D\)</span> such that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/d_orthogonal_matrix.html" id="eq_ortho_diag">
\begin{equation}
D=Q^{-1}AQ=Q^TAQ\text{.}\tag{5.6.3}
\end{equation}
</div>
</li>
</ol></article><article class="hiddenproof" id="proof-128"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-128"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-128"><article class="hiddenproof"><p id="p-2806">By <a href="" class="xref" data-knowl="./knowl/cor_self-adjoint_symmetric.html" title="Corollary 5.6.3: Self-adjoint operators and symmetry">Corollary 5.6.3</a> we have <span class="process-math">\(A\)</span> symmetric if and only if <span class="process-math">\(T_A\)</span> is self-adjoint with respect to the dot product. Statements (1)-(3) are seen to be equivalent by applying <a href="" class="xref" data-knowl="./knowl/th_spectral.html" title="Theorem 5.6.8: Spectral theorem for self-adjoint operators">Theorem 5.6.8</a> to <span class="process-math">\(T_A\)</span> (with respect to the dot product). Let <span class="process-math">\(B\)</span> be the standard basis of <span class="process-math">\(\R^n\text{.}\)</span> We see that (4) is equivalent to (3) by observing that <span class="process-math">\(B'\)</span> is an orthonormal eigenbasis of <span class="process-math">\(T_A\)</span> if and only if the matrix <span class="process-math">\(Q=\underset{B'\rightarrow B}{P}\)</span> obtained by placing the elements of <span class="process-math">\(B'\)</span> as columns is orthogonal and diagonalizes <span class="process-math">\(A\text{.}\)</span></p></article></div>
<p id="p-2807">The process of finding matrices <span class="process-math">\(Q\)</span> and <span class="process-math">\(D\)</span> satisfying <a href="" class="xref" data-knowl="./knowl/eq_ortho_diag.html" title="Equation 5.6.3">(5.6.3)</a> is called <em class="emphasis">orthogonal diagonalization</em>. A close look at the proof of <a href="" class="xref" data-knowl="./knowl/th_spectral.html" title="Theorem 5.6.8: Spectral theorem for self-adjoint operators">Theorem 5.6.8</a> gives rise to the following orthogonal diagonalization method for matrices.</p>
<article class="algorithm theorem-like" id="proc_ortho_diag"><h4 class="heading">
<span class="type">Procedure</span><span class="space"> </span><span class="codenumber">5.6.12</span><span class="period">.</span><span class="space"> </span><span class="title">Orthogonal diagonalization.</span>
</h4>
<p id="p-2808">Let <span class="process-math">\(A\)</span> be a symmetric matrix. To orthogonally diagonalize <span class="process-math">\(A\)</span> proceed as follows.</p>
<ol class="decimal">
<li id="li-1027"><p id="p-2809">Let <span class="process-math">\(\lambda_1, \lambda_2, \dots, \lambda_r\)</span> be the distinct eigenvalues of <span class="process-math">\(A\text{.}\)</span> For each <span class="process-math">\(1\leq i\leq r\text{,}\)</span> compute an <em class="emphasis">orthonormal</em> ordered basis of <span class="process-math">\(W_{\lambda_i}\text{.}\)</span></p></li>
<li id="li-1028">
<p id="p-2810">Let <span class="process-math">\(B'=(\boldv_1, \boldv_2, \dots, \boldv_n)\)</span> be the ordered basis obtained by concatenating the orthonormal bases computed in (1). This is an orthonormal basis of eigenvectors. It follows that the matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
Q=\begin{bmatrix}
\vert\amp \vert\amp \amp \vert\\
\boldv_1\amp \boldv_2\amp\cdots \amp \boldv_n\\
\vert\amp \vert\amp \amp \vert
\end{bmatrix}
\end{equation*}
</div>
<p class="continuation">is orthogonal (i.e., <span class="process-math">\(Q^{-1}=Q^T\)</span>), and the matrix <span class="process-math">\(D=Q^{-1}AQ=Q^TAQ\)</span> is diagonal.</p>
</li>
</ol></article><article class="example example-like" id="eg_ortho_diag"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">5.6.13</span><span class="period">.</span><span class="space"> </span><span class="title">Orthogonal diagonalization.</span>
</h4>
<p id="p-2811">The symmetric matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A=\frac{1}{3}\begin{amatrix}[rrr]
-1\amp 2\amp 2\\
2 \amp -1 \amp 2 \\
2\amp 2 \amp -1  \end{amatrix}
\end{equation*}
</div>
<p class="continuation">has characteristic polynomial <span class="process-math">\(p(x)=x^3+x^2-x-1\text{.}\)</span> Find an orthogonal matrix <span class="process-math">\(Q\)</span> and diagonal matrix <span class="process-math">\(D\)</span> such that <span class="process-math">\(D=Q^TAQ\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-106" id="solution-106"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-106"><div class="solution solution-like">
<p id="p-2812">First we factor <span class="process-math">\(p(x)\text{.}\)</span> Looking at the constant term we see that the only possible integer roots of <span class="process-math">\(p(x)\)</span> are <span class="process-math">\(\pm 1\text{.}\)</span> It is easily verified that <span class="process-math">\(p(1)=0\text{,}\)</span> and  polynomial division yields the factorization <span class="process-math">\(p(x)=(x-1)(x^2+2x+1)\text{.}\)</span>  Further factorization of <span class="process-math">\(x^2+2x+1\)</span> gives us  <span class="process-math">\(p(x)=(x-1)(x+1)^2\text{.}\)</span></p>
<p id="p-2813">Next we compute <em class="emphasis">orthonormal</em> bases of the eigenspaces <span class="process-math">\(W_1\)</span> and <span class="process-math">\(W_{-1}\text{,}\)</span> yielding</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-270">
\begin{align*}
B_1\amp=\left(\frac{1}{\sqrt{3}}(1,1,1)\right) \amp B_{2}\amp =\left(\frac{1}{\sqrt{2}}(1,-1,0), \frac{1}{\sqrt{6}}(1,1,-2)\right)\text{.}
\end{align*}
</div>
<p class="continuation">Assembling these bases elements into the orthogonal matrix</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
Q=\begin{amatrix}[rrr]1/\sqrt{3}\amp 1/\sqrt{2}\amp 1/\sqrt{6}\\
1/\sqrt{3}\amp -1/\sqrt{2}\amp 1/\sqrt{6}\\
1/\sqrt{3}\amp 0\amp -2/\sqrt{6}\end{amatrix}\text{,}
\end{equation*}
</div>
<p class="continuation">we conclude that <span class="process-math">\(D=Q^{-1}AQ=Q^TAQ\text{,}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
D=\begin{amatrix}[rrr]1\amp 0\amp 0\\ 0\amp -1\amp 0\\ 0\amp 0\amp -1  \end{amatrix}\text{.}
\end{equation*}
</div>
</div></div>
</div></article><p id="p-2814">Observe that the two eigenspaces <span class="process-math">\(W_1\)</span> and <span class="process-math">\(W_{-1}\)</span> of the matrix <span class="process-math">\(A\)</span> in <a href="" class="xref" data-knowl="./knowl/eg_ortho_diag.html" title="Example 5.6.13: Orthogonal diagonalization">Example 5.6.13</a> are orthogonal to one another, as predicted by the spectral theorem. Indeed, <span class="process-math">\(W_1\)</span> is the line passing through the origin with direction vector <span class="process-math">\(\boldn=(1,1,1)\text{,}\)</span> and <span class="process-math">\(W_{-1}\)</span> is its orthogonal complement, the plane passing through the origin with normal vector <span class="process-math">\(\boldn\text{.}\)</span> <a href="" class="xref" data-knowl="./knowl/fig_ortho_diag.html" title="Figure 5.6.14: Eigenspaces of a symmetric matrix are orthogonal">Figure 5.6.14</a> depicts the orthogonal configuration of the eigenspaces of this example. This is an excellent illustration of what makes the diagonalizability of symmetric matrices (and self-adjoint operators) special. Keep it in mind!</p>
<figure class="figure figure-like" id="fig_ortho_diag"><iframe id="geogebra_ortho_diag" width="600" height="450" src="geogebra_ortho_diag-if.html"></iframe><figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">5.6.14<span class="period">.</span></span><span class="space"> </span>Eigenspaces of a symmetric matrix are orthogonal</figcaption></figure><p id="p-2815">Do not overlook the reverse implication of equivalence <a href="" class="xref" data-knowl="./knowl/eq_self_adjoint.html" title="Equation 5.6.2">(5.6.2)</a>. As the next example illustrates, we can show an operator is self-adjoint by examining the geometry of its eigenspaces.</p>
<article class="example example-like" id="eg_ortho_proj_selfadjoint"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">5.6.15</span><span class="period">.</span><span class="space"> </span><span class="title">Orthogonal projections are self-adjoint.</span>
</h4>
<p id="p-2816">Let <span class="process-math">\((V,\angvec{\, , \,})\)</span> be a finite-dimensional inner product space, let <span class="process-math">\(W\)</span> be a subpsace of <span class="process-math">\(V\text{,}\)</span> and let <span class="process-math">\(T=\operatorname{proj}_W\)</span> be orthogonal projection onto <span class="process-math">\(W\text{.}\)</span> Prove that <span class="process-math">\(T\)</span> is self-adjoint.</p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-107" id="solution-107"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-107"><div class="solution solution-like">
<p id="p-2817">By <a href="" class="xref" data-knowl="./knowl/th_spectral.html" title="Theorem 5.6.8: Spectral theorem for self-adjoint operators">Theorem 5.6.8</a> it suffices to show that <span class="process-math">\(T\)</span> is orthogonally diagonalizable. According to <a href="" class="xref" data-knowl="./knowl/ex_orthoproj_props.html" title="Exercise 4.3.6.12">Exercise 4.3.6.12</a> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_spectral.html ./knowl/ex_orthoproj_props.html" id="md-271">
\begin{align*}
\boldv\in W \amp \iff T(\boldv)=\boldv\\
\boldv\in W^\perp \amp \iff T(\boldv)=\boldzero\text{.}
\end{align*}
</div>
<p class="continuation">Equivalently, <span class="process-math">\(W=W_1\)</span> and <span class="process-math">\(W^\perp=W_0\)</span> are the 1- and 0-eigenspaces of <span class="process-math">\(T\text{,}\)</span> respectively. Since <span class="process-math">\(\dim W+\dim W^\perp=\dim V\)</span> we conclude that <span class="process-math">\(T\)</span> is diagonalizable. Since clearly <span class="process-math">\(W\)</span> and <span class="process-math">\(W^\perp\)</span> are orthogonal, we conclude that <span class="process-math">\(T\)</span> is in fact othogonally diagonalizable, hence self-adjoint.</p>
</div></div>
</div></article></section><section class="exercises" id="s_spectral_theorem_ex"><h3 class="heading hide-type">
<span class="type">Exercises</span> <span class="codenumber">5.6.3</span> <span class="title">Exercises</span>
</h3>
<div class="exercisegroup" id="exercisegroup-39">
<h4 class="heading"><span class="title">Exercise Group.</span></h4>
<div class="introduction" id="introduction-84"><p id="p-2818">Orthogonally diagonalize the given symmetric matrix <span class="process-math">\(A\)</span> following <a href="" class="xref" data-knowl="./knowl/proc_ortho_diag.html" title="Procedure 5.6.12: Orthogonal diagonalization">Procedure 5.6.12</a>: i.e. find a diagonal matrix <span class="process-math">\(D\)</span> and orthogonal matrix <span class="process-math">\(Q\)</span> satisfying <span class="process-math">\(D=Q^{T}AQ\text{.}\)</span></p></div>
<div class="exercisegroup-exercises">
<article class="exercise exercise-like" id="exercise-319"><h5 class="heading"><span class="codenumber">1<span class="period">.</span></span></h5>
<p id="p-2819"><span class="process-math">\(A=\begin{amatrix}[rr]
2\amp 1\\ 1\amp 2
\end{amatrix}\)</span></p></article><article class="exercise exercise-like" id="exercise-320"><h5 class="heading"><span class="codenumber">2<span class="period">.</span></span></h5>
<p id="p-2820"><span class="process-math">\(A=\begin{amatrix}[rr]-1\amp 1\\ 1\amp 2  \end{amatrix}\)</span></p></article><article class="exercise exercise-like" id="exercise-321"><h5 class="heading"><span class="codenumber">3<span class="period">.</span></span></h5>
<p id="p-2821"><span class="process-math">\(A=\begin{amatrix}[rrr]-1 \amp 1 \amp -2 \\
1 \amp -1 \amp -2 \\
-2 \amp -2 \amp 2  \end{amatrix}\)</span></p></article><article class="exercise exercise-like" id="exercise-322"><h5 class="heading"><span class="codenumber">4<span class="period">.</span></span></h5>
<p id="p-2822"><span class="process-math">\(A=\frac{1}{6}\begin{amatrix}[rrr]
1\amp 7\amp -2\\
7\amp 1\amp -2\\
-2\amp -2\amp 10
\end{amatrix}\)</span></p></article><article class="exercise exercise-like" id="exercise-323"><h5 class="heading"><span class="codenumber">5<span class="period">.</span></span></h5>
<p id="p-2823"><span class="process-math">\(A=\begin{amatrix}[rrr]
1\amp 2\amp 1\\
2\amp 0\amp 0\\
1\amp 0\amp 3  \end{amatrix}\)</span></p></article><article class="exercise exercise-like" id="exercise-324"><h5 class="heading"><span class="codenumber">6<span class="period">.</span></span></h5>
<p id="p-2824"><span class="process-math">\(A=\begin{amatrix}[rrrr]
0 \amp 0 \amp 1 \amp 0 \\
0 \amp 0 \amp 0 \amp 1 \\
1 \amp 0 \amp 0 \amp 0 \\
0 \amp 1 \amp 0 \amp 0  \end{amatrix}\)</span></p></article><article class="exercise exercise-like" id="exercise-325"><h5 class="heading"><span class="codenumber">7<span class="period">.</span></span></h5>
<p id="p-2825"><span class="process-math">\(A=\begin{amatrix}[rrrr]0 \amp 0 \amp 1 \amp 0 \\
0 \amp 1 \amp 0 \amp 0 \\
1 \amp 0 \amp 0 \amp 0 \\
0 \amp 0 \amp 0 \amp 1  \end{amatrix}\)</span></p></article><article class="exercise exercise-like" id="exercise-326"><h5 class="heading"><span class="codenumber">8<span class="period">.</span></span></h5>
<p id="p-2826"><span class="process-math">\(A=\begin{amatrix}[rrrr]
1\amp 1\amp 1\amp 1\\
1\amp 1\amp 1\amp 1 \\
1\amp 1\amp 1\amp 1 \\
1\amp 1\amp 1\amp 1
\end{amatrix}\)</span></p></article>
</div>
</div>
<article class="exercise exercise-like" id="ex_self-adjoint_symmetric"><h4 class="heading"><span class="codenumber">9<span class="period">.</span></span></h4>
<p id="p-2827">Let <span class="process-math">\((V, \langle\, , \rangle)\)</span> be a finite-dimensional inner product space, let <span class="process-math">\(T\colon V\rightarrow V\)</span> be a linear transformation, and let <span class="process-math">\(B=(\boldv_1, \boldv_2, \dots, \boldv_n)\)</span> be an ordered basis of <span class="process-math">\(V\text{.}\)</span> Prove: <span class="process-math">\(T\)</span> is self-adjoint if and only if</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_self-adjoint.html">
\begin{equation*}
\langle T(\boldv_i),\boldv_j\rangle=\langle \boldv_i, T(\boldv_j)\rangle
\end{equation*}
</div>
<p class="continuation">for all <span class="process-math">\(1\leq i,j\leq n\text{.}\)</span> In other words, to prove <span class="process-math">\(T\)</span> is self-adjoint it suffices to show property <a href="" class="xref" data-knowl="./knowl/eq_self-adjoint.html" title="Equation 5.6.1">(5.6.1)</a> holds for all elements of a basis of <span class="process-math">\(V\text{.}\)</span></p></article><article class="exercise exercise-like" id="ex_selfadjoint_complement"><h4 class="heading"><span class="codenumber">10<span class="period">.</span></span></h4>
<p id="p-2828">Let <span class="process-math">\((V, \langle\, , \rangle)\)</span> be a finite-dimensional inner product space, let <span class="process-math">\(T\colon V\rightarrow V\)</span> be a self-adjoint operator, and let <span class="process-math">\(W\)</span> be a subspace of <span class="process-math">\(V\text{.}\)</span></p>
<ol class="lower-alpha">
<li id="li-1029"><p id="p-2829">Prove: if <span class="process-math">\(\boldv\in W^\perp\text{,}\)</span> then <span class="process-math">\(T(\boldv)\in W^\perp\text{.}\)</span></p></li>
<li id="li-1030">
<p id="p-2830">By (a), restricting <span class="process-math">\(T\)</span> to <span class="process-math">\(W^\perp\)</span> defines a linear transformation</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-272">
\begin{align*}
T\vert_{W^\perp}\colon W^\perp\amp\rightarrow W^\perp \\
\boldv \amp \mapsto T(\boldv)\text{.}
\end{align*}
</div>
<p class="continuation">Prove that <span class="process-math">\(T\vert_{W^\perp}\)</span> is self-adjoint. Here the inner product on the subspace <span class="process-math">\(W^\perp\)</span> is inherited from <span class="process-math">\((V, \angvec{\, , \,})\)</span> by restriction.</p>
</li>
</ol></article><article class="exercise exercise-like" id="exercise-329"><h4 class="heading"><span class="codenumber">11<span class="period">.</span></span></h4>
<p id="p-2831">Assume <span class="process-math">\(A\in M_{nn}\)</span> is symmetric and orthogonal. Prove that the characteristic polynomial of <span class="process-math">\(A\)</span> factors as <span class="process-math">\(p(x)=(x-1)^r(x+1)^s\)</span> for some nonnegative integers <span class="process-math">\(r,s\text{.}\)</span> In particular, the eigenvalues of <span class="process-math">\(A\)</span> are among <span class="process-math">\(1\)</span> and <span class="process-math">\(-1\text{.}\)</span></p></article><div class="exercisegroup" id="exercisegroup-40">
<h4 class="heading"><span class="title">Exercise Group.</span></h4>
<div class="introduction" id="introduction-85">
<p id="p-2832">Let <span class="process-math">\(\mathcal{C}\subseteq \R^2\)</span> be a conic curve defined by a quadratic equation of the form</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq_conic_eqn">
\begin{equation}
\mathcal{C}\colon ax^2+bxy+cy^2=d\tag{5.6.4}
\end{equation}
</div>
<p class="continuation">where <span class="process-math">\(a,b,c\in \R\)</span> are fixed constants. You may have learned that <span class="process-math">\(\mathcal{C}\)</span> can be rotated to a conic <span class="process-math">\(\mathcal{C}'\)</span> with a “standard equation” of the form <span class="process-math">\(ex^2+fy^2=d\text{.}\)</span> In the following exercises we will see why this is true.</p>
</div>
<div class="exercisegroup-exercises">
<article class="exercise exercise-like" id="exercise-330"><h5 class="heading"><span class="codenumber">12<span class="period">.</span></span></h5>
<p id="p-2833">Find a symmetric matrix <span class="process-math">\(A\in M_{22}\)</span> satisfying the following property: <span class="process-math">\(\boldx=(x,y)\)</span> satisfies <a href="" class="xref" data-knowl="./knowl/eq_conic_eqn.html" title="Equation 5.6.4">(5.6.4)</a> if and only if</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_conic_eqn.html" id="eq_conic_eqn_matrix">
\begin{equation}
\boldx \cdot (A\boldx)=\boldx^TA\boldx=d\text{.}\tag{5.6.5}
\end{equation}
</div>
<p class="continuation">(Here we conflate the <span class="process-math">\(1\times 1\)</span> matrix <span class="process-math">\(\begin{bmatrix}d
\end{bmatrix}\)</span> with the scalar <span class="process-math">\(d\in \R\text{.}\)</span>)</p></article><article class="exercise exercise-like" id="exercise-331"><h5 class="heading"><span class="codenumber">13<span class="period">.</span></span></h5>
<p id="p-2834">Show that there is a rotation matrix <span class="process-math">\(Q\in M_{22}\)</span> satisfying <span class="process-math">\(D=Q^TAQ\text{,}\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
D=\begin{amatrix}[rr] e\amp 0\\ 0\amp f \end{amatrix}
\end{equation*}
</div>
<p class="continuation">for some <span class="process-math">\(e,f\in \R\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-38" id="hint-38"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-38"><div class="hint solution-like"><p id="p-2835">See <a href="" class="xref" data-knowl="./knowl/ex_ortho_matrix_rotation_reflection.html" title="Exercise 5.3.5.16">Exercise 5.3.5.16</a>.</p></div></div>
</div></article><article class="exercise exercise-like" id="exercise-332"><h5 class="heading"><span class="codenumber">14<span class="period">.</span></span></h5>
<p id="p-2836">Show that <span class="process-math">\(\boldx\)</span> satisfies <a href="" class="xref" data-knowl="./knowl/eq_conic_eqn_matrix.html" title="Equation 5.6.5">(5.6.5)</a> if and only if <span class="process-math">\(\boldx'=Q^{-1}\boldx=Q^T\boldx\)</span> satisfies</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_conic_eqn_matrix.html" id="eq_conic_std">
\begin{equation}
ex+fy=d\text{.}\tag{5.6.6}
\end{equation}
</div></article><article class="exercise exercise-like" id="exercise-333"><h5 class="heading"><span class="codenumber">15<span class="period">.</span></span></h5>
<p id="p-2837">Explain why we can conclude that there is a rotation that maps the conic <span class="process-math">\(\mathcal{C}\)</span> with equation <a href="" class="xref" data-knowl="./knowl/eq_conic_eqn.html" title="Equation 5.6.4">(5.6.4)</a> to the conic <span class="process-math">\(\mathcal{C}'\)</span> with “standard equation” <a href="" class="xref" data-knowl="./knowl/eq_conic_std.html" title="Equation 5.6.6">(5.6.6)</a>.</p></article><article class="exercise exercise-like" id="exercise-334"><h5 class="heading"><span class="codenumber">16<span class="period">.</span></span></h5>
<p id="p-2838">Let <span class="process-math">\(\mathcal{C}\subseteq\R^2\)</span> be the conic curve with equation</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x^2+4xy+y^2=1\text{.}
\end{equation*}
</div>
<ol class="lower-alpha">
<li id="li-1031">
<p id="p-2839">Find an angle <span class="process-math">\(\theta\)</span> and constants <span class="process-math">\(a,b\in \R\)</span> such that the rotation <span class="process-math">\(\rho_\theta\)</span> maps <span class="process-math">\(\mathcal{C}\)</span> to a conic <span class="process-math">\(\mathcal{C}'\)</span> with defining equation</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
ax^2+by^2=1\text{.}
\end{equation*}
</div>
</li>
<li id="li-1032"><p id="p-2840">First graph <span class="process-math">\(\mathcal{C}'\text{,}\)</span> and then graph <span class="process-math">\(\mathcal{C}\)</span> using the result of (a). What type of conics (parabolas, ellipses, hyperbolas) are <span class="process-math">\(\mathcal{C}\)</span> and <span class="process-math">\(\mathcal{C'}\)</span> ?</p></li>
</ol></article>
</div>
</div></section></section></div></main>
</div>
</body>
</html>
